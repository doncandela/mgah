<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title></title>
  <style>
  @font-face {
  font-family: octicons-link;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body .octicon {
  display: inline-block;
  fill: currentColor;
  vertical-align: text-bottom;
}

.markdown-body .anchor {
  float: left;
  line-height: 1;
  margin-left: -20px;
  padding-right: 4px;
}

.markdown-body .anchor:focus {
  outline: none;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
  color: #1b1f23;
  vertical-align: middle;
  visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
  text-decoration: none;
}

.markdown-body h1:hover .anchor .octicon-link,
.markdown-body h2:hover .anchor .octicon-link,
.markdown-body h3:hover .anchor .octicon-link,
.markdown-body h4:hover .anchor .octicon-link,
.markdown-body h5:hover .anchor .octicon-link,
.markdown-body h6:hover .anchor .octicon-link {
  visibility: visible;
}

.markdown-body {
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #24292e;
  line-height: 1.5;
  font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;
  font-size: 16px;
  line-height: 1.5;
  word-wrap: break-word;
}

.markdown-body .pl-c {
  color: #6a737d;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
  color: #005cc5;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
  color: #6f42c1;
}

.markdown-body .pl-s .pl-s1,
.markdown-body .pl-smi {
  color: #24292e;
}

.markdown-body .pl-ent {
  color: #22863a;
}

.markdown-body .pl-k {
  color: #d73a49;
}

.markdown-body .pl-pds,
.markdown-body .pl-s,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sra,
.markdown-body .pl-sr .pl-sre {
  color: #032f62;
}

.markdown-body .pl-smw,
.markdown-body .pl-v {
  color: #e36209;
}

.markdown-body .pl-bu {
  color: #b31d28;
}

.markdown-body .pl-ii {
  background-color: #b31d28;
  color: #fafbfc;
}

.markdown-body .pl-c2 {
  background-color: #d73a49;
  color: #fafbfc;
}

.markdown-body .pl-c2:before {
  content: "^M";
}

.markdown-body .pl-sr .pl-cce {
  color: #22863a;
  font-weight: 700;
}

.markdown-body .pl-ml {
  color: #735c0f;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
  color: #005cc5;
  font-weight: 700;
}

.markdown-body .pl-mi {
  color: #24292e;
  font-style: italic;
}

.markdown-body .pl-mb {
  color: #24292e;
  font-weight: 700;
}

.markdown-body .pl-md {
  background-color: #ffeef0;
  color: #b31d28;
}

.markdown-body .pl-mi1 {
  background-color: #f0fff4;
  color: #22863a;
}

.markdown-body .pl-mc {
  background-color: #ffebda;
  color: #e36209;
}

.markdown-body .pl-mi2 {
  background-color: #005cc5;
  color: #f6f8fa;
}

.markdown-body .pl-mdr {
  color: #6f42c1;
  font-weight: 700;
}

.markdown-body .pl-ba {
  color: #586069;
}

.markdown-body .pl-sg {
  color: #959da5;
}

.markdown-body .pl-corl {
  color: #032f62;
  text-decoration: underline;
}

.markdown-body details {
  display: block;
}

.markdown-body summary {
  display: list-item;
}

.markdown-body a {
  background-color: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline-width: 0;
}

.markdown-body strong {
  font-weight: inherit;
  font-weight: bolder;
}

.markdown-body h1 {
  font-size: 2em;
  margin: .67em 0;
}

.markdown-body img {
  border-style: none;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
  font-family: monospace,monospace;
  font-size: 1em;
}

.markdown-body hr {
  box-sizing: content-box;
  height: 0;
  overflow: visible;
}

.markdown-body input {
  font: inherit;
  margin: 0;
}

.markdown-body input {
  overflow: visible;
}

.markdown-body [type=checkbox] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body * {
  box-sizing: border-box;
}

.markdown-body input {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}

.markdown-body a {
  color: #0366d6;
  text-decoration: none;
}

.markdown-body a:hover {
  text-decoration: underline;
}

.markdown-body strong {
  font-weight: 600;
}

.markdown-body hr {
  background: transparent;
  border: 0;
  border-bottom: 1px solid #dfe2e5;
  height: 0;
  margin: 15px 0;
  overflow: hidden;
}

.markdown-body hr:before {
  content: "";
  display: table;
}

.markdown-body hr:after {
  clear: both;
  content: "";
  display: table;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body details summary {
  cursor: pointer;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-bottom: 0;
  margin-top: 0;
}

.markdown-body h1 {
  font-size: 32px;
}

.markdown-body h1,
.markdown-body h2 {
  font-weight: 600;
}

.markdown-body h2 {
  font-size: 24px;
}

.markdown-body h3 {
  font-size: 20px;
}

.markdown-body h3,
.markdown-body h4 {
  font-weight: 600;
}

.markdown-body h4 {
  font-size: 16px;
}

.markdown-body h5 {
  font-size: 14px;
}

.markdown-body h5,
.markdown-body h6 {
  font-weight: 600;
}

.markdown-body h6 {
  font-size: 12px;
}

.markdown-body p {
  margin-bottom: 10px;
  margin-top: 0;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ol,
.markdown-body ul {
  margin-bottom: 0;
  margin-top: 0;
  padding-left: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ol ol ol,
.markdown-body ol ul ol,
.markdown-body ul ol ol,
.markdown-body ul ul ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre {
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-bottom: 0;
  margin-top: 0;
}

.markdown-body input::-webkit-inner-spin-button,
.markdown-body input::-webkit-outer-spin-button {
  -webkit-appearance: none;
  appearance: none;
  margin: 0;
}

.markdown-body .border {
  border: 1px solid #e1e4e8!important;
}

.markdown-body .border-0 {
  border: 0!important;
}

.markdown-body .border-bottom {
  border-bottom: 1px solid #e1e4e8!important;
}

.markdown-body .rounded-1 {
  border-radius: 3px!important;
}

.markdown-body .bg-white {
  background-color: #fff!important;
}

.markdown-body .bg-gray-light {
  background-color: #fafbfc!important;
}

.markdown-body .text-gray-light {
  color: #6a737d!important;
}

.markdown-body .mb-0 {
  margin-bottom: 0!important;
}

.markdown-body .my-2 {
  margin-bottom: 8px!important;
  margin-top: 8px!important;
}

.markdown-body .pl-0 {
  padding-left: 0!important;
}

.markdown-body .py-0 {
  padding-bottom: 0!important;
  padding-top: 0!important;
}

.markdown-body .pl-1 {
  padding-left: 4px!important;
}

.markdown-body .pl-2 {
  padding-left: 8px!important;
}

.markdown-body .py-2 {
  padding-bottom: 8px!important;
  padding-top: 8px!important;
}

.markdown-body .pl-3,
.markdown-body .px-3 {
  padding-left: 16px!important;
}

.markdown-body .px-3 {
  padding-right: 16px!important;
}

.markdown-body .pl-4 {
  padding-left: 24px!important;
}

.markdown-body .pl-5 {
  padding-left: 32px!important;
}

.markdown-body .pl-6 {
  padding-left: 40px!important;
}

.markdown-body .f6 {
  font-size: 12px!important;
}

.markdown-body .lh-condensed {
  line-height: 1.25!important;
}

.markdown-body .text-bold {
  font-weight: 600!important;
}

.markdown-body:before {
  content: "";
  display: table;
}

.markdown-body:after {
  clear: both;
  content: "";
  display: table;
}

.markdown-body>:first-child {
  margin-top: 0!important;
}

.markdown-body>:last-child {
  margin-bottom: 0!important;
}

.markdown-body a:not([href]) {
  color: inherit;
  text-decoration: none;
}

.markdown-body blockquote,
.markdown-body dl,
.markdown-body ol,
.markdown-body p,
.markdown-body pre,
.markdown-body table,
.markdown-body ul {
  margin-bottom: 16px;
  margin-top: 0;
}

.markdown-body hr {
  background-color: #e1e4e8;
  border: 0;
  height: .25em;
  margin: 24px 0;
  padding: 0;
}

.markdown-body blockquote {
  border-left: .25em solid #dfe2e5;
  color: #6a737d;
  padding: 0 1em;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #fafbfc;
  border: 1px solid #c6cbd1;
  border-bottom-color: #959da5;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #959da5;
  color: #444d56;
  display: inline-block;
  font-size: 11px;
  line-height: 10px;
  padding: 3px 5px;
  vertical-align: middle;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  font-weight: 600;
  line-height: 1.25;
  margin-bottom: 16px;
  margin-top: 24px;
}

.markdown-body h1 {
  font-size: 2em;
}

.markdown-body h1,
.markdown-body h2 {
  border-bottom: 1px solid #eaecef;
  padding-bottom: .3em;
}

.markdown-body h2 {
  font-size: 1.5em;
}

.markdown-body h3 {
  font-size: 1.25em;
}

.markdown-body h4 {
  font-size: 1em;
}

.markdown-body h5 {
  font-size: .875em;
}

.markdown-body h6 {
  color: #6a737d;
  font-size: .85em;
}

.markdown-body ol,
.markdown-body ul {
  padding-left: 2em;
}

.markdown-body ol ol,
.markdown-body ol ul,
.markdown-body ul ol,
.markdown-body ul ul {
  margin-bottom: 0;
  margin-top: 0;
}

.markdown-body li {
  word-wrap: break-all;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body li+li {
  margin-top: .25em;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  font-size: 1em;
  font-style: italic;
  font-weight: 600;
  margin-top: 16px;
  padding: 0;
}

.markdown-body dl dd {
  margin-bottom: 16px;
  padding: 0 16px;
}

.markdown-body table {
  display: block;
  overflow: auto;
  width: 100%;
}

.markdown-body table th {
  font-weight: 600;
}

.markdown-body table td,
.markdown-body table th {
  border: 1px solid #dfe2e5;
  padding: 6px 13px;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #c6cbd1;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f6f8fa;
}

.markdown-body img {
  background-color: #fff;
  box-sizing: content-box;
  max-width: 100%;
}

.markdown-body img[align=right] {
  padding-left: 20px;
}

.markdown-body img[align=left] {
  padding-right: 20px;
}

.markdown-body code {
  background-color: rgba(27,31,35,.05);
  border-radius: 3px;
  font-size: 85%;
  margin: 0;
  padding: .2em .4em;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre>code {
  background: transparent;
  border: 0;
  font-size: 100%;
  margin: 0;
  padding: 0;
  white-space: pre;
  word-break: normal;
}

.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body .highlight pre,
.markdown-body pre {
  background-color: #f6f8fa;
  border-radius: 3px;
  font-size: 85%;
  line-height: 1.45;
  overflow: auto;
  padding: 16px;
}

.markdown-body pre code {
  background-color: transparent;
  border: 0;
  display: inline;
  line-height: inherit;
  margin: 0;
  max-width: auto;
  overflow: visible;
  padding: 0;
  word-wrap: normal;
}

.markdown-body .commit-tease-sha {
  color: #444d56;
  display: inline-block;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 90%;
}

.markdown-body .blob-wrapper {
  border-bottom-left-radius: 3px;
  border-bottom-right-radius: 3px;
  overflow-x: auto;
  overflow-y: hidden;
}

.markdown-body .blob-wrapper-embedded {
  max-height: 240px;
  overflow-y: auto;
}

.markdown-body .blob-num {
  -moz-user-select: none;
  -ms-user-select: none;
  -webkit-user-select: none;
  color: rgba(27,31,35,.3);
  cursor: pointer;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 12px;
  line-height: 20px;
  min-width: 50px;
  padding-left: 10px;
  padding-right: 10px;
  text-align: right;
  user-select: none;
  vertical-align: top;
  white-space: nowrap;
  width: 1%;
}

.markdown-body .blob-num:hover {
  color: rgba(27,31,35,.6);
}

.markdown-body .blob-num:before {
  content: attr(data-line-number);
}

.markdown-body .blob-code {
  line-height: 20px;
  padding-left: 10px;
  padding-right: 10px;
  position: relative;
  vertical-align: top;
}

.markdown-body .blob-code-inner {
  color: #24292e;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 12px;
  overflow: visible;
  white-space: pre;
  word-wrap: normal;
}

.markdown-body .pl-token.active,
.markdown-body .pl-token:hover {
  background: #ffea7f;
  cursor: pointer;
}

.markdown-body kbd {
  background-color: #fafbfc;
  border: 1px solid #d1d5da;
  border-bottom-color: #c6cbd1;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #c6cbd1;
  color: #444d56;
  display: inline-block;
  font: 11px SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  line-height: 10px;
  padding: 3px 5px;
  vertical-align: middle;
}

.markdown-body :checked+.radio-label {
  border-color: #0366d6;
  position: relative;
  z-index: 1;
}

.markdown-body .tab-size[data-tab-size="1"] {
  -moz-tab-size: 1;
  tab-size: 1;
}

.markdown-body .tab-size[data-tab-size="2"] {
  -moz-tab-size: 2;
  tab-size: 2;
}

.markdown-body .tab-size[data-tab-size="3"] {
  -moz-tab-size: 3;
  tab-size: 3;
}

.markdown-body .tab-size[data-tab-size="4"] {
  -moz-tab-size: 4;
  tab-size: 4;
}

.markdown-body .tab-size[data-tab-size="5"] {
  -moz-tab-size: 5;
  tab-size: 5;
}

.markdown-body .tab-size[data-tab-size="6"] {
  -moz-tab-size: 6;
  tab-size: 6;
}

.markdown-body .tab-size[data-tab-size="7"] {
  -moz-tab-size: 7;
  tab-size: 7;
}

.markdown-body .tab-size[data-tab-size="8"] {
  -moz-tab-size: 8;
  tab-size: 8;
}

.markdown-body .tab-size[data-tab-size="9"] {
  -moz-tab-size: 9;
  tab-size: 9;
}

.markdown-body .tab-size[data-tab-size="10"] {
  -moz-tab-size: 10;
  tab-size: 10;
}

.markdown-body .tab-size[data-tab-size="11"] {
  -moz-tab-size: 11;
  tab-size: 11;
}

.markdown-body .tab-size[data-tab-size="12"] {
  -moz-tab-size: 12;
  tab-size: 12;
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 .2em .25em -1.6em;
  vertical-align: middle;
}

.markdown-body hr {
  border-bottom-color: #eee;
}

.markdown-body .pl-0 {
  padding-left: 0!important;
}

.markdown-body .pl-1 {
  padding-left: 4px!important;
}

.markdown-body .pl-2 {
  padding-left: 8px!important;
}

.markdown-body .pl-3 {
  padding-left: 16px!important;
}

.markdown-body .pl-4 {
  padding-left: 24px!important;
}

.markdown-body .pl-5 {
  padding-left: 32px!important;
}

.markdown-body .pl-6 {
  padding-left: 40px!important;
}

.markdown-body .pl-7 {
  padding-left: 48px!important;
}

.markdown-body .pl-8 {
  padding-left: 64px!important;
}

.markdown-body .pl-9 {
  padding-left: 80px!important;
}

.markdown-body .pl-10 {
  padding-left: 96px!important;
}

.markdown-body .pl-11 {
  padding-left: 112px!important;
}

.markdown-body .pl-12 {
  padding-left: 128px!important;
}

/*# sourceURL=webpack://./node_modules/github-markdown-css/github-markdown.css */
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,{"version":3,"sources":["webpack://./node_modules/github-markdown-css/github-markdown.css"],"names":[],"mappings":"AAAA;EACE,0BAA0B;EAC1B,2DAAqtE;AACvtE;;AAEA;EACE,qBAAqB;EACrB,kBAAkB;EAClB,2BAA2B;AAC7B;;AAEA;EACE,WAAW;EACX,cAAc;EACd,kBAAkB;EAClB,kBAAkB;AACpB;;AAEA;EACE,aAAa;AACf;;AAEA;;;;;;EAME,cAAc;EACd,sBAAsB;EACtB,kBAAkB;AACpB;;AAEA;;;;;;EAME,qBAAqB;AACvB;;AAEA;;;;;;EAME,mBAAmB;AACrB;;AAEA;EACE,0BAA0B;EAC1B,8BAA8B;EAC9B,cAAc;EACd,gBAAgB;EAChB,kIAAkI;EAClI,eAAe;EACf,gBAAgB;EAChB,qBAAqB;AACvB;;AAEA;EACE,cAAc;AAChB;;AAEA;;EAEE,cAAc;AAChB;;AAEA;;EAEE,cAAc;AAChB;;AAEA;;EAEE,cAAc;AAChB;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,cAAc;AAChB;;AAEA;;;;;;;EAOE,cAAc;AAChB;;AAEA;;EAEE,cAAc;AAChB;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,aAAa;AACf;;AAEA;EACE,cAAc;EACd,gBAAgB;AAClB;;AAEA;EACE,cAAc;AAChB;;AAEA;;;EAGE,cAAc;EACd,gBAAgB;AAClB;;AAEA;EACE,cAAc;EACd,kBAAkB;AACpB;;AAEA;EACE,cAAc;EACd,gBAAgB;AAClB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,cAAc;EACd,gBAAgB;AAClB;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,cAAc;EACd,0BAA0B;AAC5B;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,kBAAkB;AACpB;;AAEA;EACE,6BAA6B;AAC/B;;AAEA;;EAEE,gBAAgB;AAClB;;AAEA;EACE,oBAAoB;EACpB,mBAAmB;AACrB;;AAEA;EACE,cAAc;EACd,eAAe;AACjB;;AAEA;EACE,kBAAkB;AACpB;;AAEA;;;EAGE,gCAAgC;EAChC,cAAc;AAChB;;AAEA;EACE,uBAAuB;EACvB,SAAS;EACT,iBAAiB;AACnB;;AAEA;EACE,aAAa;EACb,SAAS;AACX;;AAEA;EACE,iBAAiB;AACnB;;AAEA;EACE,sBAAsB;EACtB,UAAU;AACZ;;AAEA;EACE,sBAAsB;AACxB;;AAEA;EACE,oBAAoB;EACpB,kBAAkB;EAClB,oBAAoB;AACtB;;AAEA;EACE,cAAc;EACd,qBAAqB;AACvB;;AAEA;EACE,0BAA0B;AAC5B;;AAEA;EACE,gBAAgB;AAClB;;AAEA;EACE,uBAAuB;EACvB,SAAS;EACT,gCAAgC;EAChC,SAAS;EACT,cAAc;EACd,gBAAgB;AAClB;;AAEA;EACE,WAAW;EACX,cAAc;AAChB;;AAEA;EACE,WAAW;EACX,WAAW;EACX,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,iBAAiB;AACnB;;AAEA;;EAEE,UAAU;AACZ;;AAEA;EACE,eAAe;AACjB;;AAEA;;;;;;EAME,gBAAgB;EAChB,aAAa;AACf;;AAEA;EACE,eAAe;AACjB;;AAEA;;EAEE,gBAAgB;AAClB;;AAEA;EACE,eAAe;AACjB;;AAEA;EACE,eAAe;AACjB;;AAEA;;EAEE,gBAAgB;AAClB;;AAEA;EACE,eAAe;AACjB;;AAEA;EACE,eAAe;AACjB;;AAEA;;EAEE,gBAAgB;AAClB;;AAEA;EACE,eAAe;AACjB;;AAEA;EACE,mBAAmB;EACnB,aAAa;AACf;;AAEA;EACE,SAAS;AACX;;AAEA;;EAEE,gBAAgB;EAChB,aAAa;EACb,eAAe;AACjB;;AAEA;;EAEE,4BAA4B;AAC9B;;AAEA;;;;EAIE,4BAA4B;AAC9B;;AAEA;EACE,cAAc;AAChB;;AAEA;;EAEE,4EAA4E;EAC5E,eAAe;AACjB;;AAEA;EACE,gBAAgB;EAChB,aAAa;AACf;;AAEA;;EAEE,wBAAwB;EACxB,gBAAgB;EAChB,SAAS;AACX;;AAEA;EACE,mCAAmC;AACrC;;AAEA;EACE,mBAAmB;AACrB;;AAEA;EACE,0CAA0C;AAC5C;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,gCAAgC;AAClC;;AAEA;EACE,mCAAmC;AACrC;;AAEA;EACE,wBAAwB;AAC1B;;AAEA;EACE,0BAA0B;AAC5B;;AAEA;EACE,4BAA4B;EAC5B,yBAAyB;AAC3B;;AAEA;EACE,yBAAyB;AAC3B;;AAEA;EACE,2BAA2B;EAC3B,wBAAwB;AAC1B;;AAEA;EACE,2BAA2B;AAC7B;;AAEA;EACE,2BAA2B;AAC7B;;AAEA;EACE,6BAA6B;EAC7B,0BAA0B;AAC5B;;AAEA;;EAEE,4BAA4B;AAC9B;;AAEA;EACE,6BAA6B;AAC/B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,yBAAyB;AAC3B;;AAEA;EACE,2BAA2B;AAC7B;;AAEA;EACE,0BAA0B;AAC5B;;AAEA;EACE,WAAW;EACX,cAAc;AAChB;;AAEA;EACE,WAAW;EACX,WAAW;EACX,cAAc;AAChB;;AAEA;EACE,uBAAuB;AACzB;;AAEA;EACE,0BAA0B;AAC5B;;AAEA;EACE,cAAc;EACd,qBAAqB;AACvB;;AAEA;;;;;;;EAOE,mBAAmB;EACnB,aAAa;AACf;;AAEA;EACE,yBAAyB;EACzB,SAAS;EACT,aAAa;EACb,cAAc;EACd,UAAU;AACZ;;AAEA;EACE,gCAAgC;EAChC,cAAc;EACd,cAAc;AAChB;;AAEA;EACE,aAAa;AACf;;AAEA;EACE,gBAAgB;AAClB;;AAEA;EACE,yBAAyB;EACzB,yBAAyB;EACzB,4BAA4B;EAC5B,kBAAkB;EAClB,kCAAkC;EAClC,cAAc;EACd,qBAAqB;EACrB,eAAe;EACf,iBAAiB;EACjB,gBAAgB;EAChB,sBAAsB;AACxB;;AAEA;;;;;;EAME,gBAAgB;EAChB,iBAAiB;EACjB,mBAAmB;EACnB,gBAAgB;AAClB;;AAEA;EACE,cAAc;AAChB;;AAEA;;EAEE,gCAAgC;EAChC,oBAAoB;AACtB;;AAEA;EACE,gBAAgB;AAClB;;AAEA;EACE,iBAAiB;AACnB;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,iBAAiB;AACnB;;AAEA;EACE,cAAc;EACd,gBAAgB;AAClB;;AAEA;;EAEE,iBAAiB;AACnB;;AAEA;;;;EAIE,gBAAgB;EAChB,aAAa;AACf;;AAEA;EACE,oBAAoB;AACtB;;AAEA;EACE,gBAAgB;AAClB;;AAEA;EACE,iBAAiB;AACnB;;AAEA;EACE,UAAU;AACZ;;AAEA;EACE,cAAc;EACd,kBAAkB;EAClB,gBAAgB;EAChB,gBAAgB;EAChB,UAAU;AACZ;;AAEA;EACE,mBAAmB;EACnB,eAAe;AACjB;;AAEA;EACE,cAAc;EACd,cAAc;EACd,WAAW;AACb;;AAEA;EACE,gBAAgB;AAClB;;AAEA;;EAEE,yBAAyB;EACzB,iBAAiB;AACnB;;AAEA;EACE,sBAAsB;EACtB,6BAA6B;AAC/B;;AAEA;EACE,yBAAyB;AAC3B;;AAEA;EACE,sBAAsB;EACtB,uBAAuB;EACvB,eAAe;AACjB;;AAEA;EACE,kBAAkB;AACpB;;AAEA;EACE,mBAAmB;AACrB;;AAEA;EACE,oCAAoC;EACpC,kBAAkB;EAClB,cAAc;EACd,SAAS;EACT,kBAAkB;AACpB;;AAEA;EACE,iBAAiB;AACnB;;AAEA;EACE,uBAAuB;EACvB,SAAS;EACT,eAAe;EACf,SAAS;EACT,UAAU;EACV,gBAAgB;EAChB,kBAAkB;AACpB;;AAEA;EACE,mBAAmB;AACrB;;AAEA;EACE,gBAAgB;EAChB,kBAAkB;AACpB;;AAEA;;EAEE,yBAAyB;EACzB,kBAAkB;EAClB,cAAc;EACd,iBAAiB;EACjB,cAAc;EACd,aAAa;AACf;;AAEA;EACE,6BAA6B;EAC7B,SAAS;EACT,eAAe;EACf,oBAAoB;EACpB,SAAS;EACT,eAAe;EACf,iBAAiB;EACjB,UAAU;EACV,iBAAiB;AACnB;;AAEA;EACE,cAAc;EACd,qBAAqB;EACrB,4EAA4E;EAC5E,cAAc;AAChB;;AAEA;EACE,8BAA8B;EAC9B,+BAA+B;EAC/B,gBAAgB;EAChB,kBAAkB;AACpB;;AAEA;EACE,iBAAiB;EACjB,gBAAgB;AAClB;;AAEA;EACE,sBAAsB;EACtB,qBAAqB;EACrB,yBAAyB;EACzB,wBAAwB;EACxB,eAAe;EACf,4EAA4E;EAC5E,eAAe;EACf,iBAAiB;EACjB,eAAe;EACf,kBAAkB;EAClB,mBAAmB;EACnB,iBAAiB;EACjB,iBAAiB;EACjB,mBAAmB;EACnB,mBAAmB;EACnB,SAAS;AACX;;AAEA;EACE,wBAAwB;AAC1B;;AAEA;EACE,+BAA+B;AACjC;;AAEA;EACE,iBAAiB;EACjB,kBAAkB;EAClB,mBAAmB;EACnB,kBAAkB;EAClB,mBAAmB;AACrB;;AAEA;EACE,cAAc;EACd,4EAA4E;EAC5E,eAAe;EACf,iBAAiB;EACjB,gBAAgB;EAChB,iBAAiB;AACnB;;AAEA;;EAEE,mBAAmB;EACnB,eAAe;AACjB;;AAEA;EACE,yBAAyB;EACzB,yBAAyB;EACzB,4BAA4B;EAC5B,kBAAkB;EAClB,kCAAkC;EAClC,cAAc;EACd,qBAAqB;EACrB,0EAA0E;EAC1E,iBAAiB;EACjB,gBAAgB;EAChB,sBAAsB;AACxB;;AAEA;EACE,qBAAqB;EACrB,kBAAkB;EAClB,UAAU;AACZ;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,iBAAiB;EACjB,YAAY;AACd;;AAEA;EACE,iBAAiB;EACjB,YAAY;AACd;;AAEA;EACE,iBAAiB;EACjB,YAAY;AACd;;AAEA;EACE,qBAAqB;AACvB;;AAEA;EACE,eAAe;AACjB;;AAEA;EACE,2BAA2B;EAC3B,sBAAsB;AACxB;;AAEA;EACE,yBAAyB;AAC3B;;AAEA;EACE,yBAAyB;AAC3B;;AAEA;EACE,2BAA2B;AAC7B;;AAEA;EACE,2BAA2B;AAC7B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,6BAA6B;AAC/B;;AAEA;EACE,6BAA6B;AAC/B","sourceRoot":""} */
  </style>
  <style>
  /**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
	color: black;
	background: none;
	text-shadow: 0 1px white;
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	font-size: 1em;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
}

pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
	text-shadow: none;
	background: #b3d4fc;
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
	text-shadow: none;
	background: #b3d4fc;
}

@media print {
	code[class*="language-"],
	pre[class*="language-"] {
		text-shadow: none;
	}
}

/* Code blocks */
pre[class*="language-"] {
	padding: 1em;
	margin: .5em 0;
	overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
	background: #f5f2f0;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	padding: .1em;
	border-radius: .3em;
	white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: slategray;
}

.token.punctuation {
	color: #999;
}

.token.namespace {
	opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
	color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
	color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
	color: #9a6e3a;
	/* This background color was intended by the author of this theme. */
	background: hsla(0, 0%, 100%, .5);
}

.token.atrule,
.token.attr-value,
.token.keyword {
	color: #07a;
}

.token.function,
.token.class-name {
	color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
	color: #e90;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}

/*# sourceURL=webpack://./node_modules/prismjs/themes/prism.css */
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJzb3VyY2VzIjpbIndlYnBhY2s6Ly8uL25vZGVfbW9kdWxlcy9wcmlzbWpzL3RoZW1lcy9wcmlzbS5jc3MiXSwibmFtZXMiOltdLCJtYXBwaW5ncyI6IkFBQUE7Ozs7RUFJRTs7QUFFRjs7Q0FFQyxZQUFZO0NBQ1osZ0JBQWdCO0NBQ2hCLHdCQUF3QjtDQUN4QixzRUFBc0U7Q0FDdEUsY0FBYztDQUNkLGdCQUFnQjtDQUNoQixnQkFBZ0I7Q0FDaEIsb0JBQW9CO0NBQ3BCLGtCQUFrQjtDQUNsQixpQkFBaUI7Q0FDakIsZ0JBQWdCOztDQUVoQixnQkFBZ0I7Q0FDaEIsY0FBYztDQUNkLFdBQVc7O0NBRVgscUJBQXFCO0NBQ3JCLGtCQUFrQjtDQUNsQixpQkFBaUI7Q0FDakIsYUFBYTtBQUNkOztBQUVBOztDQUVDLGlCQUFpQjtDQUNqQixtQkFBbUI7QUFDcEI7O0FBRUE7O0NBRUMsaUJBQWlCO0NBQ2pCLG1CQUFtQjtBQUNwQjs7QUFFQTtDQUNDOztFQUVDLGlCQUFpQjtDQUNsQjtBQUNEOztBQUVBLGdCQUFnQjtBQUNoQjtDQUNDLFlBQVk7Q0FDWixjQUFjO0NBQ2QsY0FBYztBQUNmOztBQUVBOztDQUVDLG1CQUFtQjtBQUNwQjs7QUFFQSxnQkFBZ0I7QUFDaEI7Q0FDQyxhQUFhO0NBQ2IsbUJBQW1CO0NBQ25CLG1CQUFtQjtBQUNwQjs7QUFFQTs7OztDQUlDLGdCQUFnQjtBQUNqQjs7QUFFQTtDQUNDLFdBQVc7QUFDWjs7QUFFQTtDQUNDLFdBQVc7QUFDWjs7QUFFQTs7Ozs7OztDQU9DLFdBQVc7QUFDWjs7QUFFQTs7Ozs7O0NBTUMsV0FBVztBQUNaOztBQUVBOzs7OztDQUtDLGNBQWM7Q0FDZCxvRUFBb0U7Q0FDcEUsaUNBQWlDO0FBQ2xDOztBQUVBOzs7Q0FHQyxXQUFXO0FBQ1o7O0FBRUE7O0NBRUMsY0FBYztBQUNmOztBQUVBOzs7Q0FHQyxXQUFXO0FBQ1o7O0FBRUE7O0NBRUMsaUJBQWlCO0FBQ2xCO0FBQ0E7Q0FDQyxrQkFBa0I7QUFDbkI7O0FBRUE7Q0FDQyxZQUFZO0FBQ2IiLCJzb3VyY2VSb290IjoiIn0= */
  </style>
  <style>
  /* stylelint-disable font-family-no-missing-generic-family-keyword */
@font-face {
  font-family: 'KaTeX_AMS';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_AMS-Regular.73ea273a.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_AMS-Regular.d562e886.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_AMS-Regular.853be924.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Caligraphic';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Caligraphic-Bold.a1abf90d.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Caligraphic-Bold.d757c535.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Caligraphic-Bold.7489a2fb.ttf) format('truetype');
  font-weight: bold;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Caligraphic';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Caligraphic-Regular.d6484fce.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Caligraphic-Regular.db074fa2.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Caligraphic-Regular.7e873d38.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Fraktur';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Fraktur-Bold.931d67ea.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Fraktur-Bold.354501ba.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Fraktur-Bold.4c761b37.ttf) format('truetype');
  font-weight: bold;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Fraktur';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Fraktur-Regular.172d3529.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Fraktur-Regular.6fdf0ac5.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Fraktur-Regular.ed305b54.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Main';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-Bold.39890742.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-Bold.0c3b8929.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-Bold.8169508b.ttf) format('truetype');
  font-weight: bold;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Main';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-BoldItalic.20f389c4.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-BoldItalic.428978dc.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-BoldItalic.828abcb2.ttf) format('truetype');
  font-weight: bold;
  font-style: italic;
}
@font-face {
  font-family: 'KaTeX_Main';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-Italic.fe2176f7.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-Italic.fd947498.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-Italic.fa675e5e.ttf) format('truetype');
  font-weight: normal;
  font-style: italic;
}
@font-face {
  font-family: 'KaTeX_Main';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-Regular.f650f111.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-Regular.4f35fbcc.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Main-Regular.9eba1d77.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Math';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Math-BoldItalic.dcbcbd93.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Math-BoldItalic.3f07ed67.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Math-BoldItalic.bf2d440b.ttf) format('truetype');
  font-weight: bold;
  font-style: italic;
}
@font-face {
  font-family: 'KaTeX_Math';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Math-Italic.6d3d25f4.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Math-Italic.96759856.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Math-Italic.8a5f9363.ttf) format('truetype');
  font-weight: normal;
  font-style: italic;
}
@font-face {
  font-family: 'KaTeX_SansSerif';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_SansSerif-Bold.95591a92.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_SansSerif-Bold.b9cd458a.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_SansSerif-Bold.5b49f499.ttf) format('truetype');
  font-weight: bold;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_SansSerif';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_SansSerif-Italic.7d393d38.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_SansSerif-Italic.8d593cfa.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_SansSerif-Italic.b257a18c.ttf) format('truetype');
  font-weight: normal;
  font-style: italic;
}
@font-face {
  font-family: 'KaTeX_SansSerif';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_SansSerif-Regular.cd5e231e.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_SansSerif-Regular.02271ec5.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_SansSerif-Regular.2f7bc363.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Script';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Script-Regular.c81d1b2a.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Script-Regular.073b3402.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Script-Regular.fc9ba524.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Size1';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size1-Regular.6eec866c.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size1-Regular.0108e89c.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size1-Regular.6de7d4b5.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Size2';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size2-Regular.2960900c.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size2-Regular.3a99e70a.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size2-Regular.57f5c183.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Size3';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size3-Regular.e1951519.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size3-Regular.7947224e.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size3-Regular.8d6b6822.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Size4';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size4-Regular.e418bf25.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size4-Regular.aeffd802.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Size4-Regular.4ad7c7e8.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'KaTeX_Typewriter';
  src: url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Typewriter-Regular.c295e7f7.woff2) format('woff2'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Typewriter-Regular.4c6b94fd.woff) format('woff'), url(file:///snap/marktext/9/opt/MarkText/resources/app.asar/dist/electron/fonts/KaTeX_Typewriter-Regular.c5c02d76.ttf) format('truetype');
  font-weight: normal;
  font-style: normal;
}
.katex {
  font: normal 1.21em KaTeX_Main, Times New Roman, serif;
  line-height: 1.2;
  text-indent: 0;
  text-rendering: auto;
}
.katex * {
  -ms-high-contrast-adjust: none !important;
  border-color: currentColor;
}
.katex .katex-version::after {
  content: "0.15.2";
}
.katex .katex-mathml {
  /* Accessibility hack to only show to screen readers
         Found at: http://a11yproject.com/posts/how-to-hide-content/ */
  position: absolute;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 0;
  border: 0;
  height: 1px;
  width: 1px;
  overflow: hidden;
}
.katex .katex-html {
  /* \newline is an empty block at top level, between .base elements */
}
.katex .katex-html > .newline {
  display: block;
}
.katex .base {
  position: relative;
  display: inline-block;
  white-space: nowrap;
  width: -webkit-min-content;
  width: -moz-min-content;
  width: min-content;
}
.katex .strut {
  display: inline-block;
}
.katex .textbf {
  font-weight: bold;
}
.katex .textit {
  font-style: italic;
}
.katex .textrm {
  font-family: KaTeX_Main;
}
.katex .textsf {
  font-family: KaTeX_SansSerif;
}
.katex .texttt {
  font-family: KaTeX_Typewriter;
}
.katex .mathnormal {
  font-family: KaTeX_Math;
  font-style: italic;
}
.katex .mathit {
  font-family: KaTeX_Main;
  font-style: italic;
}
.katex .mathrm {
  font-style: normal;
}
.katex .mathbf {
  font-family: KaTeX_Main;
  font-weight: bold;
}
.katex .boldsymbol {
  font-family: KaTeX_Math;
  font-weight: bold;
  font-style: italic;
}
.katex .amsrm {
  font-family: KaTeX_AMS;
}
.katex .mathbb,
.katex .textbb {
  font-family: KaTeX_AMS;
}
.katex .mathcal {
  font-family: KaTeX_Caligraphic;
}
.katex .mathfrak,
.katex .textfrak {
  font-family: KaTeX_Fraktur;
}
.katex .mathtt {
  font-family: KaTeX_Typewriter;
}
.katex .mathscr,
.katex .textscr {
  font-family: KaTeX_Script;
}
.katex .mathsf,
.katex .textsf {
  font-family: KaTeX_SansSerif;
}
.katex .mathboldsf,
.katex .textboldsf {
  font-family: KaTeX_SansSerif;
  font-weight: bold;
}
.katex .mathitsf,
.katex .textitsf {
  font-family: KaTeX_SansSerif;
  font-style: italic;
}
.katex .mainrm {
  font-family: KaTeX_Main;
  font-style: normal;
}
.katex .vlist-t {
  display: inline-table;
  table-layout: fixed;
  border-collapse: collapse;
}
.katex .vlist-r {
  display: table-row;
}
.katex .vlist {
  display: table-cell;
  vertical-align: bottom;
  position: relative;
}
.katex .vlist > span {
  display: block;
  height: 0;
  position: relative;
}
.katex .vlist > span > span {
  display: inline-block;
}
.katex .vlist > span > .pstrut {
  overflow: hidden;
  width: 0;
}
.katex .vlist-t2 {
  margin-right: -2px;
}
.katex .vlist-s {
  display: table-cell;
  vertical-align: bottom;
  font-size: 1px;
  width: 2px;
  min-width: 2px;
}
.katex .vbox {
  display: inline-flex;
  flex-direction: column;
  align-items: baseline;
}
.katex .hbox {
  display: inline-flex;
  flex-direction: row;
  width: 100%;
}
.katex .thinbox {
  display: inline-flex;
  flex-direction: row;
  width: 0;
  max-width: 0;
}
.katex .msupsub {
  text-align: left;
}
.katex .mfrac > span > span {
  text-align: center;
}
.katex .mfrac .frac-line {
  display: inline-block;
  width: 100%;
  border-bottom-style: solid;
}
.katex .mfrac .frac-line,
.katex .overline .overline-line,
.katex .underline .underline-line,
.katex .hline,
.katex .hdashline,
.katex .rule {
  min-height: 1px;
}
.katex .mspace {
  display: inline-block;
}
.katex .llap,
.katex .rlap,
.katex .clap {
  width: 0;
  position: relative;
}
.katex .llap > .inner,
.katex .rlap > .inner,
.katex .clap > .inner {
  position: absolute;
}
.katex .llap > .fix,
.katex .rlap > .fix,
.katex .clap > .fix {
  display: inline-block;
}
.katex .llap > .inner {
  right: 0;
}
.katex .rlap > .inner,
.katex .clap > .inner {
  left: 0;
}
.katex .clap > .inner > span {
  margin-left: -50%;
  margin-right: 50%;
}
.katex .rule {
  display: inline-block;
  border: solid 0;
  position: relative;
}
.katex .overline .overline-line,
.katex .underline .underline-line,
.katex .hline {
  display: inline-block;
  width: 100%;
  border-bottom-style: solid;
}
.katex .hdashline {
  display: inline-block;
  width: 100%;
  border-bottom-style: dashed;
}
.katex .sqrt > .root {
  /* These values are taken from the definition of `\r@@t`,
             `\mkern 5mu` and `\mkern -10mu`. */
  margin-left: 0.27777778em;
  margin-right: -0.55555556em;
}
.katex .sizing.reset-size1.size1,
.katex .fontsize-ensurer.reset-size1.size1 {
  font-size: 1em;
}
.katex .sizing.reset-size1.size2,
.katex .fontsize-ensurer.reset-size1.size2 {
  font-size: 1.2em;
}
.katex .sizing.reset-size1.size3,
.katex .fontsize-ensurer.reset-size1.size3 {
  font-size: 1.4em;
}
.katex .sizing.reset-size1.size4,
.katex .fontsize-ensurer.reset-size1.size4 {
  font-size: 1.6em;
}
.katex .sizing.reset-size1.size5,
.katex .fontsize-ensurer.reset-size1.size5 {
  font-size: 1.8em;
}
.katex .sizing.reset-size1.size6,
.katex .fontsize-ensurer.reset-size1.size6 {
  font-size: 2em;
}
.katex .sizing.reset-size1.size7,
.katex .fontsize-ensurer.reset-size1.size7 {
  font-size: 2.4em;
}
.katex .sizing.reset-size1.size8,
.katex .fontsize-ensurer.reset-size1.size8 {
  font-size: 2.88em;
}
.katex .sizing.reset-size1.size9,
.katex .fontsize-ensurer.reset-size1.size9 {
  font-size: 3.456em;
}
.katex .sizing.reset-size1.size10,
.katex .fontsize-ensurer.reset-size1.size10 {
  font-size: 4.148em;
}
.katex .sizing.reset-size1.size11,
.katex .fontsize-ensurer.reset-size1.size11 {
  font-size: 4.976em;
}
.katex .sizing.reset-size2.size1,
.katex .fontsize-ensurer.reset-size2.size1 {
  font-size: 0.83333333em;
}
.katex .sizing.reset-size2.size2,
.katex .fontsize-ensurer.reset-size2.size2 {
  font-size: 1em;
}
.katex .sizing.reset-size2.size3,
.katex .fontsize-ensurer.reset-size2.size3 {
  font-size: 1.16666667em;
}
.katex .sizing.reset-size2.size4,
.katex .fontsize-ensurer.reset-size2.size4 {
  font-size: 1.33333333em;
}
.katex .sizing.reset-size2.size5,
.katex .fontsize-ensurer.reset-size2.size5 {
  font-size: 1.5em;
}
.katex .sizing.reset-size2.size6,
.katex .fontsize-ensurer.reset-size2.size6 {
  font-size: 1.66666667em;
}
.katex .sizing.reset-size2.size7,
.katex .fontsize-ensurer.reset-size2.size7 {
  font-size: 2em;
}
.katex .sizing.reset-size2.size8,
.katex .fontsize-ensurer.reset-size2.size8 {
  font-size: 2.4em;
}
.katex .sizing.reset-size2.size9,
.katex .fontsize-ensurer.reset-size2.size9 {
  font-size: 2.88em;
}
.katex .sizing.reset-size2.size10,
.katex .fontsize-ensurer.reset-size2.size10 {
  font-size: 3.45666667em;
}
.katex .sizing.reset-size2.size11,
.katex .fontsize-ensurer.reset-size2.size11 {
  font-size: 4.14666667em;
}
.katex .sizing.reset-size3.size1,
.katex .fontsize-ensurer.reset-size3.size1 {
  font-size: 0.71428571em;
}
.katex .sizing.reset-size3.size2,
.katex .fontsize-ensurer.reset-size3.size2 {
  font-size: 0.85714286em;
}
.katex .sizing.reset-size3.size3,
.katex .fontsize-ensurer.reset-size3.size3 {
  font-size: 1em;
}
.katex .sizing.reset-size3.size4,
.katex .fontsize-ensurer.reset-size3.size4 {
  font-size: 1.14285714em;
}
.katex .sizing.reset-size3.size5,
.katex .fontsize-ensurer.reset-size3.size5 {
  font-size: 1.28571429em;
}
.katex .sizing.reset-size3.size6,
.katex .fontsize-ensurer.reset-size3.size6 {
  font-size: 1.42857143em;
}
.katex .sizing.reset-size3.size7,
.katex .fontsize-ensurer.reset-size3.size7 {
  font-size: 1.71428571em;
}
.katex .sizing.reset-size3.size8,
.katex .fontsize-ensurer.reset-size3.size8 {
  font-size: 2.05714286em;
}
.katex .sizing.reset-size3.size9,
.katex .fontsize-ensurer.reset-size3.size9 {
  font-size: 2.46857143em;
}
.katex .sizing.reset-size3.size10,
.katex .fontsize-ensurer.reset-size3.size10 {
  font-size: 2.96285714em;
}
.katex .sizing.reset-size3.size11,
.katex .fontsize-ensurer.reset-size3.size11 {
  font-size: 3.55428571em;
}
.katex .sizing.reset-size4.size1,
.katex .fontsize-ensurer.reset-size4.size1 {
  font-size: 0.625em;
}
.katex .sizing.reset-size4.size2,
.katex .fontsize-ensurer.reset-size4.size2 {
  font-size: 0.75em;
}
.katex .sizing.reset-size4.size3,
.katex .fontsize-ensurer.reset-size4.size3 {
  font-size: 0.875em;
}
.katex .sizing.reset-size4.size4,
.katex .fontsize-ensurer.reset-size4.size4 {
  font-size: 1em;
}
.katex .sizing.reset-size4.size5,
.katex .fontsize-ensurer.reset-size4.size5 {
  font-size: 1.125em;
}
.katex .sizing.reset-size4.size6,
.katex .fontsize-ensurer.reset-size4.size6 {
  font-size: 1.25em;
}
.katex .sizing.reset-size4.size7,
.katex .fontsize-ensurer.reset-size4.size7 {
  font-size: 1.5em;
}
.katex .sizing.reset-size4.size8,
.katex .fontsize-ensurer.reset-size4.size8 {
  font-size: 1.8em;
}
.katex .sizing.reset-size4.size9,
.katex .fontsize-ensurer.reset-size4.size9 {
  font-size: 2.16em;
}
.katex .sizing.reset-size4.size10,
.katex .fontsize-ensurer.reset-size4.size10 {
  font-size: 2.5925em;
}
.katex .sizing.reset-size4.size11,
.katex .fontsize-ensurer.reset-size4.size11 {
  font-size: 3.11em;
}
.katex .sizing.reset-size5.size1,
.katex .fontsize-ensurer.reset-size5.size1 {
  font-size: 0.55555556em;
}
.katex .sizing.reset-size5.size2,
.katex .fontsize-ensurer.reset-size5.size2 {
  font-size: 0.66666667em;
}
.katex .sizing.reset-size5.size3,
.katex .fontsize-ensurer.reset-size5.size3 {
  font-size: 0.77777778em;
}
.katex .sizing.reset-size5.size4,
.katex .fontsize-ensurer.reset-size5.size4 {
  font-size: 0.88888889em;
}
.katex .sizing.reset-size5.size5,
.katex .fontsize-ensurer.reset-size5.size5 {
  font-size: 1em;
}
.katex .sizing.reset-size5.size6,
.katex .fontsize-ensurer.reset-size5.size6 {
  font-size: 1.11111111em;
}
.katex .sizing.reset-size5.size7,
.katex .fontsize-ensurer.reset-size5.size7 {
  font-size: 1.33333333em;
}
.katex .sizing.reset-size5.size8,
.katex .fontsize-ensurer.reset-size5.size8 {
  font-size: 1.6em;
}
.katex .sizing.reset-size5.size9,
.katex .fontsize-ensurer.reset-size5.size9 {
  font-size: 1.92em;
}
.katex .sizing.reset-size5.size10,
.katex .fontsize-ensurer.reset-size5.size10 {
  font-size: 2.30444444em;
}
.katex .sizing.reset-size5.size11,
.katex .fontsize-ensurer.reset-size5.size11 {
  font-size: 2.76444444em;
}
.katex .sizing.reset-size6.size1,
.katex .fontsize-ensurer.reset-size6.size1 {
  font-size: 0.5em;
}
.katex .sizing.reset-size6.size2,
.katex .fontsize-ensurer.reset-size6.size2 {
  font-size: 0.6em;
}
.katex .sizing.reset-size6.size3,
.katex .fontsize-ensurer.reset-size6.size3 {
  font-size: 0.7em;
}
.katex .sizing.reset-size6.size4,
.katex .fontsize-ensurer.reset-size6.size4 {
  font-size: 0.8em;
}
.katex .sizing.reset-size6.size5,
.katex .fontsize-ensurer.reset-size6.size5 {
  font-size: 0.9em;
}
.katex .sizing.reset-size6.size6,
.katex .fontsize-ensurer.reset-size6.size6 {
  font-size: 1em;
}
.katex .sizing.reset-size6.size7,
.katex .fontsize-ensurer.reset-size6.size7 {
  font-size: 1.2em;
}
.katex .sizing.reset-size6.size8,
.katex .fontsize-ensurer.reset-size6.size8 {
  font-size: 1.44em;
}
.katex .sizing.reset-size6.size9,
.katex .fontsize-ensurer.reset-size6.size9 {
  font-size: 1.728em;
}
.katex .sizing.reset-size6.size10,
.katex .fontsize-ensurer.reset-size6.size10 {
  font-size: 2.074em;
}
.katex .sizing.reset-size6.size11,
.katex .fontsize-ensurer.reset-size6.size11 {
  font-size: 2.488em;
}
.katex .sizing.reset-size7.size1,
.katex .fontsize-ensurer.reset-size7.size1 {
  font-size: 0.41666667em;
}
.katex .sizing.reset-size7.size2,
.katex .fontsize-ensurer.reset-size7.size2 {
  font-size: 0.5em;
}
.katex .sizing.reset-size7.size3,
.katex .fontsize-ensurer.reset-size7.size3 {
  font-size: 0.58333333em;
}
.katex .sizing.reset-size7.size4,
.katex .fontsize-ensurer.reset-size7.size4 {
  font-size: 0.66666667em;
}
.katex .sizing.reset-size7.size5,
.katex .fontsize-ensurer.reset-size7.size5 {
  font-size: 0.75em;
}
.katex .sizing.reset-size7.size6,
.katex .fontsize-ensurer.reset-size7.size6 {
  font-size: 0.83333333em;
}
.katex .sizing.reset-size7.size7,
.katex .fontsize-ensurer.reset-size7.size7 {
  font-size: 1em;
}
.katex .sizing.reset-size7.size8,
.katex .fontsize-ensurer.reset-size7.size8 {
  font-size: 1.2em;
}
.katex .sizing.reset-size7.size9,
.katex .fontsize-ensurer.reset-size7.size9 {
  font-size: 1.44em;
}
.katex .sizing.reset-size7.size10,
.katex .fontsize-ensurer.reset-size7.size10 {
  font-size: 1.72833333em;
}
.katex .sizing.reset-size7.size11,
.katex .fontsize-ensurer.reset-size7.size11 {
  font-size: 2.07333333em;
}
.katex .sizing.reset-size8.size1,
.katex .fontsize-ensurer.reset-size8.size1 {
  font-size: 0.34722222em;
}
.katex .sizing.reset-size8.size2,
.katex .fontsize-ensurer.reset-size8.size2 {
  font-size: 0.41666667em;
}
.katex .sizing.reset-size8.size3,
.katex .fontsize-ensurer.reset-size8.size3 {
  font-size: 0.48611111em;
}
.katex .sizing.reset-size8.size4,
.katex .fontsize-ensurer.reset-size8.size4 {
  font-size: 0.55555556em;
}
.katex .sizing.reset-size8.size5,
.katex .fontsize-ensurer.reset-size8.size5 {
  font-size: 0.625em;
}
.katex .sizing.reset-size8.size6,
.katex .fontsize-ensurer.reset-size8.size6 {
  font-size: 0.69444444em;
}
.katex .sizing.reset-size8.size7,
.katex .fontsize-ensurer.reset-size8.size7 {
  font-size: 0.83333333em;
}
.katex .sizing.reset-size8.size8,
.katex .fontsize-ensurer.reset-size8.size8 {
  font-size: 1em;
}
.katex .sizing.reset-size8.size9,
.katex .fontsize-ensurer.reset-size8.size9 {
  font-size: 1.2em;
}
.katex .sizing.reset-size8.size10,
.katex .fontsize-ensurer.reset-size8.size10 {
  font-size: 1.44027778em;
}
.katex .sizing.reset-size8.size11,
.katex .fontsize-ensurer.reset-size8.size11 {
  font-size: 1.72777778em;
}
.katex .sizing.reset-size9.size1,
.katex .fontsize-ensurer.reset-size9.size1 {
  font-size: 0.28935185em;
}
.katex .sizing.reset-size9.size2,
.katex .fontsize-ensurer.reset-size9.size2 {
  font-size: 0.34722222em;
}
.katex .sizing.reset-size9.size3,
.katex .fontsize-ensurer.reset-size9.size3 {
  font-size: 0.40509259em;
}
.katex .sizing.reset-size9.size4,
.katex .fontsize-ensurer.reset-size9.size4 {
  font-size: 0.46296296em;
}
.katex .sizing.reset-size9.size5,
.katex .fontsize-ensurer.reset-size9.size5 {
  font-size: 0.52083333em;
}
.katex .sizing.reset-size9.size6,
.katex .fontsize-ensurer.reset-size9.size6 {
  font-size: 0.5787037em;
}
.katex .sizing.reset-size9.size7,
.katex .fontsize-ensurer.reset-size9.size7 {
  font-size: 0.69444444em;
}
.katex .sizing.reset-size9.size8,
.katex .fontsize-ensurer.reset-size9.size8 {
  font-size: 0.83333333em;
}
.katex .sizing.reset-size9.size9,
.katex .fontsize-ensurer.reset-size9.size9 {
  font-size: 1em;
}
.katex .sizing.reset-size9.size10,
.katex .fontsize-ensurer.reset-size9.size10 {
  font-size: 1.20023148em;
}
.katex .sizing.reset-size9.size11,
.katex .fontsize-ensurer.reset-size9.size11 {
  font-size: 1.43981481em;
}
.katex .sizing.reset-size10.size1,
.katex .fontsize-ensurer.reset-size10.size1 {
  font-size: 0.24108004em;
}
.katex .sizing.reset-size10.size2,
.katex .fontsize-ensurer.reset-size10.size2 {
  font-size: 0.28929605em;
}
.katex .sizing.reset-size10.size3,
.katex .fontsize-ensurer.reset-size10.size3 {
  font-size: 0.33751205em;
}
.katex .sizing.reset-size10.size4,
.katex .fontsize-ensurer.reset-size10.size4 {
  font-size: 0.38572806em;
}
.katex .sizing.reset-size10.size5,
.katex .fontsize-ensurer.reset-size10.size5 {
  font-size: 0.43394407em;
}
.katex .sizing.reset-size10.size6,
.katex .fontsize-ensurer.reset-size10.size6 {
  font-size: 0.48216008em;
}
.katex .sizing.reset-size10.size7,
.katex .fontsize-ensurer.reset-size10.size7 {
  font-size: 0.57859209em;
}
.katex .sizing.reset-size10.size8,
.katex .fontsize-ensurer.reset-size10.size8 {
  font-size: 0.69431051em;
}
.katex .sizing.reset-size10.size9,
.katex .fontsize-ensurer.reset-size10.size9 {
  font-size: 0.83317261em;
}
.katex .sizing.reset-size10.size10,
.katex .fontsize-ensurer.reset-size10.size10 {
  font-size: 1em;
}
.katex .sizing.reset-size10.size11,
.katex .fontsize-ensurer.reset-size10.size11 {
  font-size: 1.19961427em;
}
.katex .sizing.reset-size11.size1,
.katex .fontsize-ensurer.reset-size11.size1 {
  font-size: 0.20096463em;
}
.katex .sizing.reset-size11.size2,
.katex .fontsize-ensurer.reset-size11.size2 {
  font-size: 0.24115756em;
}
.katex .sizing.reset-size11.size3,
.katex .fontsize-ensurer.reset-size11.size3 {
  font-size: 0.28135048em;
}
.katex .sizing.reset-size11.size4,
.katex .fontsize-ensurer.reset-size11.size4 {
  font-size: 0.32154341em;
}
.katex .sizing.reset-size11.size5,
.katex .fontsize-ensurer.reset-size11.size5 {
  font-size: 0.36173633em;
}
.katex .sizing.reset-size11.size6,
.katex .fontsize-ensurer.reset-size11.size6 {
  font-size: 0.40192926em;
}
.katex .sizing.reset-size11.size7,
.katex .fontsize-ensurer.reset-size11.size7 {
  font-size: 0.48231511em;
}
.katex .sizing.reset-size11.size8,
.katex .fontsize-ensurer.reset-size11.size8 {
  font-size: 0.57877814em;
}
.katex .sizing.reset-size11.size9,
.katex .fontsize-ensurer.reset-size11.size9 {
  font-size: 0.69453376em;
}
.katex .sizing.reset-size11.size10,
.katex .fontsize-ensurer.reset-size11.size10 {
  font-size: 0.83360129em;
}
.katex .sizing.reset-size11.size11,
.katex .fontsize-ensurer.reset-size11.size11 {
  font-size: 1em;
}
.katex .delimsizing.size1 {
  font-family: KaTeX_Size1;
}
.katex .delimsizing.size2 {
  font-family: KaTeX_Size2;
}
.katex .delimsizing.size3 {
  font-family: KaTeX_Size3;
}
.katex .delimsizing.size4 {
  font-family: KaTeX_Size4;
}
.katex .delimsizing.mult .delim-size1 > span {
  font-family: KaTeX_Size1;
}
.katex .delimsizing.mult .delim-size4 > span {
  font-family: KaTeX_Size4;
}
.katex .nulldelimiter {
  display: inline-block;
  width: 0.12em;
}
.katex .delimcenter {
  position: relative;
}
.katex .op-symbol {
  position: relative;
}
.katex .op-symbol.small-op {
  font-family: KaTeX_Size1;
}
.katex .op-symbol.large-op {
  font-family: KaTeX_Size2;
}
.katex .op-limits > .vlist-t {
  text-align: center;
}
.katex .accent > .vlist-t {
  text-align: center;
}
.katex .accent .accent-body {
  position: relative;
}
.katex .accent .accent-body:not(.accent-full) {
  width: 0;
}
.katex .overlay {
  display: block;
}
.katex .mtable .vertical-separator {
  display: inline-block;
  min-width: 1px;
}
.katex .mtable .arraycolsep {
  display: inline-block;
}
.katex .mtable .col-align-c > .vlist-t {
  text-align: center;
}
.katex .mtable .col-align-l > .vlist-t {
  text-align: left;
}
.katex .mtable .col-align-r > .vlist-t {
  text-align: right;
}
.katex .svg-align {
  text-align: left;
}
.katex svg {
  display: block;
  position: absolute;
  width: 100%;
  height: inherit;
  fill: currentColor;
  stroke: currentColor;
  fill-rule: nonzero;
  fill-opacity: 1;
  stroke-width: 1;
  stroke-linecap: butt;
  stroke-linejoin: miter;
  stroke-miterlimit: 4;
  stroke-dasharray: none;
  stroke-dashoffset: 0;
  stroke-opacity: 1;
}
.katex svg path {
  stroke: none;
}
.katex img {
  border-style: none;
  min-width: 0;
  min-height: 0;
  max-width: none;
  max-height: none;
}
.katex .stretchy {
  width: 100%;
  display: block;
  position: relative;
  overflow: hidden;
}
.katex .stretchy::before,
.katex .stretchy::after {
  content: "";
}
.katex .hide-tail {
  width: 100%;
  position: relative;
  overflow: hidden;
}
.katex .halfarrow-left {
  position: absolute;
  left: 0;
  width: 50.2%;
  overflow: hidden;
}
.katex .halfarrow-right {
  position: absolute;
  right: 0;
  width: 50.2%;
  overflow: hidden;
}
.katex .brace-left {
  position: absolute;
  left: 0;
  width: 25.1%;
  overflow: hidden;
}
.katex .brace-center {
  position: absolute;
  left: 25%;
  width: 50%;
  overflow: hidden;
}
.katex .brace-right {
  position: absolute;
  right: 0;
  width: 25.1%;
  overflow: hidden;
}
.katex .x-arrow-pad {
  padding: 0 0.5em;
}
.katex .cd-arrow-pad {
  padding: 0 0.55556em 0 0.27778em;
}
.katex .x-arrow,
.katex .mover,
.katex .munder {
  text-align: center;
}
.katex .boxpad {
  padding: 0 0.3em;
}
.katex .fbox,
.katex .fcolorbox {
  box-sizing: border-box;
  border: 0.04em solid;
}
.katex .cancel-pad {
  padding: 0 0.2em;
}
.katex .cancel-lap {
  margin-left: -0.2em;
  margin-right: -0.2em;
}
.katex .sout {
  border-bottom-style: solid;
  border-bottom-width: 0.08em;
}
.katex .angl {
  box-sizing: border-box;
  border-top: 0.049em solid;
  border-right: 0.049em solid;
  margin-right: 0.03889em;
}
.katex .anglpad {
  padding: 0 0.03889em;
}
.katex .eqn-num::before {
  counter-increment: katexEqnNo;
  content: "(" counter(katexEqnNo) ")";
}
.katex .mml-eqn-num::before {
  counter-increment: mmlEqnNo;
  content: "(" counter(mmlEqnNo) ")";
}
.katex .mtr-glue {
  width: 50%;
}
.katex .cd-vert-arrow {
  display: inline-block;
  position: relative;
}
.katex .cd-label-left {
  display: inline-block;
  position: absolute;
  right: calc(50% + 0.3em);
  text-align: left;
}
.katex .cd-label-right {
  display: inline-block;
  position: absolute;
  left: calc(50% + 0.3em);
  text-align: right;
}
.katex-display {
  display: block;
  margin: 1em 0;
  text-align: center;
}
.katex-display > .katex {
  display: block;
  text-align: center;
  white-space: nowrap;
}
.katex-display > .katex > .katex-html {
  display: block;
  position: relative;
}
.katex-display > .katex > .katex-html > .tag {
  position: absolute;
  right: 0;
}
.katex-display.leqno > .katex > .katex-html > .tag {
  left: 0;
  right: auto;
}
.katex-display.fleqn > .katex {
  text-align: left;
  padding-left: 2em;
}
body {
  counter-reset: katexEqnNo mmlEqnNo;
}


/*# sourceURL=webpack://./node_modules/katex/dist/katex.css */
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,{"version":3,"sources":["webpack://./node_modules/katex/dist/katex.css"],"names":[],"mappings":"AAAA,oEAAoE;AACpE;EACE,wBAAwB;EACxB,gLAA8J;EAC9J,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,gCAAgC;EAChC,gLAA6K;EAC7K,iBAAiB;EACjB,kBAAkB;AACpB;AACA;EACE,gCAAgC;EAChC,gLAAsL;EACtL,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,4BAA4B;EAC5B,kLAAiK;EACjK,iBAAiB;EACjB,kBAAkB;AACpB;AACA;EACE,4BAA4B;EAC5B,mLAA0K;EAC1K,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,yBAAyB;EACzB,mLAAwJ;EACxJ,iBAAiB;EACjB,kBAAkB;AACpB;AACA;EACE,yBAAyB;EACzB,mLAA0K;EAC1K,iBAAiB;EACjB,kBAAkB;AACpB;AACA;EACE,yBAAyB;EACzB,mLAA8J;EAC9J,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,yBAAyB;EACzB,mLAAiK;EACjK,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,yBAAyB;EACzB,mLAA0K;EAC1K,iBAAiB;EACjB,kBAAkB;AACpB;AACA;EACE,yBAAyB;EACzB,mLAA8J;EAC9J,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,8BAA8B;EAC9B,mLAAuK;EACvK,iBAAiB;EACjB,kBAAkB;AACpB;AACA;EACE,8BAA8B;EAC9B,mLAA6K;EAC7K,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,8BAA8B;EAC9B,mLAAgL;EAChL,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,2BAA2B;EAC3B,mLAAuK;EACvK,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,0BAA0B;EAC1B,mLAAoK;EACpK,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,0BAA0B;EAC1B,mLAAoK;EACpK,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,0BAA0B;EAC1B,mLAAoK;EACpK,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,0BAA0B;EAC1B,mLAAoK;EACpK,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,+BAA+B;EAC/B,mLAAmL;EACnL,mBAAmB;EACnB,kBAAkB;AACpB;AACA;EACE,sDAAsD;EACtD,gBAAgB;EAChB,cAAc;EACd,oBAAoB;AACtB;AACA;EACE,yCAAyC;EACzC,0BAA0B;AAC5B;AACA;EACE,iBAAiB;AACnB;AACA;EACE;sEACoE;EACpE,kBAAkB;EAClB,8BAA8B;EAC9B,UAAU;EACV,SAAS;EACT,WAAW;EACX,UAAU;EACV,gBAAgB;AAClB;AACA;EACE,oEAAoE;AACtE;AACA;EACE,cAAc;AAChB;AACA;EACE,kBAAkB;EAClB,qBAAqB;EACrB,mBAAmB;EACnB,0BAA0B;EAC1B,uBAAuB;EACvB,kBAAkB;AACpB;AACA;EACE,qBAAqB;AACvB;AACA;EACE,iBAAiB;AACnB;AACA;EACE,kBAAkB;AACpB;AACA;EACE,uBAAuB;AACzB;AACA;EACE,4BAA4B;AAC9B;AACA;EACE,6BAA6B;AAC/B;AACA;EACE,uBAAuB;EACvB,kBAAkB;AACpB;AACA;EACE,uBAAuB;EACvB,kBAAkB;AACpB;AACA;EACE,kBAAkB;AACpB;AACA;EACE,uBAAuB;EACvB,iBAAiB;AACnB;AACA;EACE,uBAAuB;EACvB,iBAAiB;EACjB,kBAAkB;AACpB;AACA;EACE,sBAAsB;AACxB;AACA;;EAEE,sBAAsB;AACxB;AACA;EACE,8BAA8B;AAChC;AACA;;EAEE,0BAA0B;AAC5B;AACA;EACE,6BAA6B;AAC/B;AACA;;EAEE,yBAAyB;AAC3B;AACA;;EAEE,4BAA4B;AAC9B;AACA;;EAEE,4BAA4B;EAC5B,iBAAiB;AACnB;AACA;;EAEE,4BAA4B;EAC5B,kBAAkB;AACpB;AACA;EACE,uBAAuB;EACvB,kBAAkB;AACpB;AACA;EACE,qBAAqB;EACrB,mBAAmB;EACnB,yBAAyB;AAC3B;AACA;EACE,kBAAkB;AACpB;AACA;EACE,mBAAmB;EACnB,sBAAsB;EACtB,kBAAkB;AACpB;AACA;EACE,cAAc;EACd,SAAS;EACT,kBAAkB;AACpB;AACA;EACE,qBAAqB;AACvB;AACA;EACE,gBAAgB;EAChB,QAAQ;AACV;AACA;EACE,kBAAkB;AACpB;AACA;EACE,mBAAmB;EACnB,sBAAsB;EACtB,cAAc;EACd,UAAU;EACV,cAAc;AAChB;AACA;EACE,oBAAoB;EACpB,sBAAsB;EACtB,qBAAqB;AACvB;AACA;EACE,oBAAoB;EACpB,mBAAmB;EACnB,WAAW;AACb;AACA;EACE,oBAAoB;EACpB,mBAAmB;EACnB,QAAQ;EACR,YAAY;AACd;AACA;EACE,gBAAgB;AAClB;AACA;EACE,kBAAkB;AACpB;AACA;EACE,qBAAqB;EACrB,WAAW;EACX,0BAA0B;AAC5B;AACA;;;;;;EAME,eAAe;AACjB;AACA;EACE,qBAAqB;AACvB;AACA;;;EAGE,QAAQ;EACR,kBAAkB;AACpB;AACA;;;EAGE,kBAAkB;AACpB;AACA;;;EAGE,qBAAqB;AACvB;AACA;EACE,QAAQ;AACV;AACA;;EAEE,OAAO;AACT;AACA;EACE,iBAAiB;EACjB,iBAAiB;AACnB;AACA;EACE,qBAAqB;EACrB,eAAe;EACf,kBAAkB;AACpB;AACA;;;EAGE,qBAAqB;EACrB,WAAW;EACX,0BAA0B;AAC5B;AACA;EACE,qBAAqB;EACrB,WAAW;EACX,2BAA2B;AAC7B;AACA;EACE;+CAC6C;EAC7C,yBAAyB;EACzB,2BAA2B;AAC7B;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,iBAAiB;AACnB;AACA;;EAEE,kBAAkB;AACpB;AACA;;EAEE,kBAAkB;AACpB;AACA;;EAEE,kBAAkB;AACpB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,iBAAiB;AACnB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,kBAAkB;AACpB;AACA;;EAEE,iBAAiB;AACnB;AACA;;EAEE,kBAAkB;AACpB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,kBAAkB;AACpB;AACA;;EAEE,iBAAiB;AACnB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,iBAAiB;AACnB;AACA;;EAEE,mBAAmB;AACrB;AACA;;EAEE,iBAAiB;AACnB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,iBAAiB;AACnB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,iBAAiB;AACnB;AACA;;EAEE,kBAAkB;AACpB;AACA;;EAEE,kBAAkB;AACpB;AACA;;EAEE,kBAAkB;AACpB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,iBAAiB;AACnB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,iBAAiB;AACnB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,kBAAkB;AACpB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,gBAAgB;AAClB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,sBAAsB;AACxB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,cAAc;AAChB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,uBAAuB;AACzB;AACA;;EAEE,cAAc;AAChB;AACA;EACE,wBAAwB;AAC1B;AACA;EACE,wBAAwB;AAC1B;AACA;EACE,wBAAwB;AAC1B;AACA;EACE,wBAAwB;AAC1B;AACA;EACE,wBAAwB;AAC1B;AACA;EACE,wBAAwB;AAC1B;AACA;EACE,qBAAqB;EACrB,aAAa;AACf;AACA;EACE,kBAAkB;AACpB;AACA;EACE,kBAAkB;AACpB;AACA;EACE,wBAAwB;AAC1B;AACA;EACE,wBAAwB;AAC1B;AACA;EACE,kBAAkB;AACpB;AACA;EACE,kBAAkB;AACpB;AACA;EACE,kBAAkB;AACpB;AACA;EACE,QAAQ;AACV;AACA;EACE,cAAc;AAChB;AACA;EACE,qBAAqB;EACrB,cAAc;AAChB;AACA;EACE,qBAAqB;AACvB;AACA;EACE,kBAAkB;AACpB;AACA;EACE,gBAAgB;AAClB;AACA;EACE,iBAAiB;AACnB;AACA;EACE,gBAAgB;AAClB;AACA;EACE,cAAc;EACd,kBAAkB;EAClB,WAAW;EACX,eAAe;EACf,kBAAkB;EAClB,oBAAoB;EACpB,kBAAkB;EAClB,eAAe;EACf,eAAe;EACf,oBAAoB;EACpB,sBAAsB;EACtB,oBAAoB;EACpB,sBAAsB;EACtB,oBAAoB;EACpB,iBAAiB;AACnB;AACA;EACE,YAAY;AACd;AACA;EACE,kBAAkB;EAClB,YAAY;EACZ,aAAa;EACb,eAAe;EACf,gBAAgB;AAClB;AACA;EACE,WAAW;EACX,cAAc;EACd,kBAAkB;EAClB,gBAAgB;AAClB;AACA;;EAEE,WAAW;AACb;AACA;EACE,WAAW;EACX,kBAAkB;EAClB,gBAAgB;AAClB;AACA;EACE,kBAAkB;EAClB,OAAO;EACP,YAAY;EACZ,gBAAgB;AAClB;AACA;EACE,kBAAkB;EAClB,QAAQ;EACR,YAAY;EACZ,gBAAgB;AAClB;AACA;EACE,kBAAkB;EAClB,OAAO;EACP,YAAY;EACZ,gBAAgB;AAClB;AACA;EACE,kBAAkB;EAClB,SAAS;EACT,UAAU;EACV,gBAAgB;AAClB;AACA;EACE,kBAAkB;EAClB,QAAQ;EACR,YAAY;EACZ,gBAAgB;AAClB;AACA;EACE,gBAAgB;AAClB;AACA;EACE,gCAAgC;AAClC;AACA;;;EAGE,kBAAkB;AACpB;AACA;EACE,gBAAgB;AAClB;AACA;;EAEE,sBAAsB;EACtB,oBAAoB;AACtB;AACA;EACE,gBAAgB;AAClB;AACA;EACE,mBAAmB;EACnB,oBAAoB;AACtB;AACA;EACE,0BAA0B;EAC1B,2BAA2B;AAC7B;AACA;EACE,sBAAsB;EACtB,yBAAyB;EACzB,2BAA2B;EAC3B,uBAAuB;AACzB;AACA;EACE,oBAAoB;AACtB;AACA;EACE,6BAA6B;EAC7B,oCAAoC;AACtC;AACA;EACE,2BAA2B;EAC3B,kCAAkC;AACpC;AACA;EACE,UAAU;AACZ;AACA;EACE,qBAAqB;EACrB,kBAAkB;AACpB;AACA;EACE,qBAAqB;EACrB,kBAAkB;EAClB,wBAAwB;EACxB,gBAAgB;AAClB;AACA;EACE,qBAAqB;EACrB,kBAAkB;EAClB,uBAAuB;EACvB,iBAAiB;AACnB;AACA;EACE,cAAc;EACd,aAAa;EACb,kBAAkB;AACpB;AACA;EACE,cAAc;EACd,kBAAkB;EAClB,mBAAmB;AACrB;AACA;EACE,cAAc;EACd,kBAAkB;AACpB;AACA;EACE,kBAAkB;EAClB,QAAQ;AACV;AACA;EACE,OAAO;EACP,WAAW;AACb;AACA;EACE,gBAAgB;EAChB,iBAAiB;AACnB;AACA;EACE,kCAAkC;AACpC","sourceRoot":""} */
  </style>
  <style>
    .markdown-body {
      font-family: -apple-system,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;
      box-sizing: border-box;
      min-width: 200px;
      max-width: 980px;
      margin: 0 auto;
      padding: 45px;
    }

    @media not print {
      .markdown-body {
        padding: 45px;
      }

      @media (max-width: 767px) {
        .markdown-body {
          padding: 15px;
        }
      }
    }

    .hf-container {
      color: #24292e;
      line-height: 1.3;
    }

    .markdown-body .highlight pre,
    .markdown-body pre {
      white-space: pre-wrap;
    }
    .markdown-body table {
      display: table;
    }
    .markdown-body img[data-align="center"] {
      display: block;
      margin: 0 auto;
    }
    .markdown-body img[data-align="right"] {
      display: block;
      margin: 0 0 0 auto;
    }
    .markdown-body li.task-list-item {
      list-style-type: none;
    }
    .markdown-body li > [type=checkbox] {
      margin: 0 0 0 -1.3em;
    }
    .markdown-body input[type="checkbox"] ~ p {
      margin-top: 0;
      display: inline-block;
    }
    .markdown-body ol ol,
    .markdown-body ul ol {
      list-style-type: decimal;
    }
    .markdown-body ol ol ol,
    .markdown-body ol ul ol,
    .markdown-body ul ol ol,
    .markdown-body ul ul ol {
      list-style-type: decimal;
    }
  </style>
  <style>.markdown-body a.footnote-ref {
  text-decoration: none;
}

.footnotes {
  font-size: .85em;
  opacity: .8;
}

.footnotes li[role="doc-endnote"] {
  position: relative;
}

.footnotes .footnote-back {
  position: absolute;
  font-family: initial;
  top: .2em;
  right: 1em;
  text-decoration: none;
}

.inline-math.invalid,
.multiple-math.invalid {
  color: rgb(255, 105, 105);
}

.toc-container {
  width: 100%;
}

.toc-container .toc-title {
  font-weight: 700;
  font-size: 1.2em;
  margin-bottom: 0;
}

.toc-container li,
.toc-container ul,
.toc-container ul li {
  list-style: none !important;
}

.toc-container > ul {
  padding-left: 0;
}

.toc-container ul li span {
  display : flex;
}

.toc-container ul li span a {
  color: inherit;
  text-decoration: none;
}
.toc-container ul li span a:hover {
  color: inherit;
  text-decoration: none;
}

.toc-container ul li span span.dots {
  flex: 1;
  height: 0.65em;
  margin: 0 10px;
  border-bottom: 2px dotted black;
}

/*# sourceURL=webpack://./src/muya/lib/assets/styles/exportStyle.css */
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJzb3VyY2VzIjpbIndlYnBhY2s6Ly8uL3NyYy9tdXlhL2xpYi9hc3NldHMvc3R5bGVzL2V4cG9ydFN0eWxlLmNzcyJdLCJuYW1lcyI6W10sIm1hcHBpbmdzIjoiQUFBQTtFQUNFLHFCQUFxQjtBQUN2Qjs7QUFFQTtFQUNFLGdCQUFnQjtFQUNoQixXQUFXO0FBQ2I7O0FBRUE7RUFDRSxrQkFBa0I7QUFDcEI7O0FBRUE7RUFDRSxrQkFBa0I7RUFDbEIsb0JBQW9CO0VBQ3BCLFNBQVM7RUFDVCxVQUFVO0VBQ1YscUJBQXFCO0FBQ3ZCOztBQUVBOztFQUVFLHlCQUF5QjtBQUMzQjs7QUFFQTtFQUNFLFdBQVc7QUFDYjs7QUFFQTtFQUNFLGdCQUFnQjtFQUNoQixnQkFBZ0I7RUFDaEIsZ0JBQWdCO0FBQ2xCOztBQUVBOzs7RUFHRSwyQkFBMkI7QUFDN0I7O0FBRUE7RUFDRSxlQUFlO0FBQ2pCOztBQUVBO0VBQ0UsY0FBYztBQUNoQjs7QUFFQTtFQUNFLGNBQWM7RUFDZCxxQkFBcUI7QUFDdkI7QUFDQTtFQUNFLGNBQWM7RUFDZCxxQkFBcUI7QUFDdkI7O0FBRUE7RUFDRSxPQUFPO0VBQ1AsY0FBYztFQUNkLGNBQWM7RUFDZCwrQkFBK0I7QUFDakMiLCJzb3VyY2VSb290IjoiIn0= */</style>
  <style>.markdown-body{}pre.front-matter{display:none!important;}</style>
</head>
<body>
  <article class="markdown-body"><h1 class="atx" id="my-cheat-sheet-for-mpi-gpu-apptainer-and-hpc">My cheat sheet for MPI, GPU, Apptainer, and HPC</h1>
<p>mgah.md  D. Candela   4/7/25</p>
<ul>
<li><p><a href="#intro">Introduction</a>  </p>
<ul>
<li><a href="#what-is">What is this?</a></li>
<li><a href="#parcomp-python">Parallel computing in Python</a></li>
<li><a href="#hardware">Hardware used</a><ul>
<li><a href="#pcs">PCs</a></li>
<li><a href="#gpus">GPUs</a></li>
<li><a href="#unity-intro">Unity HPC cluster</a></li>
</ul>
</li>
<li><a href="#pip-conda-apt">Pip, Conda, and APT</a></li>
<li><a href="#envs-testcode">Conda environments and test code used in this document</a></li>
<li><a href="#local-package">Installing a local package</a></li>
<li><a href="#multiple-cores">Parallel execution on multiple cores</a></li>
</ul>
</li>
<li><p><a href="#on-linux-pc">Part 1: MPI, GPU, and Apptainer on a Linux PC</a></p>
<ul>
<li><a href="#mpi-pc">MPI on a Linux PC</a><ul>
<li><a href="#why-mpi-pc">Why do it</a>    </li>
<li><a href="#install-openmpi-pc">Installing OpenMPI and <code>mpi4py</code> on a Linux PC</a></li>
<li><a href="#mpi-testprogs">Simple MPI test programs: <code>mpi_hw.py</code>  and <code>osu_bw.py</code></a></li>
<li><a href="#mpi-dem21">More elaborate MPI programs using the <code>dem21</code> package</a></li>
<li><a href="#multithread-mpi">Hyperthreading and NumPy multithreading with MPI</a></li>
</ul>
</li>
<li><a href="#gpu-pc">Using an NVIDIA GPU on a Linux PC</a><ul>
<li><a href="#why-gpu-pc">Why do it</a></li>
<li><a href="#non-nvidia">Non-NVIDIA GPUs</a></li>
<li><a href="#nvidia-drivers">Installing NVIDIA drivers</a></li>
<li><a href="#pytorch-cupy">Installing CUDA-aware Python packages: PyTorch, CuPy...</a></li>
<li><a href="#gpu-list">A few of NVDIA's many GPUS, with test results</a></li>
</ul>
</li>
<li><a href="#apptainer-pc">Using Apptainer on a Linux PC</a><ul>
<li><a href="#why-apptainer-pc">Why do it</a></li>
<li><a href="#apptainer-history">Apptainer history</a></li>
<li><a href="#install-apptainer">Installing Apptainer</a></li>
<li><a href="#os-only-container">Testing the install: An OS-only container</a></li>
<li><a href="#packages-container">A container including chosen Python packages</a></li>
<li><a href="#local-package-container">A container with a local Python package installed</a></li>
<li><a href="#mpi-container">A container that can use MPI</a></li>
<li><a href="#dem21-container">A container to run the more elaborate MPI package <code>dem21</code></a></li>
<li><a href="#gpu-container">A container that can use a GPU</a></li>
</ul>
</li>
</ul>
</li>
<li><p><a href="#move-to-hpc">Part 2: Moving code to a Slurm HPC cluster</a></p>
<ul>
<li><a href="#why-hpc">Why do it</a></li>
<li><a href="#unity-cluster">Unity cluster at UMass, Amherst</a><ul>
<li><a href="#unity-history">History</a></li>
<li><a href="#unity-login">Logging in</a></li>
<li><a href="#unity-storage">Storage</a></li>
<li><a href="#unity-file-transfer">Transferring files to/from Unity</a></li>
<li><a href="#unity-slurm">Slurm on Unity</a></li>
<li><a href="#run-interactive">Running jobs interactively: <code>salloc</code> or <code>unity-compute</code></a></li>
<li><a href="#rc-files">Using <code>.bashrc</code> and <code>.bash_aliases</code></a></li>
<li><a href="#unity-modules-conda">Using modules and Conda</a></li>
<li><a href="#run-batch">Running batch jobs: <code>sbatch</code></a></li>
</ul>
</li>
<li><a href="#unity-mpi">Using MPI on Unity (without Apptainer)</a><ul>
<li><a href="#ways-mpi-unity">Ways of running Python MPI programs on Unity</a></li>
<li><a href="#sbatch-mpi">Use <code>sbatch</code> to run a simple MPI job</a></li>
<li><a href="#sbatch-multithread">Enabling NumPy multithreading in MPI batch jobs</a></li>
<li><a href="#sbatch-dem21">Use <code>sbatch</code> to run <code>boxpct.py + dem21</code> with MPI</a></li>
</ul>
</li>
<li><a href="#unity-gpu">Using a GPU on Unity (without Apptainer)</a><ul>
<li><a href="#conda-gpu-unity">A Conda environment capable of using a GPU</a></li>
<li><a href="#gputest-interactive">Run <code>gputest.py</code> on Unity interactively</a></li>
<li><a href="#gpu-sbatch">A batch job using a GPU</a></li>
</ul>
</li>
<li><a href="#unity-apptainer">Using Apptainer on Unity</a><ul>
<li><a href="#images-to-unity">Getting container images on the cluster</a></li>
<li><a href="#unity-run-container">Running a container interactively or in batch job</a></li>
<li><a href="#unity-mpi-container">Running containers that use MPI</a></li>
<li><a href="#unity-gpu-container">Running a container the uses a GPU</a></li>
</ul>
</li>
</ul>
</li>
<li><p><a href="#random-notes">Random notes on parallel computing in Python</a></p>
<ul>
<li><a href="#journey">A long journey</a></li>
<li><a href="#wall-cpu-time">Wall time and CPU time</a></li>
<li><a href="#other-speed-factors">Factors other than parallelism affecting execution speed</a></li>
<li><a href="#strong-weak-scaling">Strong and weak scaling</a></li>
<li><a href="#estimate-mpi-overhead">Estimating MPI communication overhead</a></li>
</ul>
</li>
</ul>
<h2 class="atx" id="introduction-lessa-iddouble-quoteintrodouble-quotegreaterlessagreater">Introduction <a id="intro"></a></h2>
<h3 class="atx" id="what-is-thislessa-iddouble-quotewhat-isdouble-quotegreaterlessagreater">What is this?<a id="what-is"></a></h3>
<p>This the cheat sheet I that accumulated as I learned to combine several tools for <strong>parallel computing in Python</strong> on various <strong>Linux</strong> computer systems:</p>
<ul>
<li><p><a href="https://en.wikipedia.org/wiki/Message_Passing_Interface"><strong>MPI</strong></a> allows multiple instances of Python to operate in parallel and communicate with each other, in the cores of a single computer or a cluster of connected computers. Code written to parallelize using MPI can utilize all the cores of a desktop computer and also scale to a larger number of cores in an HPC computer cluster.</p>
</li>
<li><p>A <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit"><strong>GPU</strong></a> installed in a single computer can carry out highly parallel computations, so it offers an alternative to "MPI on a cluster of computers" for parallelizing code - but the degree of parallel operation is limited by the model of GPU that is available (unless multiple GPUs and/or GPUs on multiple MPI-connected computers are used, things not discussed in this document).</p>
</li>
<li><p><a href="https://apptainer.org/"><strong>Apptainer</strong></a> (formerly called <strong>Singularity</strong>) is a <strong>container</strong> system that allows user code and most of its dependencies (OS version, packages like NumPy) to be packaged together into a single large "image" file, which should then be usable  without modification or detailed environment configuration on many different computer systems from a Linux PC to a large cluster.</p>
</li>
<li><p>High-performance Computing (<a href="https://en.wikipedia.org/wiki/High-performance_computing"><strong>HPC</strong></a>) typically refers to using a large cluster of connected computers assembled and maintained by Universities and other organizations for the use of their communities.  This document only discusses an HPC cluster running Linux and managed by  <a href="https://slurm.schedmd.com/overview.html"><strong>Slurm</strong></a> scheduling software, with  the the <a href="https://unity.rc.umass.edu/index.php"><strong>UMass Unity cluster</strong></a> as the specific HPC system used here.</p>
</li>
<li><p>A few references are made in this document to <a href="https://github.com/">GitHub</a> as a place from which files can be downloaded.  Many resources are available on using Git/GitHub, including [this cheat sheet](<a href="https://github.com/doncandela/gs-git">GitHub - doncandela/gs-git: Getting started with Git and GitHub - also Markdown, PW managers...</a>) that I put together.</p>
</li>
</ul>
<p>Why Python?  Why Linux? Because those are what I use, and this is my cheat sheet.  So this document is geared towards this work flow:</p>
<ul>
<li><p>Write some Python code and get it working on a Linux PC.</p>
</li>
<li><p>(If desired) to get some parallel speedup either:</p>
<ul>
<li><p>add MPI code and get that working on the multiple cores of the PC, or</p>
</li>
<li><p>start using a GPU-aware package like CuPy or PyTorch and get that working using the PC's GPU.</p>
</li>
</ul>
</li>
<li><p>(If desired) to move the code to an HPC cluster like Unity:</p>
<ul>
<li><p>Optionally use Apptainer to containerize the code - this document shows how to do this if the code uses MPI, a GPU, or neither.</p>
</li>
<li><p>Copy the (already working) code, containerized or not, to the HPC cluster and run it there.</p>
</li>
</ul>
</li>
</ul>
<p>Although there may be some information useful for the following topics, this document <strong>does not cover:</strong></p>
<ul>
<li><p>Other than brief mentions, the use of OpenMP (a multithreading package not to be confused with OpenMPI) and/or the Python Mutiproccessing package for parallelization on the cores of a single computer. However, multithreading by NumPy (which may indirectly use OpenMP) is discussed.</p>
</li>
<li><p>Operating systems other than Linux (Windows, macOS...).</p>
</li>
<li><p>Computer languages other than Python such as C++.</p>
</li>
<li><p>GPUs other than NVIDIA, except some brief mentions of AMD ROCm and Mac MPS support in the section <a href="#non-nvidia">Non-NVIDIA GPUs</a> below.</p>
</li>
<li><p>Direct, low-level programming of GPUs in CUDA-C++  (as opposed to the use of GPU-aware Python packages like CuPy and PyTorch, which are discussed).</p>
</li>
<li><p>"Higher level" (than MPI) packages for using computer clusters such as Spark, Dask, Charm4Py/Charm++...).</p>
</li>
<li><p>Cloud computing (Amazon Web Services, Microsoft Azure...). </p>
</li>
<li><p>The Docker container system, other than as a source for building Apptainer containers.</p>
</li>
<li><p>The Kubernetes scheduling/management software typically used rather than Slurm in commercial settings, particularly with Docker.</p>
</li>
</ul>
<h3 class="atx" id="parallel-computing-in-pythonlessa-iddouble-quoteparcomp-pythondouble-quotegreaterlessagreater">Parallel computing in Python<a id="parcomp-python"></a></h3>
<p>Python is a semi-interpreted language (compiled to a byte code, like Java) and so is much more slowly executed than a fully compiled language like C++, unless an add-on like <a href="http://numba.pydata.org/">Numba</a> or <a href="https://cython.org/">Cython</a> is used (neither of these is discussed further in this document, although they may certainly be useful).</p>
<p>Therefore good performance on large tasks is often achieved by using <strong>packages</strong> (typically written by others in a compiled language like C++) like <a href="https://numpy.org/">NumPy</a>, <a href="https://scipy.org/">SciPy</a>, <a href="https://cupy.dev/">CuPy</a>, and <a href="https://pytorch.org/">PyTorch</a>, to carry out the time-consuming <strong>inner loops</strong> of algorithms. The same is true of other high-level languages like <a href="https://www.mathworks.com/products/matlab.html">MATLAB</a> and <a href="https://www.mathematica.org/">Mathematica</a>.   While some think Python is inherently slower than C++, if the time limiting factor is, for example, a large linear algebra operation then in either language it will likely be carried out by the same highly-optimized <a href="https://www.netlib.org/blas/">BLAS</a> function on a CPU (via NumPy, for Python), or the corresponding <a href="https://developer.nvidia.com/cublas">cuBLAS</a> function on a GPU (via CuPy).</p>
<p>There are however some murky intermediate situations. For example <a href="https://numpy.org/doc/stable/user/basics.indexing.html">NumPy advanced indexing</a> allows many complicated operations (e.g. operations on elements meeting complicated conditions) on arrays to be carried out much faster than if they were coded directly in Python -- but maybe slower than would be possible in C++.</p>
<p>Be that as it may, the premise of this document is <strong>speeding up (Python + packages) code</strong> by using one or the other of the following strategies (or potentially both together, although that is not discussed in detail):</p>
<p>(a)  <strong>by running many copies of the same (Python + packages) code at the same time, using MPI</strong> -- on the multiple cores of one or more CPUs, or</p>
<p>(b) <strong>by using GPU-aware packages</strong> -- a GPU is a highly-parallel computational device which however does not directly run Python code (or C++ code, for that matter, although a specialized hybrid language called <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/">CUDA C++</a> is often used to program GPUs).</p>
<p>For case (a) the individual, simultaneously-executing copies of a Python program can each take advantage of packages like NumPy and SciPy.  (However, depending on how things are set up, when used with MPI packages like NumPy may be prevented from using multithreading on multiple cores as is common without MPI.)  For this approach, you need to figure out how to split your problem into many pieces that can profitably run in parallel, how the pieces will be set up, controlled, and communicate with each other, etc.</p>
<p> Conversely for case (b) a  <strong>GPU-aware Python package</strong> like CuPy, PyTorch, or PyCUDA can be installed. The first two of these completely take care of parallelization in a manner transparent to the Python programmer, who however must keep track of which objects are on the GPU and which are on the CPU - a relatively simple thing.</p>
<p>It is important to distinguish between <strong>multithreading</strong> and <strong>multiprocessing</strong>:</p>
<ul>
<li><p>A <strong>process</strong> is an independently-running program with its own memory space and other resources. Each process can run an independent Python program. Each core of a CPU can run multiple processes, but only one at a time (i.e. serially) - running multiple processes in parallel requires multiple cores.</p>
</li>
<li><p>A <strong>thread</strong> is part of a process, that can sometimes use multiple cores to run in parallel with other threads in the same process. For example BLAS which is called by NumPy to do linear algebra can use <strong>multithreading</strong> to run faster if multiple cores are available to the process. </p>
</li>
<li><p>Although a Python program can call packages like NumPy/BLAS that are sped up by doing multithreading on multiple cores, only one Python interpreter at a time can run in a process (for now - there is a <a href="https://peps.python.org/pep-0703/">proposal</a> to relax this). Thus to carry out parallel <em>Python</em> operations <strong>multiprocessing</strong> is required. This can take several different forms:</p>
<ul>
<li><p>Python has a standard package <a href="https://docs.python.org/3/library/multiprocessing.html"><strong><code>multiprocessing</code></strong></a> that can run parallel processes on the different cores of a single CPU (maybe on all the cores in the typically two CPUs in an HPC node? I’m a bit unclear on this).</p>
</li>
<li><p>The C++ package <a href="https://www.openmp.org/"><strong>OpenMP</strong></a> (Python bindings <a href="https://github.com/Python-for-HPC/PyOMP"><strong>PyOMP</strong></a>) can also run parallel processes on the different cores single CPU (or single node = typically two CPUs?).</p>
</li>
<li><p><a href="https://en.wikipedia.org/wiki/Message_Passing_Interface"><strong>MPI</strong></a> can run parallel processes on the different cores of a single CPU and <strong>also on multiple nodes connected by a network</strong>. Implementations of MPI go under names like <a href="https://www.open-mpi.org/"><strong>OpenMPI</strong></a> (not to be confused with the non-MPI single-node multiprocessing package OpenMP) and <a href="https://www.mpich.org/"><strong>MPICH</strong></a>. A Python interface to the installed version of MPI is provided by <a href="https://mpi4py.readthedocs.io/en/stable/"><strong>MPI for Python (<code>mpi4py</code>)</strong></a>. </p>
<ul>
<li>Rather than directly use MPI, various higher-level applications like <a href="https://spark.apache.org/"><strong>Spark</strong></a>, <a href="https://www.dask.org/"><strong>Dask</strong></a>, or <a href="https://charm4py.readthedocs.io/en/latest/"><strong>Charm4py</strong></a> (perhaps no longer supported) can be used to coordinate parallel operations between cores and nodes. These applications can use MPI, and do not require MPI coding by the user. </li>
</ul>
</li>
<li><p>Parallel Python processes that do not need to communicate at all can be run on separate nodes of an HPC cluster as separately launched jobs, without using any of the things mentioned above.</p>
</li>
</ul>
</li>
<li><p>I haven’t used either of the Python packages <code>multiproccessing</code>, PyOMP but I believe the <code>multiprocessing</code> package has more high-level language support for Python. I believe this type of single-CPU, multi-core multiprocessing should be possible in an Apptainer container as described in this document, but I haven’t tried this.</p>
</li>
</ul>
<p>Finally, some Python jargon: A text file with extension <code>.py</code> containing Python language statements is sometimes called</p>
<ul>
<li>a <strong>program</strong>, considering it to express an algorithm like a C++ program, or</li>
<li>a <strong>script</strong>, considering it to be a set of high-level directives, or</li>
<li>a <strong>module</strong>, considering it to be code that could be imported into another <code>.py</code> file.
In this document these three terms are used interchangeably with apologies to those who make distinctions between them.</li>
</ul>
<h3 class="atx" id="hardware-usedlessa-iddouble-quotehardwaredouble-quotegreaterlessagreater">Hardware used<a id="hardware"></a></h3>
<h4 class="atx" id="pcslessa-iddouble-quotepcsdouble-quotegreaterlessagreater">PCs<a id="pcs"></a></h4>
<p>The commands and test programs shown in this document were tested on one or more of these PCs (only two of these have GPUs):</p>
<ul>
<li><strong>candela-20:</strong> Assembled from parts 9/19, 3.6 GHz AMD Ryzen 5 3600 6-core CPU, 32 GB RAM, GPU similar to NVIDIA GeForce GTX 1050 Ti, running Ubuntu 24.04.</li>
<li><strong>candela-21:</strong> Assembled from parts 11/22, 3.4 GHz AMD Ryzen 9 5950X 16-core CPU, 64 GB RAM, GPU similar to NVIDIA GeForce GTX 1060 6 GB VRAM, running Ubuntu 24.04.</li>
<li><strong>hoffice:</strong> Lenovo A10 510-23 purch 11/17, 2.4 GHz Intel Core i5 4-core CPU, 8 GB RAM, no NVIDIA-type GPU, running Ubuntu 24.04.</li>
</ul>
<h4 class="atx" id="gpuslessa-iddouble-quotegpusdouble-quotegreaterlessagreater">GPUs<a id="gpus"></a></h4>
<p>A more detailed version of this table is in the section <a href="#gpu-list">A few of NVDIA's many GPUS, with test results</a> below. The GPUs in candela-20 and candela-21 were actually EVGA models equivalent to the NVIDIA models listed here.</p>
<table>
<thead>
<tr>
<th>NVIDIA Model:</th>
<th>GeForce GTX 1050 Ti</th>
<th>GeForce GTX 1660</th>
<th>Tesla T4</th>
<th>Tesla V100 DGXS</th>
<th>Tesla A100 SMX4</th>
<th>Hopper H100 SXM5</th>
</tr>
</thead>
<tbody><tr>
<td>Where:</td>
<td>candela-20 GPU</td>
<td>candela-21 GPU</td>
<td>Best free GPU on Colab 10/23</td>
<td>Available on Unity</td>
<td>Available on Unity</td>
<td>Exists on Unity</td>
</tr>
<tr>
<td>Price:</td>
<td>$250 9/19</td>
<td>$297 11/22</td>
<td>$2,000 10/23</td>
<td>$1,500 10/23</td>
<td>$15,000 10/23</td>
<td>$30,000 10/23</td>
</tr>
</tbody></table>
<h4 class="atx" id="unity-hpc-clusterlessa-iddouble-quoteunity-introdouble-quotegreaterlessagreater">Unity HPC cluster<a id="unity-intro"></a></h4>
<p>The HPC commands shown in this document were tested on the <a href="https://unity.rc.umass.edu/index.php">Unity cluster</a> at UMass, Amherst. Unity runs the <a href="https://slurm.schedmd.com/overview.html">Slurm</a> job scheduling system and as of 1/25 had:</p>
<ul>
<li>About 350 general-access nodes plus another 350 “preempt” nodes belonging to groups but available for general access when not otherwise being used (also additional nodes never available for general access).</li>
<li>About 20,000 total cores in the general-access and preempt nodes, with individual nodes mostly having two CPUs and between 24 and 192 cores.</li>
<li>GPUs on about half of the nodes, with individual nodes having between 2 and 8 GPUs giving about 1000 total GPUs.  The GPU models (thus capabilities) varied widely, with the newest/best GPUs on the preempt modes as might be expected.</li>
</ul>
<p>Detailed information on using Unity is in the section <a href="#unity-cluster">Unity cluster at UMass, Amherst</a> below.</p>
<h3 class="atx" id="pip-conda-and-aptlessa-iddouble-quotepip-conda-aptdouble-quotegreaterlessagreater">Pip, Conda, and APT<a id="pip-conda-apt"></a></h3>
<ul>
<li><p><a href="https://pypi.org/project/pip/"><strong>Pip</strong></a> (package installer for Python) installs Python packages by default from <a href="https://pypi.org/"><strong>PyPI</strong></a>, the open-source Python Package Index.</p>
<ul>
<li><p>Some Python packages installed by pip require libraries written in other languages; pip can download the source code for these libraries and compile it. Alternatively pip can download a <strong>wheel</strong> (replaces an earlier thing called an <strong>egg</strong>) that has the needed libraries pre-compiled. Pip will prefer a wheel to uncompiled libraries if available, and will cache wheels for later use. A few pip commands:</p>
<pre><code class="fenced-code-block">$ pip install package            # install a package
$ pip install package=2.3.4      # install a specific version
$ pip list                       # list all installed packages
$ pip freeze                     # list all installed packages with more info
$ pip show package               # show info on package: where it is,what depends on it
$ pip uninstall package          # uninstall package</code></pre>
</li>
<li><p>Pip can also be used to install a package located on the local computer, which will allow the package to be imported from any directory on that computer. The local package will be a directory (repo in the example below) that contains the files <code>pyproject.toml</code> and <code>setup.py</code> and one or more subdirectories containing the Python modules that make up the package. Instructions for setting up a package so it can be installed with pip are <a href="https://stackoverflow.com/questions/714063/importing-modules-from-parent-folder">here</a> (see the the answer “Solution without sys.path hacks”); also more up-to-date instructions including <code>pyproject.toml</code> are in Appendix B of this <a href="https://github.com/doncandela/gs-git.git">Git/GitHub</a> tutorial. Once a package has been set up in this way, it can be installed as follows:</p>
<pre><code class="fenced-code-block">$ cd ~/../repo               # switch to package directory
$ pip install -e .           # install from current directory, -e means package
                             # can be edited without re-installing</code></pre>
</li>
<li><p>If a <strong>virtual environment</strong> has been created and activated by <strong>venv</strong> or by <strong>Conda</strong>, pip will install Python packages “in that environment”, i.e. they will only be visible and importable when that environment is activated.</p>
</li>
<li><p>You often see <code>python -m pip install package</code> used rather than the simpler commands listed above. I haven’t found this necessary when using pip inside a virtual environment; a discussion is <a href="https://snarky.ca/why-you-should-use-python-m-pip/">here</a>.</p>
</li>
<li><p>You will often see <code>pip3</code> rather than <code>pip</code>. If you are in an environment with Python 3 installed (vs. the earlier Python 2) they should point to the same command -- you can check this by comparing the output from <code>pip --version</code> with that from <code>pip3 --version</code>.</p>
</li>
</ul>
</li>
<li><p><a href="https://anaconda.org/anaconda/conda"><strong>Conda</strong></a> combines and extends the package-management functions of <strong>pip</strong> and the environment-management functions of <strong>venv</strong>. Conda can install packages and libraries for any language, not just Python, which means Conda can install Python itself.</p>
<ul>
<li><p><strong>Anaconda</strong> and <strong>Miniconda</strong> are <strong>distributions</strong> of packages (many, and not so many respectively).   </p>
</li>
<li><p>It seems preferable to use Conda to install packages when they are available as Conda packages, but many packages (and more recent versions of packages) are not available as Conda packages and can only be installed using pip.</p>
<ul>
<li>Frequently more up-to-date Conda packages are available from <a href="https://conda-forge.org/"><strong>conda-forge</strong></a> than from the default Conda channel -- see example below on how to use.</li>
<li>Here is an <a href="https://www.anaconda.com/blog/using-pip-in-a-conda-environment">article on using Conda and pip together</a>; it says <strong>pip should be used <em>after</em> Conda</strong>. In other words (I believe) creating a Conda environment automatically creates a venv environment of the same name, and activating the Conda environment switches to that venv.   </li>
<li>When using pip and Conda together, <strong>the Conda environment should be created including Python</strong> as in all the examples in this document.  Then, if pip is used in this environment it will install things in this environment.  If the Conda environment does not include Python, pip will try to modify the global environment which is usually not what is wanted (and is not allowed on an HPC cluster like Unity).</li>
</ul>
</li>
<li><p>Some Conda commands:</p>
<pre><code class="fenced-code-block">$ conda update conda                  # good to do this before other conda commands
$ conda search openmpi                # search for openmpi packages in default channels
$ conda search -c conda-forge openmpi # search in channel conda-forge
$ conda create -n p39 python=3.9.12   # create environment p39 with specific Python version
$ conda activate p39                  # activate environment p39, will change prompt
(p39)$ conda install matplotlib numba numpy pyyaml scipy  # install packages to current
                                                          # environment p39
(p39)$ conda install spyder=5.2.2 # install Spyder IDE to this evironment
(p39)$ conda install -c conda-forge quaternion            # install a package from the
                                                          # Conda-Forge repository
$ conda env list                     # list all defined environments
$ conda create -n enew --clone eold  # create environment enew by cloning existing eold
$ conda env remove -n p39            # get rid of environment p39</code></pre>
</li>
<li><p>Sometimes <code>conda create</code> or <code>conda install</code> will fail with the message <code>Solving environment: failed</code>.  Tips to avoid or fix this situation:</p>
<ul>
<li>Include all of the packages needed in the initial <code>conda create</code> command, rather than adding them later with <code>conda install</code> (or at least all of the packages that seem to be interacting).</li>
<li>Let Conda choose the version numbers rather than specifying them.</li>
<li>Get packages from <code>conda-forge</code> as shown above.</li>
<li>If you do specify a Python version, often an <strong>earlier Python version</strong> will be compatible with the available Conda versions of the other packages you need.</li>
<li>An IDE like Spyder has many complex dependencies. But when used only to edit files (as opposed to running them) Spyder can be run from the base or no environment, so there is no need to install it in your environments.</li>
</ul>
</li>
</ul>
</li>
<li><p><a href="https://documentation.ubuntu.com/server/how-to/software/package-management/index.html"><strong>APT</strong></a> (Advanced Packaging Tool) is used to <strong>install software packages system-wide</strong> (for all users, in all environments) and <strong>must be run with root (sudo) privilege</strong> except  when used to find out about installed packages.  The <strong><code>apt</code></strong> command is more modern than and basically replaces the earlier <strong><code>apt-get</code></strong> although you will see references to both, often mixed together.  Some common APT commands:</p>
<pre><code class="fenced-code-block">$ sudo apt update             # update package index, run this before running other apt cmds
$ sudu apt install &lt;package&gt;  # install a package
$ sudo apt upgrade            # upgrade all installed packages
$ sudo apt remove &lt;package&gt;   # remove a previously installed package
$ apt list --installed        # list all installed packages
$ apt list &lt;package&gt; --installed  # list installed packages with this name</code></pre>
</li>
</ul>
<h3 class="atx" id="conda-environments-and-test-code-used-in-this-documentlessa-iddouble-quoteenvs-testcodedouble-quotegreaterlessagreater">Conda environments and test code used in this document<a id="envs-testcode"></a></h3>
<ul>
<li><p><strong>Conda environments and Apptainer</strong>. Often, and for all the examples in this document, there is no need to create a Conda environment when an Apptainer container is being used - the container serves as an environment.  (One could run an Apptainer container from a Conda environment if additional packages not installed in the container were needed  -- but that is not shown here.)</p>
</li>
<li><p>The following Conda environments are created and used on a PC, when Apptainer is not being used (except for <strong><code>ompi</code></strong> which is used when an Apptainer container is run). </p>
<ul>
<li><strong><code>p39</code></strong> (defined just above) has Python 3.9, NumPy, SciPy, etc but does not have OpenMPI, PyTorch, or CuPy.</li>
<li><strong><code>dfs</code></strong> (defined in <a href="#local-package">Installing a local package</a> below) environment for trying out  the local package <code>dcfuncs</code>.</li>
<li><strong><code>m4p</code></strong> (defined in <a href="#mpi-pc">MPI on a Linux PC</a>) includes OpenMPI 5 and <code>mpi4py</code>, so MPI can be used by a Python program.</li>
<li><strong><code>dem21</code></strong> (also defined in <a href="#mpi-pc">MPI on a Linux PC</a>) is like <code>m4p</code> but additionally includes the locally-installed package <code>dem21</code> and additional packages that <code>dem21</code> imports.</li>
<li><strong><code>pyt</code></strong> (defined in <a href="#pytorch-cupy">Installing CUDA-aware Python packages...</a> below) adds PyTorch.</li>
<li><strong><code>gpu</code></strong> (also defined in <a href="#pytorch-cupy">Installing CUDA-aware Python packages...</a> below) adds CuPy.</li>
<li><strong><code>ompi</code></strong> (defined in <a href="#mpi-container">A container that can use MPI</a>) includes only OpenMPI and Python as an example of a minimal environment for running a container that uses MPI.</li>
</ul>
</li>
<li><p>The following Conda environments are created and used on the Unity HPC cluster, when Apptainer is not being used (except for <strong><code>ompi</code></strong> which is used when an Apptainer container is run).  They generally do the same things as the corresponding environments defined for PCs listed just above.</p>
<ul>
<li><strong><code>npsp</code></strong> (defined in <a href="#unity-modules-conda">Using modules and Conda</a>) has NumPy, SciPy, and Matplotlib, but not CuPy.</li>
<li><strong><code>dfs</code></strong> (also defined in <a href="#unity-modules-conda">Using modules and Conda</a>) has NumPy and the local package <code>dcfuncs</code> installed.</li>
<li><strong><code>m4p</code></strong> (defined in <a href="#unity-mpi">Using MPI on Unity (without Apptainer)</a>) includes OpenMPI 5.0.3, and <code>mpi4py</code>, so MPI can be used.</li>
<li><strong><code>dem21</code></strong> (also defined in <a href="#unity-mpi">Using MPI on Unity (without Apptainer)</a>) is like <code>m4p</code> but additionally includes the locally-installed package <code>dem21</code> and additional packages that <code>dem21</code> imports.</li>
<li><strong><code>gpu</code></strong> (defined in <a href="#unity-gpu">Using a GPU in Unity (without Apptainer)</a>) includes CuPy, so a GPU can be used.</li>
<li><strong><code>ompi</code></strong> (defined in  <a href="#unity-mpi-container">Running containers that use MPI</a>) includes only OpenMPI and Python as an example of a minimal environment for running a container that uses MPI.</li>
</ul>
</li>
<li><p>The following test code is used:</p>
<ul>
<li><strong><code>mpi_hw.py</code></strong> is an MPI "Hello world" program that verifies that a functional MPI system is installed that can run multiple copies of a Python program in parallel.</li>
<li><strong><code>osu_bw.py</code></strong> measures the communication speed between two MPI ranks.</li>
<li><strong><code>count.py</code></strong> times how fast a Python program can count.</li>
<li><strong><code>count_mpi.py</code></strong> times the counting speeds of multiple Python processes running simultaneously using MPI.</li>
<li><strong><code>threadcount.py</code></strong> uses timing to estimate the number of threads in use while NumPy is multiplying matrices.</li>
<li><strong><code>threadcount_mpi.py</code></strong> estimates the number of threads in use in each rank of an MPI run.</li>
<li><strong><code>gputest.py</code></strong> makes dense and sparse matrices of various sizes and floating-point types, and times operations using these matrices on the CPU and (if available) the GPU. If run in an environment without CuPy like <strong><code>p39</code></strong>, only CPU tests will be run. But if run in <strong><code>gpu</code></strong> and a GPU can be initialized, will also run GPU tests.</li>
<li><strong><code>np-version.py</code></strong> is a very short program that imports NumPy and prints out its version.</li>
<li><strong><code>dcfuncs</code></strong> is small package of utility functions, used in this document as an example of a Python package <a href="#local-package">installed locally</a>.  It is available from the public GitHub repo <a href="https://github.com/doncandela/dcfuncs">doncandela/dcfuncs</a>, which also includes the test programs <strong><code>test_util.py</code></strong>, etc, mentioned in this document.</li>
<li><strong><code>dem21</code></strong> is a complex package for doing DEM simulations of granular media using MPI parallelism. It is stored  in the currently private GitHub repo <a href="https://github.com/doncandela/dem21">doncandela/dem21</a>.  It is used in this document as a test and example of how a large, complex MPI code can be run.  The <code>dem21</code> repo includes the test program <code>boxpct.py</code> mentioned in this document. Also mentioned is a much more complex granular-memory simulation program called <code>mx2.py</code>.  While these codes are not available publicly, the examples here may be generally useful to show how an MPI program using many parallel ranks can be run on a PC or an HPC cluster, in both cases either non-containerized or containerized using Apptainer. The following shell scripts are used to run <code>mx2.py</code> on a PC, which requires various additional files not detailed in this document:<ul>
<li><strong><code>mx2.sh</code></strong> runs <code>mx2.py</code> without Apptainer.</li>
<li><strong><code>mx2-app.sh</code></strong> runs <code>mx2.py</code> using the Apptainer container built by <strong><code>dem21.def</code></strong>.</li>
</ul>
</li>
</ul>
</li>
<li><p>The following Apptainer definition files are used. They are all discussed in <a href="#apptainer-pc">Using Apptainer on a Linux PC</a> below.  They have been all been used to build container images (<code>.sif</code> files) on PCs, which can then be run successfully both on the PCs and on Unity.</p>
<ul>
<li><p><strong><code>os-only.def</code></strong> makes a container that contains only the <strong>Ubuntu OS</strong>.</p>
</li>
<li><p><strong><code>pack.def</code></strong> makes a container that contains Linux, Conda, and the <strong>Miniconda</strong> package distribution, and installs a few selected packages in the container.</p>
</li>
<li><p><strong><code>dfs.def</code></strong> makes a container with the local package <strong><code>dcfuncs</code></strong> installed in it.</p>
</li>
<li><p><strong><code>m4p.def</code></strong> makes a container with <strong>OpenMPI</strong> and <strong>MPI for Python</strong> installed in it, so it can be used to run MPI programs.</p>
</li>
<li><p><strong><code>dem21.def</code></strong> makes an MPI-enabled container like the one made by <code>m4p.def</code>, but it also has the more elaborate MPI-using package <code>dem21</code> installed in the container.</p>
</li>
<li><p><strong><code>gpu.def</code></strong> makes a container that imports <strong>CuPy</strong> so it can be used to run Python programs that use CuPy to run a GPU.</p>
</li>
</ul>
</li>
<li><p>The following sbatch scripts are defined for use with Slurm on the Unity cluster:</p>
<ul>
<li><strong><code>simple.sh</code></strong> (defined in <a href="#simple-batch">Example of a simple batch job</a>) runs job that uses none of MPI, a GPU, or Apptainer.</li>
<li><strong><code>osu_bw.sh</code></strong> (defined in <a href="#unity-mpi">Using MPI on Unity (without Apptainer)</a>) runs the MPI messaging-bandwidth test program <code>osu_bw.py</code>.</li>
<li><strong><code>threadcount_mpi.sh</code></strong> and <strong><code>threadcount_mpi2.sh</code></strong> (both also defined in <a href="#unity-mpi">Using MPI on Unity (without Apptainer)</a>) run <code>threadcount_mpi.py</code> to demonstrate the use NumPy multithreading along with MPI parallelism.</li>
<li><strong><code>boxpct_mpi.sh</code></strong> (also defined in <a href="#unity-mpi">Using MPI on Unity (without Apptainer)</a>) runs <code>boxpct.py</code> (which uses the <code>dem21</code> package) in MPI-parallel mode.</li>
<li><strong><code>gputest.sh</code></strong> (defined in <a href="#unity-gpu">Using a GPU on Unity (without Apptainer)</a>) runs <code>gputest.py</code> which uses a GPU.</li>
<li><strong><code>simple-app.sh</code></strong> (defined in <a href="#unity-run-container">Running a container interactively or in batch job</a>) uses an Apptainer container to run <code>gputest.py</code> without a GPU.</li>
<li><strong><code>osubw-app.sh</code></strong> (defined in <a href="#unity-mpi-container">Running containers that use MPI</a>) uses an Apptainer container to run the MPI messaging-bandwidth test program <code>osu_bw.py</code>.</li>
<li><strong><code>boxpct-app.sh</code></strong> (also defined in <a href="#unity-mpi-container">Running containers that use MPI</a>) uses an Apptainer container to run the test program for the <code>dem21</code> package <code>boxpct.py</code> in MPI-parallel ranks.</li>
<li>The following sbatch scripts run the granular-memory simulation program <code>mx2.py</code>, which requires various additional files not detailed in this document:<ul>
<li><strong><code>mx2-unity.sh</code></strong> runs <code>mx2.py</code> on Unity without Apptainer.</li>
<li><strong><code>mx2-unity-app.sh</code></strong> runs <code>mx2.py</code> on Unity using the Apptainer container built by <strong><code>dem21.def</code></strong>.</li>
</ul>
</li>
<li><strong><code>gputest-app.sh</code></strong> (defined in <a href="#unity-gpu-container">Running a container the uses a GPU</a>) uses an Apptainer container to run <code>gputest.py</code>  which uses a GPU.</li>
</ul>
</li>
</ul>
<h3 class="atx" id="installing-a-local-packagelessa-iddouble-quotelocal-packagedouble-quotegreaterlessagreater">Installing a local package<a id="local-package"></a></h3>
<p>sometimes it is convenient to write or otherwise come by a <strong>package of Python modules</strong> (containing class and function definitions), copy the package somewhere on the computer being used, and then make it possible to import the package from any directory on the same computer -- this is a <strong>local package</strong>, as opposed to a package downloaded from a repository of published packages like Anaconda or PyPi.  A way to structure such a local package is outlined in Appendix B of the cheat sheet  <a href="https://github.com/doncandela/gs-git">Getting started with Git and GitHub</a>.</p>
<p>In other sections of this document it is shown how a local package like this can be <a href="#local-package-unity">installed on an HPC cluster</a> like Unity (in user space), and how it can be <a href="#local-package-container">installed in an Apptainer container</a> which can then be used on a PC or on an HPC cluster.  As a starting point this section shows how a local package can be installed on a Linux PC, not using Apptainer.</p>
<ul>
<li><p>The package used for these examples is <strong><code>dcfuncs</code></strong>, a small set of utility functions that can be downloaded from <a href="https://github.com/doncandela/dcfuncs">https://github.com/doncandela/dcfuncs</a> -- hit <code>Download Zip</code> under the <code>&lt;&gt; Code</code> tab.  Alternatively, the package can be cloned into the current directory on the local PC by doing</p>
<pre><code class="fenced-code-block">$ git clone https://github.com/doncandela/dcfuncs.git</code></pre>
<p>This repository has the following structure:</p>
<pre><code class="fenced-code-block">dcfuncs/
   src/
      dcfuncs/            # installable package
         util.py          # utility functions: error exit, profiling, etc.
         configs.py       # reading yaml configuration files
      test/               # code to test if package is installed and usable
         test-util.py
         test-configs.py
         test-util.ipynb
   pyproject.toml
   setup.py</code></pre>
<p>(Read the comments in <code>util.py</code> and <code>configs.py</code> to find out what the functions do -- not relevant for present purposes.)</p>
</li>
<li><p>Make a Conda environment <code>dfs</code> in which to install and test the <code>dcfuncs</code> package:</p>
<pre><code class="fenced-code-block">$ conda update conda
$ conda create -n dfs python=3
$ conda activate dfs
(dfs)..$ conda install numpy          # needed by dcfuncs</code></pre>
</li>
<li><p>Download this package and go to the subdirectory <strong><code>test</code></strong>. Before the package is installed, running any of the <code>test-...</code> programs will give a <code>ModuleNotFound</code> error:</p>
<pre><code class="fenced-code-block">(dfs)..test$ python test-util.py
Traceback (most recent call last):
  File "test-util.py", line 7, in &lt;module&gt;
  import dcfuncs.util as dutil
ModuleNotFoundError: No module named 'dcfuncs'</code></pre>
</li>
<li><p>Go to the top directory in the repository and use this <code>pip</code> command to install the package (the optional <code>-e</code> makes the package editable without reinstalling, while the <code>.</code> means install from the current directory).</p>
<pre><code class="fenced-code-block">(dfs)...dcfuncs$ pip install -e .
(dfs)...dcfuncs$ pip list               # this will show dcfuncs installed</code></pre>
</li>
<li><p>Now the test programs run without error:</p>
<pre><code class="fenced-code-block">(dfs)..test$ python test-util.py
This is: dutil.py 8/19/24 D.C.
Using: util.py 8/18/24 D.C.

Testing zz:
- WARNING from util.py test code - This is just a warning.

Testing stoi:
stoi results = 93801881091158, 6318, 249613385242335
       ...</code></pre>
</li>
</ul>
<h3 class="atx" id="parallel-execution-on-multiple-coreslessa-iddouble-quotemultiple-coresdouble-quotegreaterlessagreater">Parallel execution on multiple cores<a id="multiple-cores"></a></h3>
<p>Modern CPU chips have multiple <strong>cores</strong> (as of 1/25 CPUs in consumer PCs have 4-10 cores while CPUs for HPC have up to 128 cores), with each core able to execute an independent <strong>thread</strong> within a process, or alternatively a full <strong>process</strong> which can execute Python code.  Some fine points about <strong>counting the number of cores</strong>:</p>
<ul>
<li>In an HPC cluster like Unity, a <strong>node</strong> is typically a board with two <strong>sockets</strong> each holding a CPU chip with shared memory between the CPUs, often along with one or more GPUs  -- so the cores per node is typically twice the cores per CPU chip. </li>
<li>Typical CPU chips can use <a href="https://en.wikipedia.org/wiki/Hyper-threading">"hyperthreading" or "hardware multithreading"</a> to make the number of <strong>virtual cores</strong> available to software to be twice the number of <strong>physical cores</strong>, giving a modest increase (less than two) in parallel throughput.  AMD calls this technology "simultaneous multithreading" while Intel calls it "hyperthreading" -- for simplicity only the latter term is used here.</li>
<li>In some SLURM and MPI settings, "cpu" refers to a <strong>core</strong> not a CPU chip. For example the <code>-c</code>,<code>-cpus-per-task</code> option to the SLURM <code>sbatch</code> command  and the <code>--cpus-per-proc</code> option to the OpenMPI <code>mpirun</code> command both set the the number of cores (not CPU chips) allocated to a process</li>
</ul>
<p>It might be thought that a PC using <em>n</em> cores should get <em>n</em> times as much computation done per second, provided the code can be efficiently split up to have <em>n</em> different things going on at the same time.  However, there are (at least) three factors that often make the gain in computation speed from using multiple cores less than the number of cores, even with efficiently parallel code: (a) the <strong>clock speeds</strong> of the cores may depend on how many are in use, due to automatic <strong>thermal management</strong> by the CPU chip, (b) the cores may need to <strong>contend for memory access</strong>, and (c) the available cores can be used for <strong>multithreading by NumPy and similar packages</strong>, or for <strong>MPI multiprocessing</strong>, or for <strong>both of these things simultaneously</strong>.</p>
<ul>
<li><p><strong>Clock speeds and thermal management.</strong>  To  show this effect we run the the program <strong><code>count_mpi.py</code></strong> on the <strong>16-core PC candela-21</strong> <a href="#pcs">mentioned above</a>. The The AMD Ryzen 9 5950X CPU chip in this PC has a <strong>base clock speed of 3.4 GHz</strong> and a <strong>boost clock speed up to 4.9 GHz</strong>.  <code>count_mpi.py</code> uses MPI to run a simple program that times how long it takes to count up to a specified number (1,000,000,000 in the examples shown here) on a chosen number of cores.  First we run on one core (the environment <code>m4p</code> is defined in <a href="#mpi-pc">MPI on a Linux PC</a> below):</p>
<pre><code class="fenced-code-block">(m4p)$ mpirun -n 1 -use-hwthread-cpus python count_mpi.py 1000000000
This is rank 0 of 1 on candela-21 running Open MPI v5.0.3
(rank 0) Counting up to 1,000,000,000...
(rank 0)...done, took 1.815e+01s, 5.510e+07counts/s
                      ...</code></pre>
<p>If we check the clock speeds in another terminal while <code>count_mpi.py</code> is running, we see that a single core is running at 4.7 GHz, near the maximum boost clock speed:</p>
<pre><code class="fenced-code-block">$ cat /proc/cpuinfo | grep 'cpu MHz'
cpu MHz        : 4657.204
cpu MHz        : 2200.000
cpu MHz        : 2200.000
cpu MHz        : 2200.000
cpu MHz        : 2200.000
cpu MHz        : 2200.000
         ...</code></pre>
<p>  Next <code>count_mpi.py</code>  is run on all 32 virtual cores (<code>-use-hwthread-cpus</code> is used to turn on hyperthreading):</p>
<pre><code class="fenced-code-block">(m4p)$ mpirun -n 32 -use-hwthread-cpus python count_mpi.py 1000000000
This is rank 5 of 32 on candela-21 running Open MPI v5.0.3
This is rank 4 of 32 on candela-21 running Open MPI v5.0.3
(rank 4) Counting up to 1,000,000,000...
This is rank 16 of 32 on candela-21 running Open MPI v5.0.3
                       ...
(rank 1)...done, took 3.957e+01s, 2.527e+07counts/s
(rank 14)...done, took 4.001e+01s, 2.499e+07counts/s
(rank 16)...done, took 4.002e+01s, 2.499e+07counts/s</code></pre>
<p>In this case all cores are running at 3.75 GHz, showing that the CPU will not use the maximum boost clock when all cores are in use:</p>
<pre><code class="fenced-code-block">$ cat /proc/cpuinfo | grep 'cpu MHz'
cpu MHz        : 3750.022
cpu MHz        : 3750.079
cpu MHz        : 3750.026
cpu MHz        : 3750.091
cpu MHz        : 3750.062
cpu MHz        : 3750.102
cpu MHz        : 3750.084
           ...</code></pre>
<p>As 16 physical cores are being used, one could expect the total count rate for all processes to be about 16*(3.75GHz/4.66GHz) = 12.8 times more than the single-core count rate.  In fact it is 32*2.5e7/s which is 14.6 times more than the single-core rate, suggesting a modest advantage from using hyperthreading.  So for this simple program which requires no memory access, the advantage of using all cores along with hyperthreading (14.6) was nearly equal to the number of cores (16) despite the reduced clock rate due to using all cores.</p>
<p>It was also found for this particular combination of software and hardware:</p>
<ul>
<li>Running on 16 cores with hyperthreading disabled (i.e. not using <code>use-hwthread-cpus</code>) gave a somewhat smaller throughput advantage (11.9) over using one core.  So in this case hyperthreading gives a 23% speadup.</li>
<li>Runinng on 16 cores with hyperthreading worked poorly (throughput advantage 7.6). From examining the clock speeds it seems that the 16 tasks were not using all 16 physical cores in this case.  In other words some physical cores ran 2 tasks in their two virtual cores, while other physical cores ran none.</li>
</ul>
</li>
<li><p><strong>Memory contention.</strong>  The cores in a CPU chip must ultimately read inputs and save outputs of computations in RAM external to the chip, and the bandwidth for moving data between RAM and the CPU cores can be the time-limiting factor for code, rather than the processing speed of the cores.  CPUs have a <a href="https://en.wikipedia.org/wiki/Cache_hierarchy">hierarchy of caches</a> to help mitigate this bottleneck, but it seems that memory access can still dominate over core processing speed for operations like sparse-matrix multiplication (see <a href="#gpu-list">CPU and GPU test results</a> below). Here is an interesting <a href="https://siboehm.com/articles/22/Fast-MMM-on-CPU">article</a> showing how the memory-intensive operation of dense-matrix multiplication is optimized to largely eliminate the memory bottleneck.</p>
</li>
<li><p><strong>NumPy multithreading.</strong></p>
<ul>
<li><p>The (non-MPI) Python script <strong><code>threadcount.py</code></strong> uses (process time)/(wall time) to estimate the number of cores in use when NumPy makes and then multiplies matrices filled with random numbers. On the 16-core PC <a href="#pcs">candela-21</a> (the environment <code>npsp</code> is defined in <a href="#unity-modules-conda">Using modules and Conda</a> below):</p>
<pre><code class="fenced-code-block">$ conda activate npsp
(npsp)$ python threadcount.py
Making 10,000 x 10,000 random matrices...
...took 1.815e+00s, average threads = 1.000
Multiplying matrices 3 times...
...took 5.426e+00s per trial, average threads = 15.959</code></pre>
<p>It can be seen that NumPy (specifically using <code>rng.normal</code> with <code>rng</code> a random number generator returned by <code>numpy.random.default_rng</code>) uses only one core to make a random-filled matrix, but (specifically using <code>numpy.matmul</code>) uses all 16 cores to multiply the matrices. By default the multithreaded NumPy functions (or rather the underlying linear algebra packages) are <strong>greedy</strong>, using all available cores in this the example above.</p>
<p>According to the NumPy docs, it may be possible to control the the number of threads used by the linear algebra packages called by NumPy by setting the environment variable <strong><code>OMP_NUM_THREADS</code></strong>.  This worked on candela-21:</p>
<pre><code class="fenced-code-block">(npsp)$ export OMP_NUM_THREADS=4
(npsp)$ python threadcount.py
Making 10,000 x 10,000 random matrices...
...took 1.809e+00s, average threads = 1.000
Multiplying matrices 3 times...
...took 8.235e+00s per trial, average threads = 3.998

(npsp)$ export OMP_NUM_THREADS=1
(npsp)$ python threadcount.py
Making 10,000 x 10,000 random matrices...
...took 1.806e+00s, average threads = 1.000
Multiplying matrices 3 times...
...took 3.112e+01s per trial, average threads = 1.000</code></pre>
<p>For this particular example, compared to using a single core, <code>np.matmul</code> was 3.8 times faster using 4 cores and 5.7 times faster using 16 cores -- so <code>np.matmul</code> made excellent use of 4 cores but had only modest gains beyond that point.</p>
</li>
<li><p>In the non-MPI experiments on the <a href="#pcs">PCs used for this document</a> Numpy never used hyperthreading -- the number of threads reported by <code>threadcount.py</code> and the number of cores in use shown by the Ubuntu System Monitor never exceeded the number of physical cores, even though the System Monitor showed twice this number of CPU's.  It may be possible to control this behavior using additonal <strong><code>OMP_...</code></strong> environment variables, as discussed <a href="https://theartofhpc.com/pcse/omp-affinity.html">here</a>; this was not tried.</p>
</li>
<li><p><strong>Tradeoff with MPI.</strong> If MPI is used, and the total number of cores available is limited, there may be a trade off between giving each MPI rank more cores (so NumPy can multithread) and running a program in more MPI ranks.  This is discussed further in <a href="#multithread-mpi">Hyperthreading and NumPy multithreading with MPI</a> below.</p>
</li>
</ul>
</li>
</ul>
<h2 class="atx" id="part-1-mpi-gpu-and-apptainer-on-a-linux-pclessa-iddouble-quoteon-linux-pcdouble-quotegreaterlessagreater">Part 1: MPI, GPU, and Apptainer on a Linux PC<a id="on-linux-pc"></a></h2>
<h3 class="atx" id="mpi-on-a-linux-pclessa-iddouble-quotempi-pcdouble-quotegreaterlessagreater">MPI on a Linux PC<a id="mpi-pc"></a></h3>
<h4 class="atx" id="why-do-itlessa-iddouble-quotewhy-mpi-pcdouble-quotegreaterlessagreater">Why do it<a id="why-mpi-pc"></a></h4>
<p>Using MPI, multiple copies of a Python program can run in parallel on the cores of a PC.  This can also be accomplished with the <a href="https://docs.python.org/3/library/multiprocessing.html">Python <code>multiprocessing</code> package</a>, which I haven't tried.</p>
<p>What MPI can do (and <code>multiprocessing</code> cannot do) is increase the parallelism to copies of Python running on <strong>multiple computers connected by a network</strong> - i.e. multiple nodes of an HPC cluster. Therefore a possible reason for developing MPI-parallel code on a PC is to enable eventual expansion to a higher degree of parallelism on an HPC cluster.  Note, however, that parallelism across all the cores of any single node of an HPC cluster could be accomplished without MPI by using the <code>multprocessing</code> package -- Unity nodes currently have up to 128 cores.</p>
<p>The most popular open-source MPI packages seem to be <a href="https://www.open-mpi.org/"><strong>OpenMPI</strong></a> and <a href="https://www.mpich.org/"><strong>MPICH</strong></a>. Also, there are some other versions of MPI that are derived from MPICH: <a href="https://mvapich.cse.ohio-state.edu/"><strong>MVAPICH2</strong></a>, <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/mpi-library.html"><strong>Intel MPI</strong></a>... For brevity <strong>only OpenMPI is discussed in this document</strong>.</p>
<h4 class="atx" id="installing-openmpi-and-mpi-for-python-mpi4py-on-a-linux-pclessa-iddouble-quoteinstall-openmpi-pcdouble-quotegreaterlessagreater"><strong>Installing OpenMPI and MPI for Python (<code>mpi4py</code>) on a Linux PC</strong><a id="install-openmpi-pc"></a></h4>
<p>To run MPI-parallel programs written in Python, it is necessary to have available (a) a working MPI installation such as <a href="https://docs.open-mpi.org/en/v5.0.x/">OpenMPI</a> and (b) a Python package such as <a href="https://mpi4py.readthedocs.io/en/stable/">MPI for Python (<code>mpi4py</code>)</a> to provide Python versions of the MPI functions. This section describes how to install OpenMPI and <code>mpi4py</code> on a PC, when an Apptainer container is not being used. Using OpenMPI + <code>mpi4py</code> in other situations is described in separate sections below: <a href="#mpi-container">with Apptainer on a PC</a>, <a href="#unity-mpi">without Apptainer on the Unity HPC cluster</a>, and <a href="#unity-mpi-container">with Apptainer on Unity</a>.</p>
<p>The docs for OpenMPI and <code>mpi4py</code> describe various ways of obtaining and installing these things, including building from source, but for the purpose of running an MPI-parallel Python program on a Linux PC the easiest thing is to use Conda to install both OpenMPI and <code>mpi4py</code> in an environment, here called <strong><code>m4p</code></strong>.  We also include some other packages likely  to be needed by programs running in this environment -- here we choose NumPy, SciPy, and Matplotlib. The version of OpenMPI installed can be found using <code>mpirun --version</code>, while much more detailed info is returned by <code>ompi_info</code>:</p>
<pre><code class="fenced-code-block">$ conda create -n m4p -c conda-forge openmpi=5 mpi4py python=3.12
$ conda activate m4p
(m4p)$ conda install -c conda-forge numpy scipy matplotlib
(m4p)$ mpirun --version
mpirun (Open MPI) 5.0.7
(m4p)$ ompi_info | head
                 Package: Open MPI conda@f424a898794e Distribution    
                Open MPI: 5.0.7                          
  Open MPI repo revision: v5.0.7                 
   Open MPI release date: Feb 14, 2025                 
                 MPI API: 3.1.0                   
            Ident string: 5.0.7                
                  Prefix: /home/dc/anaconda3/envs/m4p    
 Configured architecture: x86_64-conda-linux-gnu       
           Configured by: conda                    
           Configured on: Mon Feb 17 07:57:35 UTC 2025</code></pre>
<h4 class="atx" id="simple-mpi-test-programs-mpi_hwpy--and-osu_bwpy-lessa-iddouble-quotempi-testprogsdouble-quotegreaterlessagreater">Simple MPI test programs: <code>mpi_hw.py</code>  and <code>osu_bw.py</code> <a id="mpi-testprogs"></a></h4>
<ul>
<li><p>MPI works by <strong>loading and starting <span class="katex"><span class="katex-mathml"></span><span aria-hidden="true" class="katex-html"><span class="base"><span style="height:0.4306em;" class="strut"></span><span class="mord mathnormal">n</span></span></span></span> copies of the same code</strong>, each in its own process running on a separate core (or cores if, for example <a href="multithread-mpi">NumPy multithreading is enabled</a>)  Each process has a unique <strong>rank</strong>  in the range <span class="katex"><span class="katex-mathml"></span><span aria-hidden="true" class="katex-html"><span class="base"><span style="height:0.7278em;vertical-align:-0.0833em;" class="strut"></span><span class="mord">0</span><span style="margin-right:0.1667em;" class="mspace"></span><span class="minner">…</span><span style="margin-right:0.1667em;" class="mspace"></span><span class="mord mathnormal">n</span><span style="margin-right:0.2222em;" class="mspace"></span><span class="mbin">−</span><span style="margin-right:0.2222em;" class="mspace"></span></span><span class="base"><span style="height:0.6444em;" class="strut"></span><span class="mord">1</span></span></span></span>, and a process can find its rank via an MPI function call -- and then use the rank to figure out what it should do (this is up to the programmer!).  To simultaneously run four copies (ranks) of  the Python program <code>myprog.py</code> we do</p>
<pre><code class="fenced-code-block">$ mpirun -n 4 python myprog.py</code></pre>
</li>
<li><p>The "Hello world" of MPI programs, <strong><code>mpi_hw.py</code></strong> simply prints a message including the rank and other information.  Running <code>mpi_hw.py</code> in four ranks gives us four such messages, in an indeterminate order:**</p>
<pre><code class="fenced-code-block">(m4p)..$ cd python-scripts; ls    # cd to directory containing test programs
mpi_hw.py  osu_bw.py ...
(m4p)..python-scripts$ mpirun -n 4 python mpi_hw.py
Hello world from rank 0 of 4 on candela-21 running Open MPI v5.0.7
Hello world from rank 3 of 4 on candela-21 running Open MPI v5.0.7
Hello world from rank 1 of 4 on candela-21 running Open MPI v5.0.7
Hello world from rank 2 of 4 on candela-21 running Open MPI v5.0.7</code></pre>
<p>Some fine points about the number of ranks:</p>
<ul>
<li><p>Omitting <code>-n 4</code> above will set the number of ranks equal to the  number of available cores, while setting the number of ranks to more than the available cores will cause <code>mpirun</code> to fail.</p>
</li>
<li><p>Including the option  <code>--use-hwthread-cpus</code>  on <code>mpirun</code> will use <strong>hyperthreading</strong>, if available for the CPU used, to double the effective number of cores and thus double the allowed number of ranks.</p>
</li>
</ul>
</li>
<li><p>In <code>mpi_hw.py</code> the code in each rank runs independently, with no communication between ranks.  The main purpose of MPI is to carry out inter-rank communication, to enable non-trivial parallel algorithms.  <strong><code>osu_bw.py</code></strong> tests the <strong>speed of communication between two ranks</strong>, for messages of various sizes.  Here this test program was run on the PC candela-21.  As the two ranks are on cores on the same CPU chip (on a PC like this -- not necessarily true on an HPC cluster), the communication speed should be quite fast:</p>
<pre><code class="fenced-code-block">(m4p)..python-scripts$  mpirun -n 2 python osu_bw.py
2
2
# MPI Bandwidth Test
# Size [B]    Bandwidth [MB/s]
         1                3.69
         2                7.34
         4               14.63
         8               29.26
        16               57.95
        32              115.64
        64              209.67
       128              379.26
       256              707.62
       512            1,523.25
     1,024            2,900.98
     2,048            5,324.45
     4,096            2,881.93
     8,192            4,948.91
    16,384            7,633.05
    32,768           10,637.36
    65,536           13,375.59
   131,072           14,828.03
   262,144           15,466.52
   524,288           16,143.36
 1,048,576           16,809.99
 2,097,152           17,052.31
 4,194,304           17,227.80
 8,388,608           16,646.96
16,777,216           11,017.93</code></pre>
<p>It can be seen that the maximum inter-rank communication speed was about 17 GB/s on this PC (<a href="#pcs">candela-21</a>).</p>
</li>
</ul>
<h4 class="atx" id="more-elaborate-mpi-programs-using-the-dem21-packagelessa-iddouble-quotempi-dem21double-quotegreaterlessagreater">More elaborate MPI programs using the <code>dem21</code> package<a id="mpi-dem21"></a></h4>
<p>Here we use the discrete-element-method (DEM) simulation package <strong><code>dem21</code></strong>  (not currently publicly available) as an example of a much more elaborate MPI program.  It is assumed that OpenMPI has been installed on the PC as <a href="#install-openmpi-pc">described above</a>.</p>
<ul>
<li><p><strong>Environment for running <code>dem21</code>.</strong> With access the <code>dem21</code> repo is cloned from GitHub to a directory <code>foo/dem21</code>.  Then a suitable environment <strong><code>dem21</code></strong> is created similar to  <code>m4p</code> defined above but including the additional packages needed according to the instructions in the documentation <code>dem21.pdf</code> (in the repo).  Finally, the <code>dem21</code> package is installed in this environment (it was helpful to set the Python version to 3.11 and to break up the Conda install commands as shown here, otherwise Conda got stuck trying to solve the environment):</p>
<pre><code class="fenced-code-block">(base)..foo$ git clone git@github.com:doncandela/dem21.git

(base)..foo$ conda create -n dem21 -c conda-forge openmpi=5 mpi4py python=3.11
(base)..foo$ conda activate dem21
(dem21)..foo$ conda install -c conda-forge numpy scipy matplotlib dill numba pyaml
(dem21)..foo$ conda install -c conda-forge quaternion
(dem21)..foo$ cd dem21
(dem21)..foo/dem21$ pip install -e .</code></pre>
</li>
<li><p><strong>Quick test program <code>boxpct.py</code>.</strong>  Now it is possible to run the test program <code>boxpct.py</code> (included in the repo) in MPI-parallel mode:</p>
<pre><code class="fenced-code-block">(dem21)..foo/dem21$ cd tests/box
(dem21)..foo/dem21/tests/box$ export pproc=mpi # this tells boxpct.py to use MPI
(dem21)..foo/dem21/tests/box$ mpirun -n 4 python boxpct.py
- Started MPI on master + 3 worker ranks.
THIS IS: boxpct.py 12/3/22 D.C., using dem21 version: v1.2 2/11/25
Parallel processing: MPI, GHOST_ARRAY=True
- Read 1 config(s) from /home/dc/Documents/RES/COMPUTERS/foo/dem21/tests/box/box.yaml

SIM 1/1:
Using inelastic 'silicone' grainlets with en=0.7 and R=0.500mm
343 'sphere' grains in (7.66)x(7.66)x(7.66)mm box (phig=0.4), vrms=10.0m/s
No gravity, 'hertz' normal force law, Coulomb w. Hookean spring friction with GG mu=0.1, GW mu=0
-     Writing grain ICs x,v to /tmp/tmpkduz52n8/temp.grains
- READYING SIM with 343 grains and 6 walls
                       ...</code></pre>
</li>
<li><p><strong>A more resource-intensive run with <code>mx2.py</code>.</strong><a id="mx2py"></a> Finally we run a much bigger, longer-running DEM simulation which will be repeated below using Apptainer and on Unity (and both), to see if there is any performance impact from containerizing the code, and to investigate the speed-ups that can be obtained from the larger core counts available on Unity.</p>
<ul>
<li><p>The tested code is a simulation of a "granular memory" experiment on a dense pack of 10,240 tetrahedral grains (each composed of four spherical grainlets) with 450,000 time steps.</p>
</li>
<li><p>The simulation is carried out by the program <code>mx2.py</code>, continuing a sample-preparation simulation (not shown here) carried out by <code>ms.py</code> -- these programs call the <code>dem21</code> package which is run in run in MPI-parallel mode here.</p>
</li>
<li><p><code>mx2.py</code> needs the input-signals package <code>msigs</code> so we install it in the <code>dem21</code> environment:</p>
<pre><code class="fenced-code-block">..$ conda activate dem21
(dem21)..$ cd GMEM/msigs; ls   # cd to where msigs package is kept
'msigs README'   pyproject.toml   setup.py   src   test
(dem21)..GMEM/msigs$ pip install -e .</code></pre>
</li>
<li><p>A rather complicated directory structure not detailed here is used to organize the simulations so they can generate the granular samples and then carry out memory simulations on these samples.  Each memory simulation is carried out in a subdirectory called <strong><code>cc-expts..</code></strong> by a shell script (or on Unity, an sbatch script) called <strong><code>cc-expts/mx2...sh</code></strong> , which runs the program  <strong><code>mx2.py</code></strong> located in a higher directory.</p>
<p>Each of the various memory simulations described in this document (on a PC or on Unity, containerized or not, using different numbers of cores and/or hyperthreading) was uses a different  <strong><code>mx2..sh</code></strong> script. For this simple non-Apptainer, PC case the script is called <strong><code>mx2.sh</code></strong>:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# cc-expts/mx2.sh 4/6/25 D.C.
# Shell script to run granular-memory simulation program mx2.py non-containerized
# on a PC, as an example for "My cheat sheet for MPI, GPU, Apptainer, and HPC".
#
# Runs mx2.py in grandparent directory in 'mpi' parallel-processing mode.
# Reads default config file mx2.yaml in grandparent directory modified by
# mx2mod.yaml in current directory.
#
# To run on N cores 1st activate environment 'dem21' then do
#
# ./mx2.sh N
#
export pproc=mpi
mpirun -n $1 python ../../mx2.py mx2mod |&amp; tee output
# Alt version allows hyperthreading:
#mpirun -n $1 python --use-hwthreads-cpus ../../mx2.py mx2mod |&amp; tee output</code></pre>
<p>The simulation is run in the Conda environment <strong><code>dem21</code></strong>, in the directory <code>cc-expts</code> containing <code>mx2.sh</code> and other needed files not explained here:</p>
<pre><code class="fenced-code-block">(dem21)..$ cd ..cc-expts; ls
bw6-sigs.yaml  bw6.svg  mx2mod.yaml  mx2.sh signals.sh
(dem21)...cc-expts$ ./mx2.sh 15 # run mx2.py in 15 MPI ranks
- Started MPI on master + 14 worker ranks.
This is: mx2.py 7/29/24 D.C.
Using dem21 version: v1.2 2/11/25
Imput signals made by: memsigs.py 8/23/24 D.C.
                ...</code></pre>
</li>
<li><p>With the chosen parameters (set by <code>.yaml</code> config files read by <code>ms.py</code> and <code>mx2.py</code>) the simulation spatial domain was divided into 216 "boxes",  each of which does independent work during each simulation step.  Thus up to 216 operations could be carried out in parallel, if sufficient MPI ranks were allocated.</p>
</li>
<li><p>The boxes are distributed by the <code>dem21</code> package as evenly as possible across the available MPI ranks: rank 0 is used by the overall control program, and each remaining rank holds a "crate" which in turn holds zero or more boxes. Computation by the boxes in each crate is sequential for each time step, thus one might expect the overall execution time to be roughly proportional to the number of boxes per crate.  For the maximum possible parallelism (one box per crate) the number of MPI ranks must be at least one greater than the number of boxes, i.e. at least 217 in the present case.</p>
</li>
<li><p>When run in 15 MPI ranks on the  16-core PC <a href="#pcs">candela-21</a> with <a href="#multithread-mpi">hyperthreading disabled</a> as it is by default:</p>
<ul>
<li><p>There were 13 crates with 16 boxes and 1 crate with 8 boxes, requiring 16 serial box calculations at each time step.</p>
</li>
<li><p>The 450,000 step simulation required 15,937 s = 4.427 hr, or 3.46 microsec/step-grain.</p>
</li>
<li><p>Running the simulation required about 2.1 GB of memory beyond what the PC was using before the simulation was run.</p>
</li>
</ul>
</li>
<li><p>The simulation was also run in 30 MPI ranks on the same PC with <a href="#multithread-mpi">hyperthreading enabled</a> by supplying  <code>--use-hwthread-cpus</code> to the <code>mpirun</code> command in <code>mx2.sh</code>.</p>
<ul>
<li><p>Now there were 27 crates with 8 boxes and 2 crates with 0 boxes, requiring 8 serial box calculations at each time step, i.e. half as many as without hyperthreading.</p>
</li>
<li><p>Now the simulation required 16,567 s = 4.602 hr, or 3.60 microsec/step-grain.  So despite the greater degree of parallelism with hyperthreading, in this case there was no overall advantage in in fact the program ran slightly slower.  It seems that whatever speed advantage was provided by hyperthreading (<a href="#multiple-cores">expected to be of order 25%</a>) was negated by the the increased MPI communication required or other unknown factors.</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 class="atx" id="hyperthreading-and-numpy-multithreading-with-mpilessa-iddouble-quotemultithread-mpidouble-quotegreaterlessagreater">Hyperthreading and NumPy multithreading with MPI<a id="multithread-mpi"></a></h4>
<ul>
<li>As discussed in <a href="#multiple-cores">Parallel execution on multiple cores</a> above, "hyperthreading" or "simultaneous multithreading" is a feature of many CPU chips which makes each physical core act like two virtual cores.<ul>
<li>It seems that hyperthreading is often turned off (or disabled?) in HPC clusters, for example some information on this for the Unity cluster is <a href="https://docs.unity.rc.umass.edu/documentation/get-started/hpc-theory/threads-cores-processes-sockets/">here</a> and <a href="https://docs.unity.rc.umass.edu/news/2023/06/june-5-maintenance-concluded/">here</a>.</li>
<li>In trials running OpenMPI on Linux PCs, hyperthreading was turned off by default but is could be turned on by supplying the option <strong><code>--use-hwthread-cpus</code></strong> to <strong><code>mpirun</code></strong>.  I was unable to achieve significant performance improvements with hyperthreading (see previous section for an example), so it is not discussed further here.</li>
</ul>
</li>
<li>As also discussed in <a href="#multiple-cores">Parallel execution on multiple cores</a>, some NumPy functions (like matrix multiplication) can take advantage of multithreading on multiple cores to speed up.  I believe this is typcially via the use of OpenMP by the underlying BLAS functions employed by NumPy.<ul>
<li>For non-MPI programs <a href="#multiple-cores">it was found</a> that some NumPy functions will greedily use all available cores unless the environment variable <code>OMP_NUM_THREADS</code> is used to reduce the cores used.</li>
<li>For MPI programs on PCs, I found that the number of cores used by NumPy is controlled by the <code>mpirun</code> option <code>-cpus-per-proc</code> in concert with <code>OMP_NUM_THREADS</code>.  However, it seemed difficult to get much advantage in this way so detailed trials are not shown here.</li>
<li>When neither <code>OMP_NUM_THREADS</code> nor <code>-cpus-per-proc</code> is used, it seems  that NumPy functions called in a Python MPI program will be limited to a single core.</li>
<li>The section <a href="#sbatch-multithread">Enabling NumPy multithreading in MPI batch jobs</a> below shows how NumPy multithreading can be controlled in and MPI program running on the Unity HPC cluster.</li>
</ul>
</li>
</ul>
<h3 class="atx" id="using-an-nvidia-gpu-on-a-linux-pclessa-iddouble-quotegpu-pcdouble-quotegreaterlessagreater">Using an NVIDIA GPU on a Linux PC<a id="gpu-pc"></a></h3>
<h4 class="atx" id="why-do-itlessa-iddouble-quotewhy-gpu-pcdouble-quotegreaterlessagreater">Why do it<a id="why-gpu-pc"></a></h4>
<p>A relatively inexpensive GPU can offer significant speedups. For example in test results <a href="#gpu-list">shown below</a> on the candela-21 PC assembled in 2022 the $300 GPU was about four times faster than the $550 16-core CPU chip for operations on large dense and sparse matrices.</p>
<p>If the code might eventually be transferred to an HPC cluster, the more capable GPUs on the HPC nodes should offer even greater speed-ups than this.</p>
<h4 class="atx" id="non-nvidia-gpuslessa-iddouble-quotenon-nvidiadouble-quotegreaterlessagreater">Non-NVIDIA GPUs<a id="non-nvidia"></a></h4>
<p>Both PyTorch and CuPy can use AMD GPUs, which use <a href="https://rocm.docs.amd.com/en/latest/what-is-rocm.html">ROCm</a> drivers (vs CUDA drivers for NVIDIA GPUs).  It seems PyTorch can also use an MPS GPU on a Mac. I don't have an AMD GPU  or a Mac and haven't tried these things.</p>
<h4 class="atx" id="installing-nvidia-driverslessa-iddouble-quotenvidia-driversdouble-quotegreaterlessagreater">Installing NVIDIA drivers<a id="nvidia-drivers"></a></h4>
<p>These steps are only need once on a given PC, unless updating to newer versions.</p>
<ul>
<li><p>Find out if (and which) NVIDIA GPU hardware is installed:</p>
<pre><code class="fenced-code-block">$ sudo lshw -C display</code></pre>
</li>
<li><p>By default Ubuntu will use the open-source X driver for NVIDIA hardware, but this seems not to be appropriate when using the GPU for computation, and sometimes even just for graphics (e.g. Mayavi did not function correctly on candela-21 with the X driver). Thus a <strong>proprietary NVIDIA driver</strong> should be installed.</p>
</li>
<li><p>It’s possible to <a href="https://www.nvidia.com/download/index.aspx">download and install drivers from NVIDIA</a> but this will require stopping the X driver, etc (didn’t try).</p>
</li>
<li><p>Instead it’s easier to install from Linux channels following e.g. <a href="https://www.cyberciti.biz/faq/ubuntu-linux-install-nvidia-driver-latest-proprietary-driver/">instructions here</a>. This can be done in Terminal, but easiest to use the Ubuntu graphical <strong>Software and Updates</strong> app: The <strong>Additional Drivers</strong> tab should show the GPU and available drivers (from NVIDIA as well as X) – pick most recent (proprietary, tested) NVIDIA driver, Apply Changes, then when completed reboot system.</p>
</li>
<li><p>Now you can use the text-based and/or graphical apps supplied by NVIDIA to check that the driver is functioning and get info on the GPU:</p>
<pre><code class="fenced-code-block">$ nvidia-smi         # text-based
$ nvidia-settings    # graphical</code></pre>
<p>Note the <strong>CUDA Version</strong> from nvida-smi (was 12.2 on candela-20 PC 1/25)</p>
</li>
</ul>
<h4 class="atx" id="installing--cuda-aware-python-packages-pytorch-cupylessa-iddouble-quotepytorch-cupydouble-quotegreaterlessagreater">Installing  CUDA-aware Python packages: PyTorch, CuPy...<a id="pytorch-cupy"></a></h4>
<ul>
<li><p>To use the GPU in Python programs, a Python package must be installed that knows how to access and use the GPU.  Three such packages are discussed briefly here:</p>
<ul>
<li><strong>PyCUDA</strong>, for running CUDA-C++ code from a Python program.</li>
<li><strong>PyTorch</strong>, a popular machine-learning platform that <strong>can be used with or without a GPU</strong>.</li>
<li><strong>CuPy</strong>, which provides GPU-accelerated replacements for many NumPy and SciPy functions.</li>
</ul>
</li>
<li><p><a href="https://pypi.org/project/pycuda/"><strong>PyCUDA</strong></a> enables a Python program to directly operate an NVIDIA GPU in the <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/"><strong>CUDA-C++</strong></a> language.  CUDA-C++ code is passed to PyCUDA functions as multiline strings, for example:</p>
<pre><code class="fenced-code-block">mod = SourceModule("""
__global__ void doublify(float *a)
{
  int idx = threadIdx.x + threadIdx.y*4;
  a[idx] *= 2;
}
""")</code></pre>
<p>To used PyCUDA you will need to learn about the NVIDIA GPU architecture with its kernels, threads, streams, etc.
I have not used PyCUDA and it is not discussed further in this document.</p>
</li>
<li><p><a href="https://pytorch.org/"><strong>PyTorch</strong></a> is a machine-learning platform that can be used with or without a GPU. </p>
<ul>
<li><p><strong>Installing PyTorch on a Linux PC.</strong>  First we make a Conda environment <code>pyt</code>  in which to run PyTorch,  with other packages that will be used -- here we have chosen NumPy, SciPy, Matplotlib, and Jupyter Notebook but I think none of these are required:</p>
<pre><code class="fenced-code-block">(base)..$ conda update conda 
(base)..$ conda create -n pyt python=3                   # 1/25 installed python 3.13.1
(base)..$ conda activate pyt
(pyt)..$ conda install numpy scipy matplotlib jupyter    # this downgraded python to 3.12.8
(pyt)..$ jupyter notebook                                # check that JN works</code></pre>
<p>Next run the install PyTorch using the appropriate command from the <a href="https://pytorch.org/get-started/locally/">PyTorch Getting Started page</a>. The installation command depends on which version of CUDA is installed, if any -- since CUDA 12.2 was installed I selected the nearest version no later than 12.2 which was 12.1:</p>
<pre><code class="fenced-code-block">(pyt-gmem)..$ pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121</code></pre>
<p>To check that PyTorch is usable, run this code in a JN which creates a small tensor filled with random numbers:</p>
<pre><code class="fenced-code-block">import torch
x = torch.rand(5, 3)
print(x)

tensor([[0.3366, 0.6316, 0.7751],
        [0.6390, 0.9224, 0.9920],
        [0.3413, 0.4789, 0.9909],
        [0.3987, 0.7204, 0.1965],
        [0.7794, 0.5492, 0.6764]])</code></pre>
</li>
<li><p><strong>Using the GPU in PyTorch.</strong> The fundamental objects in PyTorch are <strong>tensors</strong>, which are NumPy arrays with lots of additional features added: the ability to store gradients, participate in backpropagation, etc.  A tensor can exist on either the CPU or the GPU, and you cannot do operations between tensors in two different places (e.g. multiply a tensor on the CPU by a tensor on the GPU).  PyTorch makes it easy to move tensors to the GPU if it exists, otherwise leave them on the CPU as this example (run in a JN) shows.</p>
<p>First we set a string <code>DEVICE</code> to be <code>'cuda'</code> if an NVIDIA GPU is available, otherwise <code>'cpu</code>'</p>
<pre><code class="fenced-code-block">import torch
DEVICE = ('cuda' if torch.cuda.is_available()              # Nvidia GPU with CUDA
          else 'mps' if torch.backends.mps.is_available()  # MAC GPU with MPS
          else 'cpu')                                      # no GPU
print(f'Availble device: {DEVICE}')

Availble device: cuda</code></pre>
<p>Next we make two <span class="katex"><span class="katex-mathml"></span><span aria-hidden="true" class="katex-html"><span class="base"><span style="height:0.7278em;vertical-align:-0.0833em;" class="strut"></span><span class="mord">3</span><span style="margin-right:0.2222em;" class="mspace"></span><span class="mbin">×</span><span style="margin-right:0.2222em;" class="mspace"></span></span><span class="base"><span style="height:0.6444em;" class="strut"></span><span class="mord">3</span></span></span></span> tensors on the CPU, and get versions of them that are moved to the available device (CPU or GPU):</p>
<pre><code class="fenced-code-block">x = torch.rand(3,3)
y = torch.rand(3,3)
xdvc = x.to(DEVICE)
ydvc = y.to(DEVICE)
x.device,xdvc.device

(device(type='cpu'), device(type='cuda', index=0))</code></pre>
<p>We can multiply the two tensors moved to the available device.  <strong>This code works whether or not a GPU is available.</strong></p>
<pre><code class="fenced-code-block">torch.mm(xdvc,ydvc)

tensor([[0.7678, 0.7135, 0.3886],
        [0.9471, 0.4305, 0.3549],
        [0.5254, 0.4289, 0.2599]], device='cuda:0')</code></pre>
<p>If we try to multiply a tensor on the CPU by a tensor on the GPU, we get an error:</p>
<pre><code class="fenced-code-block">torch.mm(x,ydvc)

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
Cell In[10], line 1
----&gt; 1 torch.mm(x,ydvc)

RuntimeError: Expected all tensors to be on the same device...</code></pre>
<p>Going the other way, we can use <code>xdvc.cpu().numpy()</code> to get the NumPy array part of a tensor or <code>xdvc[1,1].item()</code> to get the float value of a tensor element -- the results will be on the CPU, whether or not <code>xdvc</code> is on the GPU.</p>
<p>This is as far as we will go with PyTorch in this document. </p>
</li>
</ul>
</li>
<li><p><a href="https://cupy.dev/"><strong>CuPy</strong></a> provides "drop-in" substitutes for many NumPy and SciPy array functions (many with the same function names and call signatures) which however run on an NVIDIA GPU and use the highly-optimized <a href="https://developer.nvidia.com/cuda-toolkit">CUDA Toolkit</a> libraries.  Thus CuPy provides a fairly painless way to achieve GPU acceleration for NumPy/SciPy code, although one must keep track of where arrays are (GPU vs CPU) and transfer them as necessary.  CuPy also provides some "low level" GPU capabilities which have no NumPy/SciPy analogs such as creating CUDA <strong>events</strong>, writing CUDA <strong>kernels</strong>, etc.</p>
<ul>
<li><p><strong>Installing CuPy on a Linux PC.</strong> First we make a Conda environment <code>gpu</code>  in which to run Python programs using CuPy,  with other packages that will be used -- here we have chosen Numpy and SciPy so they can be compared with CuPy, and Jupyter Notebook to use for the examples below.  We install CuPy from <a href="https://conda-forge.org/">conda-forge</a> because (as of 1/25) only a very outdated version of CuPy was available from the default Conda channel.</p>
<pre><code class="fenced-code-block">(base)..$ conda update conda 
(base)..$ conda create -n gpu python=3
(base)..$ conda activate gpu
(gpu)..$ conda install numpy scipy jupyter
(gpu)..$ conda install -c conda-forge cupy
(gpu)..$ conda list              # see versions of installed packaged</code></pre>
<p>In 1/25 after these commands the installed versions were: Python 3.11.11, NumPy 2.2.1, SciPy 1.15.1, Jupyter 1.1.0, CuPy 13.3.0.</p>
</li>
<li><p><strong>Simple examples of CuPy.</strong>  This code run in a Jupyter Notebook imports <code>cupy</code> as well as <code>cupyx</code> (needed if SciPy-equivalent functions will be used) and prints out the <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities">CUDA compute capability</a> of the installed NVIDIA GPU -- this was the small GPU on the candela-20 PC with a compute capability of 6.1.  This code will fail if there is no GPU, or CUDA is not installed.</p>
<pre><code class="fenced-code-block">import numpy as np
import scipy
import cupy as cp         # numpy-equiv and CUDA GPU funcs
import cupyx              # scipy-equive GPU funcs

# Optional code to get some info on the GPU.
gpudevice = cp.cuda.Device()
print(f'GPU has compute capability {gpudevice.compute_capability}')

GPU has compute capability 61</code></pre>
<p>Next (after doing the imports as above), we make two <span class="katex"><span class="katex-mathml"></span><span aria-hidden="true" class="katex-html"><span class="base"><span style="height:0.7278em;vertical-align:-0.0833em;" class="strut"></span><span class="mord">3</span><span style="margin-right:0.2222em;" class="mspace"></span><span class="mbin">×</span><span style="margin-right:0.2222em;" class="mspace"></span></span><span class="base"><span style="height:0.6444em;" class="strut"></span><span class="mord">3</span></span></span></span> arrays of random numbers -- one using <code>np.random.rand</code> which gives a regular NumPy array (type <code>numpy.ndarray</code>) and the other using <code>cp.random.rand</code> which gives a CuPy array on the GPU (type <code>cp.ndarray</code>).  Notes: (a) the syntax is identical for the NumPy and CuPy functions, and (b) CuPy arrays always live on the GPU (unlike PyTorch tensors, which can be either on the CPU or on the GPU).</p>
<pre><code class="fenced-code-block">x = np.random.rand(3,3)
ygpu = cp.random.rand(3,3)
print('x=\n',x,type(x))
print('\nygpu=\n',ygpu,type(ygpu))

x=
  [[0.69443384 0.79801011 0.30639659]
  [0.73035583 0.42256363 0.8435655 ]
  [0.05977241 0.69179361 0.03713523]] &lt;class 'numpy.ndarray'&gt;

ygpu=
  [[0.17523124 0.84222265 0.18135991]
  [0.9385187  0.03738684 0.48680856]
  [0.96396622 0.4795829  0.97488979]] &lt;class 'cupy.ndarray'&gt;</code></pre>
<p>We cannot multiply <code>x</code> by <code>ygpu</code> without first moving one or the other of them so they are on the same device (CPU or GPU).  First we use the <code>get</code> method of a CuPy array, which returns a copy of <code>ygpu</code>  as a NumPy array (on the CPU) so we can multiply the matrices using <code>np.matmul</code>:</p>
<pre><code class="fenced-code-block">z = np.matmul(x,ygpu.get())
print('z=\n',z,type(z))

z=
  [[1.16598987 0.76164555 0.81312352]
  [1.33773368 1.03548014 1.16054826]
  [0.69553234 0.09401508 0.38381413]] &lt;class 'numpy.ndarray'&gt;</code></pre>
<p>Next we use the function <code>cp.asarray</code> to copy the NumPy array <code>x</code> to a CuPy array on the GPU, so we can multiply the matrices using <code>cp.matmul</code>:</p>
<pre><code class="fenced-code-block">zgpu = cp.matmul(cp.asarray(x),ygpu)
print('zgpu=\n',zgpu,type(zgpu))

zgpu=
  [[1.16598987 0.76164555 0.81312352]
  [1.33773368 1.03548014 1.16054826]
  [0.69553234 0.09401508 0.38381413]] &lt;class 'cupy.ndarray'&gt;</code></pre>
</li>
</ul>
</li>
<li><p><strong>A more elaborate CuPy program: <code>gputest.py</code>.</strong><a id="gputest-py"></a>  This program tests the speed of the CPU and (if available) the GPU by timing the muliplication of matrices -- both dense and sparse -- of various sizes and data types.  See the comments in <code>gputest.py</code> for details:</p>
<pre><code class="fenced-code-block">(gpu) $ python gputest.py
Running: gputest.py 11/22/23 D.C.
Local time: Mon Jan  6 14:24:54 2025
GPU 0 has compute capacity 6.1, 6 SMs, 4.23 GB RAM, guess model = GeForce GTX 1050
CPU timings use last 10 of 11 trials
GPU timings use last 25 of 28 trials

***************** Doing test dense_mult ******************
Multiply M*M=N element dense matrices
*********************************************************

************ Using float64 **************
         N     flop make mats  CPU test *CPU op/s*  GPU test *GPU op/s*  GPU xfer xfer rate
    99,856 6.30e+07 3.39e-03s 5.05e-04s 1.25e+11/s 1.23e-03s 5.12e+10/s 3.27e-02s  0.10GB/s
 1,000,000 2.00e+09 2.92e-02s 8.69e-03s 2.30e+11/s 2.85e-02s 7.02e+10/s 1.01e-02s  3.17GB/s
                                        ...</code></pre>
</li>
</ul>
<h4 class="atx" id="a-few-of-nvdiaand39s-many-gpus-with-test-resultslessa-iddouble-quotegpu-listdouble-quotegreaterlessagreater">A few of NVDIA's many GPUS, with test results<a id="gpu-list"></a></h4>
<p>NVIDA has made many different GPUs. This table shows includes the relatively small GPUs in my PCs, a somewhat bigger GPU available for free on Google Colab, and a few more powerful GPUs available on the Unity HPC cluster.</p>
<table>
<thead>
<tr>
<th>NVIDIA Model:</th>
<th>GeForce GTX 1050 Ti</th>
<th>GeForce GTX 1660</th>
<th>Tesla T4</th>
<th>Tesla V100 DGXS</th>
<th>Tesla A100 SMX4</th>
<th>Hopper H100 SXM5</th>
</tr>
</thead>
<tbody><tr>
<td>Where:</td>
<td>candela-20 GPU</td>
<td>candela-21 GPU</td>
<td>Best free on Colab 10/23</td>
<td>Available on Unity</td>
<td>Available on Unity</td>
<td>Exists on Unity</td>
</tr>
<tr>
<td>Price:</td>
<td>$250 9/19</td>
<td>$297 11/22</td>
<td>$2,000 10/23</td>
<td>$1,500 10/23</td>
<td>$15,000 10/23</td>
<td>$30,000 10/23</td>
</tr>
<tr>
<td>Release date:</td>
<td>10/16</td>
<td>3/19</td>
<td>9/18</td>
<td>3/18</td>
<td>5/20</td>
<td>3/22</td>
</tr>
<tr>
<td>GPU chip, arch:</td>
<td>Pascal</td>
<td>TU116, Turing</td>
<td>TU104, Turing</td>
<td>GV100, Volta</td>
<td>GA 100, Ampere</td>
<td>GH100, Hopper</td>
</tr>
<tr>
<td>Fab procces:</td>
<td>14 nm</td>
<td>12 nm</td>
<td>12 nm</td>
<td>12 nm</td>
<td>7 nm</td>
<td>4 nm</td>
</tr>
<tr>
<td>Transistors:</td>
<td>3.3e9</td>
<td>6.6e9</td>
<td>1.4e10</td>
<td>2.1e10</td>
<td>5.4e10</td>
<td>8e10</td>
</tr>
<tr>
<td>CUDA compute:</td>
<td>6.1</td>
<td>7.5</td>
<td>7.5</td>
<td>7.0</td>
<td>8.0</td>
<td>9.0</td>
</tr>
<tr>
<td>Streaming Multiprocs:</td>
<td>6</td>
<td>22</td>
<td>40</td>
<td>80</td>
<td>108</td>
<td>144</td>
</tr>
<tr>
<td>CUDA cores:</td>
<td>768 (128/SM)</td>
<td>1,408 (64/SM)</td>
<td>2,560 (64/SM)</td>
<td>5,120 (64/SM)</td>
<td>6,912 (64/SM)</td>
<td>16,896</td>
</tr>
<tr>
<td>Tensor cores:</td>
<td>0</td>
<td>0</td>
<td>320</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Ray tracing cores:</td>
<td>0</td>
<td>0</td>
<td>40</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Memory:</td>
<td>4 GB</td>
<td>6 GB GDDR5</td>
<td>15 GB GDDR6</td>
<td>16 GB HBM2</td>
<td>40 GB HBM2e</td>
<td>96 GB HBM3</td>
</tr>
<tr>
<td>Memory width:</td>
<td>128-bit</td>
<td>192-bit</td>
<td>256-bit</td>
<td>4,096-bit</td>
<td>5,120-bit</td>
<td>5,120-bit</td>
</tr>
<tr>
<td>Memory BW:</td>
<td>112 GB/s</td>
<td>192 GB/s</td>
<td>320 GB/s</td>
<td>897 GB/s</td>
<td>1,555 GB/s</td>
<td>1,681 GB/s</td>
</tr>
<tr>
<td>Max float64 FLOPS:</td>
<td>0.067 TF</td>
<td>0.157 TF</td>
<td>?</td>
<td>6.6 TF</td>
<td>9.7 TF</td>
<td>33.5 TF</td>
</tr>
<tr>
<td><strong>Max float32 FLOPS:</strong></td>
<td><strong>2.14 TF</strong></td>
<td><strong>5.03 TF</strong></td>
<td><strong>8.1 TF</strong></td>
<td><strong>13.2 TF</strong></td>
<td><strong>19.5 TF</strong></td>
<td><strong>66.9 TF</strong></td>
</tr>
<tr>
<td>Max tf32 FLOPS:</td>
<td></td>
<td></td>
<td>64.8 TF</td>
<td>105.7 TF</td>
<td>312 TF</td>
<td>989 TF</td>
</tr>
<tr>
<td>Max int32 OPS:</td>
<td></td>
<td></td>
<td></td>
<td>17.7 TO</td>
<td>19.7 TO</td>
<td></td>
</tr>
<tr>
<td><strong>Test results from <code>gputest.py</code></strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>System:</strong></td>
<td><strong>candela-20</strong></td>
<td><strong>candela-21</strong></td>
<td><strong>Google Colab</strong></td>
<td><strong>Unity HPC</strong></td>
<td><strong>Unity HPC</strong></td>
<td></td>
</tr>
<tr>
<td><strong>CPU or GPU:</strong></td>
<td><strong>6-core 3.8 GHz CPU</strong></td>
<td><strong>16-core 3.4 GHz CPU</strong></td>
<td><strong>Tesla T4 GPU</strong></td>
<td><strong>Tesla V100 GPU</strong></td>
<td><strong>Tesla A100 GPU</strong></td>
<td></td>
</tr>
<tr>
<td>Dense matrix multiplication</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>float64 CPU / GPU:</td>
<td>0.22 / 0.07 TF</td>
<td><strong>0.34 /0.14 TF</strong></td>
<td>0.06 /0.128 TF</td>
<td>0.64 /4.8 TF</td>
<td><strong>0.41 /11.6 TF</strong></td>
<td></td>
</tr>
<tr>
<td>float32 CPU /GPU:</td>
<td>0.55 /1.86 TF</td>
<td><strong>0.78 /3.00 TF</strong></td>
<td>0.06 / 5.6 TF</td>
<td>1.26 / 9.2 TF</td>
<td><strong>1.28 / 15.2 TF</strong></td>
<td></td>
</tr>
<tr>
<td>Bond vectors using Numpy Indexing</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>float64 CPU / GPU:</td>
<td>0.12 / 0.40 GF</td>
<td><strong>0.12 /0.66 GF</strong></td>
<td>0.06 / 1.17 GF</td>
<td>0.07 /6.2 GF</td>
<td><strong>0.115 /15.6 GF</strong></td>
<td></td>
</tr>
<tr>
<td>float32 CPU /GPU:</td>
<td>0.19 /0.52 GF</td>
<td><strong>0.22 /0.97 GF</strong></td>
<td>0.05 / 3.3 GF</td>
<td>0.11 / 3.5 GF</td>
<td><strong>0.21 / 24 GF</strong></td>
<td></td>
</tr>
<tr>
<td>Bond vectors using CSR matrix</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>float64 CPU / GPU:</td>
<td></td>
<td><strong>0.24 /0.67 GF</strong></td>
<td>0.07 / 1.12 GF</td>
<td>0.07 /5.6 GF</td>
<td><strong>0.22 /13.7 GF</strong></td>
<td></td>
</tr>
<tr>
<td>float32 CPU /GPU:</td>
<td></td>
<td><strong>0.26 /0.94 GF</strong></td>
<td>0.09 / 3.0 GF</td>
<td>0.10 / 11.9 GF</td>
<td><strong>0.26 / 21 GF</strong></td>
<td></td>
</tr>
<tr>
<td>Node forces using CSR matrix</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>float64 CPU / GPU:</td>
<td></td>
<td><strong>0.55 /1.28 GF</strong></td>
<td>0.14 / 1.96 GF</td>
<td>0.13 /7.9 GF</td>
<td><strong>0.36 /31 GF</strong></td>
<td></td>
</tr>
<tr>
<td>float32 CPU /GPU:</td>
<td></td>
<td><strong>0.66 /1.41 GF</strong></td>
<td>0.22 / 3.82 GF</td>
<td>0.23 / 13.8 GF</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>0.43 / 55 GF</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>These test results used arrays with <span class="katex"><span class="katex-mathml"></span><span aria-hidden="true" class="katex-html"><span class="base"><span style="height:0.8141em;" class="strut"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span style="height:0.8141em;" class="vlist"><span style="top:-3.063em;margin-right:0.05em;"><span style="height:2.7em;" class="pstrut"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span></span></span></span></span></span></span></span> elements.  Here TF = TFLOPS = <span class="katex"><span class="katex-mathml"></span><span aria-hidden="true" class="katex-html"><span class="base"><span style="height:0.8141em;" class="strut"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span style="height:0.8141em;" class="vlist"><span style="top:-3.063em;margin-right:0.05em;"><span style="height:2.7em;" class="pstrut"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span></span></span></span></span></span></span></span> FP ops/s, GF = GFLOPS = <span class="katex"><span class="katex-mathml"></span><span aria-hidden="true" class="katex-html"><span class="base"><span style="height:0.8141em;" class="strut"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span style="height:0.8141em;" class="vlist"><span style="top:-3.063em;margin-right:0.05em;"><span style="height:2.7em;" class="pstrut"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">9</span></span></span></span></span></span></span></span></span></span></span> FP ops/s. </p>
<ul>
<li><p>Conclusions from this testing:</p>
<ul>
<li><p><strong>float32 vs float64:</strong> This only makes a big difference when doing dense matrix calculations, which operate at close to theoretical maximum FLOPS for each type of GPU.  Sparse operations (bond vectors and of node forces) have 300-1,000 times less FLOPS, suggesting they are dominated by memory access rather than FLOP capability, and the speed doesn’t depend much on float32/float64. For <strong>dense matrix operations</strong>:</p>
<ul>
<li>Using <strong>float64</strong>, candela-21 GPU is terrible and shouldn’t be used. A100 GPU is 34 times faster than candela-21 CPU.</li>
<li>Using <strong>float32</strong> (already 2.3 times faster than float64 on candela-21 CPU), candela-21 GPU is 3.8 times faster and A100 GPU is 19 times faster than candela-21 CPU  (so using GPUs A100 is only 5 times faster than candela-21).</li>
</ul>
</li>
<li><p><strong>Speedup of float32 over float64</strong> on various systems:</p>
<ul>
<li><strong>candela-21</strong> float32 speedup is <strong>8.8 for dense operations</strong> (float32 on GPU vs float64 on CPU), only <strong>1.1-1.5 for sparse operations</strong> (all on GPU).</li>
<li><strong>Unity using A100 GPU</strong> float32 speedup is <strong>1.3 for dense operations, 1.5-1.8 for sparse operations</strong>.</li>
</ul>
</li>
<li><p><strong>CSR matrix vs numpy indexing:</strong> When calculating bond vectors from node positions, no advantage to using CSR matrix over numpy indexing.</p>
</li>
<li><p><strong>Sparse operations.</strong>  These are float32 speedups with numpy indexing for bond vectors, float64 and or CSR for bond vectors only modestly different. CPU-GPU transfer times are ignored here:</p>
<ul>
<li><strong>Calculating bond vectors from differences of node positions.</strong>  candela-21 GPU is 3.6 times faster and A100 GPU is 81 times faster than candela-21 CPU (so using GPUs A100 is 22 times faster than candela-21).</li>
<li><strong>Calculating node forces by summing bond forces.</strong>  candela-21 GPU is 2.1 times faster and A100 GPU is 83 times faster than candela-21 CPU (so using GPUs A100 is 39 times faster than candela-21).</li>
</ul>
</li>
<li><p><strong>Comparison of available GPUs</strong> using <strong>float32</strong> and <strong>candela-21 GPU</strong> as reference:</p>
<ul>
<li><strong>candela-20</strong> is <strong>1.5 times slower for dense and sparse operations</strong>.</li>
<li><strong>T4</strong> (best GPU available free on Colab as of 11/23) is <strong>1.9 times faster for dense operations, 1.3-3.2 times faster for sparse operations</strong>. But <strong>CPU operations were much slower on Colab+T4 than on candela-21.</strong></li>
<li><strong>V100</strong> (good GPU sometimes available on Unity as of 11/23) is <strong>3 times faster for dense operations, 4-10 times faster for sparse operations</strong>. But again <strong>CPU operations were slower than on candela-21.</strong></li>
<li><strong>A100</strong> (very good GPU sometimes available on Unity as of 11/23) is <strong>5 times faster for dense operations, 20-40 times faster for sparse operations. CPU operations were similar</strong> to candela-21.</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Running CuPy in a Google Colab notebook.</strong> This was quite simple, as it seems compatible Numpy, CUDA and CuPy are installed by default:</p>
<ul>
<li>Paste Python code that imports CuPy into a code cell (for example the GPU test program <code>testgpu.py</code> can simply be pasted into a cell).</li>
<li>Select a GPU runtime.  As of 10/23, the only GPU type available for free on Colab was the Tesla T4. Tesla V100 and Tesla A100 GPUs were available but only on a paid tier.</li>
<li>Hit run.</li>
</ul>
</li>
</ul>
<h3 class="atx" id="using-apptainer-on-a-linux-pclessa-iddouble-quoteapptainer-pcdouble-quotegreaterlessagreater">Using Apptainer on a Linux PC<a id="apptainer-pc"></a></h3>
<h4 class="atx" id="why-do-itlessa-iddouble-quotewhy-apptainer-pcdouble-quotegreaterlessagreater">Why do it<a id="why-apptainer-pc"></a></h4>
<p>Code that is containerized using Apptainer should be usable on various PCs without setting up environments with the correct packages (with compatible versions) installed.  However, this does require Apptainer itself to be installed on the PCs, which is not necessarily trivial or commonly done.</p>
<p>Probably the best reason for containerizing code is to make it easy to run the code on an HPC cluster, which is likely to have Apptainer pre-installed and ready to use (as Unity does).  In the examples below, <strong>containers developed and usable on a PC could also be used without modification on Unity</strong>.</p>
<h4 class="atx" id="apptainer-historylessa-iddouble-quoteapptainer-historydouble-quotegreaterlessagreater">Apptainer history<a id="apptainer-history"></a></h4>
<ul>
<li><strong>Singularity</strong> (the original name) developed in 2015 at LBL by Gregory Kurtzer et al. and became popular on HPC clusters 2016-2018.</li>
<li>2018 Kurtzer founded <a href="https://sylabs.io/">Sylabs</a> and released Singularity 3.0 rewritten in Go.</li>
<li>5/21 Sylabs forked Singularity 3.8.? to <strong>SingularityCE</strong> “community edition”, they also have a pay-for version called SingularityPRO:<ul>
<li>First version SingularityCE 3.8.0 5/26/21</li>
<li>Current version SingularityCE 4.2 as of 1/25</li>
</ul>
</li>
<li>11/21 Singularity renamed <a href="https://apptainer.org/"><strong>Apptainer</strong></a>.<ul>
<li>Last Singularity version 3.8.7 3/17/22</li>
<li>First Apptainer version 1.0.1 3/2/22</li>
<li>Current Apptainer version 1.3.6 12/24</li>
</ul>
</li>
<li>Apptainer versions on various systems, as of 1/25:<ul>
<li>My Linux PCs at work and home, installed as below: Apptainer 1.3.4</li>
<li>Unity: Apptainer 1.3.4</li>
</ul>
</li>
</ul>
<h4 class="atx" id="installing-apptainerlessa-iddouble-quoteinstall-apptainerdouble-quotegreaterlessagreater">Installing Apptainer<a id="install-apptainer"></a></h4>
<p>1/25 Installed Apptainer 1.3.4 on <a href="#pcs">my three PCs  running Ubuntu 24.04</a>:</p>
<ul>
<li><p>Followed the instructions in the Install Ubuntu Packages section in the Installing Apptainer section of the Apptainer Admin Guide in the <a href="https://apptainer.org/documentation/">documentation</a> at the Apptainer site.  These were the steps for a <strong>non-setuid</strong> installation, which generally seems to be recommended:</p>
<pre><code class="fenced-code-block">$ sudo add-apt-repository -y ppa:apptainer/ppa
$ sudo apt update
$ sudo apt install -y apptainer</code></pre>
</li>
<li><p>This should eventually be unnecessary, but as of 1/25 trying to run Apptainer freshly installed as above as a regular (non-sudo) user under Ubuntu 24.04 fails with the following messages:</p>
<pre><code class="fenced-code-block">ERROR  : Could not write info to setgroups: Permission denied
ERROR  : Error while waiting event for user namespace mappings: no event received</code></pre>
<ul>
<li><p>The source of this problem - a security upgrade when Ubuntu went to 24.04 that requires an apparmor profile for Apptainer which was omitted from the Apptainer distribution for Ubuntu - is discussed in these links:</p>
<ul>
<li><a href="https://github.com/apptainer/apptainer/issues/2608">https://github.com/apptainer/apptainer/issues/2608</a></li>
<li><a href="https://github.com/apptainer/apptainer/blob/main/INSTALL.md#apparmor-profile-ubuntu-2404">https://github.com/apptainer/apptainer/blob/main/INSTALL.md#apparmor-profile-ubuntu-2404</a></li>
<li><a href="https://github.com/apptainer/apptainer/issues/2360">https://github.com/apptainer/apptainer/issues/2360</a></li>
</ul>
</li>
<li><p>From these links I found the problem could be fixed by adding a file called <code>apptainer</code> to the directory <code>/etc/apparmor.d</code> with these contents…</p>
<pre><code class="fenced-code-block"># Permit unprivileged user namespace creation for apptainer starter
abi &lt;abi/4.0&gt;,
include &lt;tunables/global&gt;
profile apptainer /usr/libexec/apptainer/bin/starter{,-suid} 
    flags=(unconfined) {
  userns,
  # Site-specific additions and overrides. See local/README for details.
  include if exists &lt;local/apptainer&gt; 
}</code></pre>
<p>...then re-booting or running this command:</p>
<pre><code class="fenced-code-block">$ sudo systemctl reload apparmor</code></pre>
</li>
<li><p>On <strong>Unity</strong> this problem does not exist or was fixed by administrators -- non-superusers are allowed to run Apptainer containers.</p>
</li>
</ul>
</li>
<li><p>Check the Apptainer version.  I also checked the Singularity version, which on my PCs was still the pre-fork version installed in 2022 (not used in the rest of this document):</p>
<pre><code class="fenced-code-block">$ apptainer --version
apptainer version 1.3.4
$ singularity --version
singularity version 3.7.4</code></pre>
</li>
<li><p>On <strong>Unity</strong> <code>singularity</code> is aliased to <code>apptainer</code>, meaning Singularity commands actually run Apptainer.  Logged into Unity:</p>
<pre><code class="fenced-code-block">$ apptainer --version
apptainer version 1.3.4
$ singularity --version
apptainer version 1.3.4</code></pre>
<p>For this document I decided not to do this, but rather to use <code>apptainer</code> commands directly.</p>
</li>
</ul>
<h4 class="atx" id="testing-the-install-an-os-only-containerlessa-iddouble-quoteos-only-containerdouble-quotegreaterlessagreater">Testing the install: An OS-only container<a id="os-only-container"></a></h4>
<ul>
<li><p>Here is a <a href="https://medium.com/@dcat52/making-your-first-container-81b832d82a6f">short tutorial</a>.</p>
</li>
<li><p>The specifications for building a container are in a small text file (a <code>.def</code> file), while the container itself is a large Singularity image file (a <code>.sif</code> file). Typically containers are “bootstrapped” from a <strong>Docker</strong> container found on <a href="https://hub.docker.com/">Docker Hub</a> -- the <code>apptainer build</code> command will convert the Docker container to an Apptainer container, then add more things to it as specified by the <code>.def</code> file. For a minimal definition file that bootstraps the official container for Ubuntu 24.04 and doesn’t add anything further to it, make a file <strong><code>os-only.def</code></strong> with these contents:</p>
<pre><code class="fenced-code-block">Bootstrap: docker
From: ubuntu:24.04</code></pre>
<p>These statements tell Apptainer to use the container <code>ubuntu:24.04</code> from Docker Hub, where you can find many other starting containers to use for your builds (for example, containers  with other flavors or versions of Linux, with Conda and the Miniconda distribution, with other applications...).</p>
</li>
<li><p>Because container images (<code>.sif</code> files) can be fairly large (up to several GB), it is often helpful to keep them in a separately backed up directory. To avoid repetitive typing set a shell variable <code>SIFS</code> to point to this directory:</p>
<pre><code class="fenced-code-block">$ export SIFS="/home/..."        # directory where .sif files will be put</code></pre>
<p>If this path includes any spaces it must be quoted as shown here and below, otherwise the quotes can
be omitted.  Since this <code>export</code> command must be done every time a new terminal is opened, it is handy to create an alias <code>sifs</code>:</p>
<pre><code class="fenced-code-block"># Add this to ~/.bash_aliases:
alias sifs="export SIFS="/home/..."</code></pre>
</li>
<li><p>Build the container image: In the directory that contains the definition file <code>os-only.def</code> do the following command. <strong>Root privilege is necessary to build a container image, but not to use it.</strong> (According to the Apptainer docs it should be possible to build a container without root privilege by using the <code>--fakeroot</code> option, but I haven’t tried this.)</p>
<pre><code class="fenced-code-block">$ sudo apptainer build "$SIFS"/os-only.sif os-only.def</code></pre>
</li>
<li><p>This created a 30 MB image file <strong><code>os-only.sif</code></strong> in the directory <code>$SIFS</code>. We can open a shell running inside the container using the <code>apptainer shell</code> command.  This gives a prompt <code>Apptainer&gt;</code> from which we can issue shell commands that will run inside the container:</p>
<pre><code class="fenced-code-block">$ apptainer shell "$SIFS"/os-only.sif
Apptainer&gt; pwd
/home/...</code></pre>
<p>The current working directory inside the container is the same as is was before the container was started (more on this below), making it easy for commands run in the container to work with files outside the container.</p>
</li>
<li><p>The following example shows</p>
<ul>
<li><p>Python is not installed inside this bare-bones container.</p>
</li>
<li><p>The OS inside the container is Ubuntu 24.04 as set in the definition file <code>os-only.def</code>, independent of what the OS is outside the container. Either of the outside and inside OS versions can be newer (within broad limits set by kernel versions) or they can be the same.</p>
</li>
<li><p>A command (here <code>touch</code>) run inside the container accesses the directory outside the container from which the container was started.  </p>
</li>
<li><p>To exit the container shell do <code>ctrl-D</code>. Outside the container we see that Python is installed (unlike inside), and the file created by the <code>touch</code> command now exists.</p>
<pre><code class="fenced-code-block">Apptainer&gt; python --version
bash: python: command not found
Apptainer&gt; cat /etc/os-release
PRETTY_NAME="Ubuntu 24.04.1 LTS"
       ...
Apptainer&gt; pwd
/home/..          (will be directory in which “apptainer shell” was run)
Apptainer&gt; touch foo
Apptainer&gt;        (hit ctrl-D to exit the container)
exit
$ python --version
Python 3.11.11
$ ls
...  foo  ...</code></pre>
<p>Possible point of confusion: The container has its own file system with its own root, independent of the file system outside the container.  Thus <code>/etc/os-release</code> in the <code>cat</code> command above prints a file that exists inside the container with OS information.  Once a container is built, <strong>the file system inside the container is read-only</strong>. However, for convenience, <strong>certain directories inside the container are automatically bound to directories outside the container with the same names</strong> when the container is run. Typically these will include <strong>the user's current working and home directories</strong> -- making it possible to access and write to the same files and directories from inside the container as outside.</p>
<p>I believe that these two things: (a) the ability to run a container as a non-superuser, and (b) the ability to access files outside the container are among the primary differences between Apptainer and Docker containers, making Apptainer more suitable for use on a shared HPC system.  I think Docker containers are most frequently run in cloud-based virtual machines for which the user will have superuser access.</p>
<p><strong>Note on the initial working directory in an Apptainer container.</strong>  In 2023 when Unity was newer, the current working directory (CWD) inside an Apptainer container was not automatically bound to the CWD from which the container was run, if it was run from a subdirectory of <code>/work</code> (the normal place for job I/O) - I think because <code>/work</code> is not under <code>/home</code> unlike the work directories for some other HPC clusters like the former USMC.  But as of 1/25 this seems to have been fixed -- even when run from a directory under <code>/work</code>, the CWD is bound as usual.</p>
</li>
</ul>
</li>
</ul>
<h4 class="atx" id="a-container-including-chosen-python-packageslessa-iddouble-quotepackages-containerdouble-quotegreaterlessagreater">A container including chosen Python packages<a id="packages-container"></a></h4>
<ul>
<li><p>It is possible to install Pip, Python, etc. into a bare-bones Ubuntu container as created above, but it is easier to start with a container that has Python, pip, Conda, and the Miniconda package distribution pre-installed. Docker images of such containers are available from the Anaconda folks. Make a file <strong><code>pack.def</code></strong> with these contents:</p>
<pre><code class="fenced-code-block">Bootstrap: docker
From: continuumio/miniconda3

%post
  conda install numpy matplotlib scipy</code></pre>
<p>This has a new <strong><code>%post</code></strong> section which lists Linux commands that will be <strong>run during the container-build process</strong>, establishing an "environment" with the needed packages inside the container which will be available wherever the container is run. There is no need to make a Conda environment -- the container itself provides the environment.</p>
</li>
<li><p>Build the container as above:</p>
<pre><code class="fenced-code-block">$ sudo apptainer build "$SIFS"/pack.sif pack.def</code></pre>
<p>The resulting container <strong><code>pack.sif</code></strong>  is now considerably in larger – without the <code>conda install</code> command the container size is 235 MB, and with the full definition shown above it is 1.4 GB.</p>
</li>
<li><p>Shelling into the container we can find the versions of things and verify that we have a working Python installation:</p>
<pre><code class="fenced-code-block">$ apptainer shell "$SIFS"/pack.sif

Apptainer&gt; cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
       ...
Apptainer&gt; python --version
Python 3.12.8
Apptainer&gt; pip list
Package                  Version
------------------------ -----------
matplotlib               3.9.2
numpy                    2.1.3
scipy                    1.14.1
         ...
Apptainer&gt; python
         ...
&gt;&gt;&gt; print('Hello from this container')
Hello from this container</code></pre>
<p> From this we see that in the container we are running Debian 12 Linux (not Ubuntu as above), Python 3.12.8, etc. If an different version of Python is needed for compatibility, there are more specific versions of continuumio/miniconda3 that can be bootstrapped from Docker Hub.</p>
</li>
<li><p><strong>Using the container to run Python scripts outside the container.</strong></p>
<ul>
<li><p>Here is simple program <strong><code>np-version.py</code></strong> that imports NumPy and prints out its version:</p>
<pre><code class="fenced-code-block">import numpy as np
print(f'numpy version = {np.__version__}')</code></pre>
<p>Running it in a terminal showed that NumPy 1.24.3 was installed on my PC:</p>
<pre><code class="fenced-code-block">$ python np-version.py
numpy version = 1.24.3</code></pre>
</li>
<li><p>Rather than shelling into the container with <strong><code>apptainer shell</code></strong>, we we can use <strong><code>apptainer exec</code></strong> (invoked outside the container) to run <code>np-version.py</code> inside the container -- even though the file <code>np-version.py</code> is located outside the container. This reports the version of NumPy inside the container:</p>
<pre><code class="fenced-code-block">$ apptainer exec "$SIFS"/pack.sif python np-version.py
numpy version = 2.1.3</code></pre>
<p>This works because the actual program being run is <code>python</code>, which is installed inside the container, and <code>np-version.py</code> is just an input file to <code>python</code>.  Thus our program will be run with the Python version and package environment that exists inside the container.</p>
</li>
</ul>
</li>
</ul>
<h4 class="atx" id="a-container-with-a-local-python-package-installedlessa-iddouble-quotelocal-package-containerdouble-quotegreaterlessagreater">A container with a local Python package installed<a id="local-package-container"></a></h4>
<p>Next we make a container with the local package <strong><code>dcfuncs</code></strong> installed inside it, so this package can be used by Python code outside the container. See <a href="#local-package">Installing a local package</a> above, which shows how <strong><code>dcfuncs</code></strong> is installed and used without a container.</p>
<ul>
<li><p>Make a definition file <strong><code>dfs.def</code></strong> with the following contents:  </p>
<pre><code class="fenced-code-block">Bootstrap: docker
From: continuumio/miniconda3

%files
    dcfuncs /dcfuncs

%post
    conda install numpy matplotlib scipy
    cd /dcfuncs
    pip install .

%runscript
    echo foo!</code></pre>
<p>In addition to the %post section with Linux commands introduced above, this <code>.def</code> file has two new sections:</p>
<ul>
<li><p>The <strong><code>%files</code></strong>  section copies files into the container before the<code> %post</code> commands are run -- each line gives a source directory or file outside the container and a copy location inside the container. </p>
<ul>
<li><p>To <strong>build</strong> (as opposed to run) the container, the <code>dcfuncs</code> repository (directory <code>dcfuncs</code> with its files and subdirectories) must be available on the PC.  For this example copy the repository under the directory containing the definition file:</p>
<pre><code class="fenced-code-block">dfs.def
dcfuncs/
   src/
    ...</code></pre>
</li>
<li><p>As written in <code>dfs.def</code> above the files from <code>dcfuncs</code>  will be written into a directory <code>/dcfuncs</code> in the container.  When the container is built, files can be written anywhere in the container file system as specified by the <code>%files</code> section of the <code>.def</code> file, including in the container's root directory <code>/</code></p>
</li>
</ul>
</li>
<li><p>The <strong><code>%post</code></strong> section runs pip to install the <code>dcfuncs</code> package inside the container.</p>
</li>
<li><p>An Apptainer container is an executable file, and the <strong><code>%runscript</code></strong> section gives the commands that will be executed if it is run.</p>
</li>
</ul>
</li>
<li><p>Build the container, resulting in the 1.4 GB image file <strong><code>dfs.sif</code></strong>:</p>
<pre><code class="fenced-code-block">$ sudo apptainer build "$SIFS"/dfs.sif dfs.def</code></pre>
<p>You will see a warning about running <code>pip</code> as root -- not a problem here as we are in the confines of the container (I believe -- although you can find an extensive discussion of this point online).</p>
</li>
<li><p>The simplest thing we can do with this new container is to run it</p>
<pre><code class="fenced-code-block">$ "$SIFS"/dfs.sif
foo!</code></pre>
</li>
<li><p>Shelling into the container we can use <code>pip list</code> to verify that the dcfuncs package is installed:</p>
<pre><code class="fenced-code-block">$ apptainer shell "$SIFS"/dfs.sif
Apptainer&gt; pip list
Package                  Version
------------------------ -----------
dcfuncs                  1.0
             ...</code></pre>
</li>
<li><p>If we exit the container with <code>ctrl-D</code> and try to run the test code for <code>dcfuncs</code> with Python outside the container, it will fail with <code>module not found</code> (assuming we have not also installed <code>dcfuncs</code> outside the container):</p>
<pre><code class="fenced-code-block">$ python dcfuncs/test/test-util.py
Traceback (most recent call last):
          ...
ModuleNotFoundError: No module named 'dcfuncs'</code></pre>
<p>But now we can use <code>python</code> in the container to run the same test code (which lies outside the container) without error:</p>
<pre><code class="fenced-code-block">$ apptainer exec "$SIFS"/dfs.sif python dcfuncs/test/test-util.py
This is: dutil.py 8/19/24 D.C.
Using: util.py 8/18/24 D.C.

Testing zz:
- WARNING from util.py test code - This is just a warning.
                 ...</code></pre>
<p>  The upshot is that <strong>the</strong> <strong><code>dcfuncs</code> package is available to <code>python</code> running in the container, whether or not <code>dcfuncs</code> is installed outside the container</strong> – and <code>python</code> running in the container can run Python code (<code>.py</code> files) outside the container.</p>
</li>
<li><p>As <a href="#gputest-py">shown earlier in this document</a> if we run <code>gputest.py</code> in the Conda environment <code>gpu</code> then the GPU will be found and used:</p>
<pre><code class="fenced-code-block">..$ cd ...                 # change to directory where gputest.py is located
..$ conda activate gpu
(gpu)..$ python gputest.py 
Running: gputest.py 11/22/23 D.C.
Local time: Tue Jan 7 16:05:53 2025
GPU 0 has compute capacity 6.1, 6 SMs, 4.23 GB RAM, guess model = GeForce GTX 1050
CPU timings use last 10 of 11 trials
GPU timings use last 25 of 28 trials
      ...</code></pre>
<p>Conversely, since we have not installed CuPy inside this container, running the same program with <code>python</code> inside the container will not find CuPy and the GPU, even  if the container is run in the  <code>gpu</code> environment:</p>
<pre><code class="fenced-code-block">(gpu)..$ apptainer exec "$SIFS"/dfs.sif python gputest.py
Running: gputest.py 11/22/23 D.C.
Local time: Tue Jan 7 16:09:24 2025
Import cupy failed, using CPU only
CPU timings use last 10 of 11 trials
      ...</code></pre>
<p>The upshot is that <strong>the environment and packages installed outside the container are not available to <code>python</code> running in the container.</strong> While this may seem like a disadvantage, it fits in with the main objective of containerization -- providing a consistent environment for running code independent of what is installed outside the container.</p>
</li>
</ul>
<h4 class="atx" id="a-container-that-can-use-mpilessa-iddouble-quotempi-containerdouble-quotegreaterlessagreater">A container that can use MPI<a id="mpi-container"></a></h4>
<ul>
<li><p><a href="https://apptainer.org/docs/user/latest/mpi.html">Apptainer and MPI applications</a> in the Apptainer docs explains in some detail how MPI works with Apptainer. Here we give some rather simpler examples showing how Python programs using <strong><code>mpi4py</code></strong> for MPI parallelism can be run with Apptainer.  I have found that if Conda is used to install OpenMPI and MPI for Python (<code>mpi4py</code>) in the container, then it is possible for Python run in multiple containers started by <code>mpirun</code> (from OpenMPI installed outside the containers) to use MPI via <code>mpi4py</code> calls.  This did not require setting any environment variables, unlike the examples in the Apptainer docs referenced above.</p>
</li>
<li><p><strong>Memory usage.</strong> In the examples below the command</p>
<pre><code class="fenced-code-block">$ mpirun -n &lt;n&gt; apptainer exec &lt;container&gt;.sif python &lt;pyscricpt&gt;.py...</code></pre>
<p>is used to run <code>&lt;n&gt;</code> copies of the container image <code>&lt;container&gt;.sif</code>, each of which runs <code>python &lt;pyscript&gt;.py</code>.  As <code>.sif</code> files are one or more GB in size, it might be thought this would require a lot of memory when the number of MPI ranks<code>&lt;n&gt;</code> is large but this is found not be true, see <a href="#dem21-container">below</a>.  I believe this is because the Apptainer container images including their internal file systems are read-only, which allows multiple containers on the same PC to share one copy of the container image.</p>
</li>
<li><p>Make a definition file <strong><code>m4p.def</code></strong> with the following contents. The <code>%post</code> commands in this file are similar to those shown above to <a href="#install-openmpi-pc">install OpenMPI on a PC</a>:</p>
<pre><code class="fenced-code-block">Bootstrap: docker
From: continuumio/miniconda3

%post
    conda install -c conda-forge openmpi=5 mpi4py python=3.12
    conda install -c conda-forge numpy scipy matplotlib</code></pre>
</li>
<li><p>Build the container, resulting in the 1.2 GB image file <strong><code>m4p.sif</code></strong>:</p>
<pre><code class="fenced-code-block">$ sudo apptainer build "$SIFS"/m4p.sif m4p.def</code></pre>
</li>
<li><p>While the container <code>m4p.sif</code> can be built as above without a Conda environment in which MPI is installed, to run the container <strong>MPI must be installed outside the container</strong>.  This is because, as shown in examples below, MPI outside the container is used to run multiple copies of the container on separate cores and to handle communication between these copies. It will work to activate the environment <strong><code>m4p</code></strong> with OpenMPI and other packages <a href="">described above</a> before running the container, but this environment contains things that are not needed outside the container (<code>mpi4py</code>, <code>numpy</code>...).  Here we make a simpler environment <strong><code>ompi</code></strong> that includes only OpenMPI and Python (so pip could be used to install additional things in this environment):</p>
<pre><code class="fenced-code-block">$ conda deactivate
$ conda create -n ompi -c conda-forge openmpi=5 python=3.12
$ conda activate ompi
(ompi)$ mpirun --version
mpirun (Open MPI) 5.0.7</code></pre>
</li>
<li><p>With <code>ompi</code> activated we can use the the container to run <code>mpi_hw.py</code> and <code>osu_bw.py</code>, after switching to a directory that contains these programs:</p>
<pre><code class="fenced-code-block">(ompi)..$ cd python-scripts; ls
mpi_hw.py  osu_by.py ...
(ompi)..python-scripts$ mpirun -n 6 apptainer exec "$SIFS"/m4p.sif python mpi_hw.py
Hello world from rank 0 of 6 on candela-21 running Open MPI v5.0.7
Hello world from rank 3 of 6 on candela-21 running Open MPI v5.0.7
Hello world from rank 5 of 6 on candela-21 running Open MPI v5.0.7
Hello world from rank 4 of 6 on candela-21 running Open MPI v5.0.7
Hello world from rank 2 of 6 on candela-21 running Open MPI v5.0.7
Hello world from rank 1 of 6 on candela-21 running Open MPI v5.0.7
(ompi)..python-scripts$ mpirun -n 2 apptainer exec "$SIFS"/m4p.sif python osu_bw.py
2
2
# MPI Bandwidth Test
# Size [B]    Bandwidth [MB/s]
         1                3.64
         2                7.27
         4               14.58
         8               29.10
        16               56.49
        32              115.74
        64              204.76
       128              372.67
       256              698.36
       512            1,491.48
     1,024            2,902.60
     2,048            5,360.16
     4,096            7,361.31
     8,192           13,089.36
    16,384           21,916.65
    32,768           29,655.28
    65,536           36,365.06
   131,072           40,048.58
   262,144           42,727.54
   524,288           44,050.55
 1,048,576           44,995.58
 2,097,152           45,577.86
 4,194,304           45,258.97
 8,388,608           45,191.11
16,777,216           44,483.20</code></pre>
<p>Things to note in this example:</p>
</li>
<li><p>The command <code>mpirun -n 6 ...</code> is running six separate copies of the container on six cores of the PC.  This <code>mpirun</code> command is running outside the container. This is an example of the "Hybrid model" for running MPI described in the <a href="https://apptainer.org/docs/user/latest/mpi.html">Apptainer docs</a>.</p>
</li>
<li><p>For reasons I don't understand, <code>osu_bw.py</code> reports inter-rank communication speeds about three times faster when run using Apptainer (up to 45 GB/s), than when run <a href="#mpi-testprogs">directly by MPI without Apptainer</a>. </p>
</li>
<li><p>On the <a href="#pcs">hoffice PC</a>, a simple all-in-one PC (but not on the <a href="#pcs">candela-21 PC</a> , assembled from parts) <code>mpirun</code> gives warning messages about the absence of TCP - these can be suppressed by supplying <code>--mca btl ^tcp</code> to <code>mpirun</code>. I think TCP should be irrelevant when running MPI on a single PC, as it is concerned with communication between nodes.</p>
</li>
</ul>
<h4 class="atx" id="a-container-to-run-the-more-elaborate-mpi-package-dem21lessa-iddouble-quotedem21-containerdouble-quotegreaterlessagreater">A container to run the more elaborate MPI package <code>dem21</code><a id="dem21-container"></a></h4>
<p>Here we use containerized code to duplicate the non-containerized tests shown in <a href="#mpi-dem21">More elaborate MPI programs using the <code>dem21</code> package</a> above. Make a definition file <strong><code>dem21.def</code></strong> with the following contents. This is like <code>m4p.def</code> in the previous section, but with the following additions to install the <code>dem21</code>  and <code>msigs</code> packages in the container (see <a href="#local-package-container">A container with a local Python package installed</a> above):</p>
<ul>
<li><p>There is a <code>%files</code> section that will copy the <code>dem21</code> and <code>msigs</code> packages, assumed to be in the directory from which the <code>apptainer build</code> will be run, into the container. </p>
</li>
<li><p>The <code>%post</code> section includes commands that install additional remote packages needed by <code>dem21</code> and install <code>dem21</code>  and <code>msigs</code> as a local packages, as is done without a container in <a href="#mpi-dem21">More elaborate MPI programs using the <code>dem21</code> package</a> above.</p>
<pre><code class="fenced-code-block"># dem21.def 4/1/25 D.C.
# Apptainer .def file for running dem21 DEM simulation package, also
# includes msigs package to creat input signals for granular-memory sims.
Bootstrap: docker
From: continuumio/miniconda3

# Must build this container from a directory containing both dem21
# and msigs repos.
%files
    dem21 /dem21
    msigs /msigs

%post
    conda install -c conda-forge openmpi=5.0.3 mpi4py
    conda install -c conda-forge dill matplotlib numba numpy pyaml scipy
    conda install -c conda-forge quaternion
    cd /dem21
    pip install .
    cd /msigs
    pip install .</code></pre>
</li>
<li><p>A directory <code>buid-dem21</code> is created and <code>dem21.def</code> and the <code>msigs</code>  repo (not publicly available) are copied into it. Then the <code>dem21</code> package (not publicly available) is cloned into this directory and the container is built. This made the 1.3 GB image file <strong><code>dem21.sif</code></strong>:</p>
<pre><code class="fenced-code-block">...build-dem21$ git clone git@github.com:doncandela/dem21.git
...build-dem$ ls
dem21  dem21.def msigs
...build-dem$ sudo apptainer build "$SIFS"/dem21.sif dem21.def</code></pre>
</li>
<li><p>Next we test  that the <code>dem21</code> package can run in the container (see <a href="#mpi-dem21">More elaborate MPI programs using the <code>dem21</code> package</a> above for the corresponding steps without a container, and the previous section <a href="#mpi-container">A container that can use MPI</a> for how MPI is run with a container). We start by activating <strong><code>ompi</code></strong> so OpenMPI will be available outside the containers, and cd'ing to the directory containing the test program <code>boxpct.py</code> and its config file <code>box.yaml</code>:</p>
<pre><code class="fenced-code-block">...buid-dem$ conda activate ompi
(ompi)...build-dem$ cd dem21/tests/box; ls
boxpct.py box.yaml ...</code></pre>
<p>Then we set <code>pproc=mpi</code> so <code>boxpct.py</code> will run in MPI-parallel mode, and use <code>mpirun</code> to run 16 copies of <code>apptainer exec python</code> with <code>boxpct.py</code> as the argument (as usual, <code>SIFS</code> has been set to the directory containing the container image <code>dem21.sif</code>): </p>
<pre><code class="fenced-code-block">(ompi)...tests/box$ export pproc=mpi   # this tells boxpct.py to use MPI
(ompi)...tests/box$ mpirun -n 16 apptainer exec "$SIFS"/dem21.sif python boxpct.py
- Started MPI on master + 15 worker ranks.
THIS IS: boxpct.py 12/3/22 D.C., using dem21 version: v1.2 2/11/25
Parallel processing: MPI, GHOST_ARRAY=True
- Read 1 config(s) from /home/dc/.../tests/box/box.yaml

SIM 1/1:
Using inelastic 'silicone' grainlets with en=0.7 and R=0.500mm
                                ....</code></pre>
</li>
<li><p>Finally, as in the section <a href="#mx2py">A more resource-intensive run...</a> above, we use the container image <code>dem21.sif</code> with <code>mx2.py</code> to run a larger simulation.   The only change required in the shell file <code>mx2.sh</code> in that section that runs the simulation is in the last line, which now uses <code>mpirun</code> to run multiple copies of <code>apptainer exec dem21.sif python</code> rather than multiple copies of <code>python</code>.  This modified shell file is called <strong><code>mx2-app.sh</code></strong>:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# cc-expts-app/mx2-app.sh 4/6/25 D.C.
# Shell script to run granular-memory simulation program mx2.py containerized
# on a PC, as an example for "My cheat sheet for MPI, GPU, Apptainer, and HPC".
#
# Runs mx2.py in grandparent directory in 'mpi' parallel-processing mode.
# Reads default config file mx2.yaml in grandparent directory modified by
# mx2mod.yaml in current directory.
#
# To run on N cores 1st activate environment 'ompi' then do
#
# ./mx2-app.sh N
#
export pproc=mpi
mpirun -n $1 apptainer exec "$SIFS"/dem21.sif python ../../mx2.py mx2mod |&amp; tee output</code></pre>
</li>
<li><p>The simulation is run in precisely the same way as when not containerized, except that it can be run in the bare-bones OpenMPI environment <code>ompi</code> rather than the environment <code>dem21</code> which had <code>dem21</code>, <code>msigs</code>, and other packages installed:</p>
<pre><code class="fenced-code-block">...$ conda activate ompi
(ompi)...$ cd cc-expts-app; ls
mx2mod.yaml  mx2-app.sh ...
(ompi)...cd-expts-app$ sifs               # alias sets SIFS to directory with dem21.sif
(ompi)...cd-expts-app$ ./mx2-app.sh 15    # run containerized code in 15 MPI ranks
- Started MPI on master + 14 worker ranks.
This is: mx2.py 7/29/24 D.C.
Using dem21 version: v1.2 2/11/25
Imput signals made by: memsigs.py 8/23/24 D.C.
Parallel processing mode: MPI, GHOST_ARRAY=True
               ...</code></pre>
<p>This simulation required 17,054s (3.701e-6s/step-grain), which was 7% slower than the <a href="#mx2py">identical simulation done without Apptainer</a>.  Internal timing reported by <code>mx2.py</code> suggested that only 0.9% additional time was used for inter-process communication when Apptainer was used, so it is not clear if the 7% slowdown is actually due to containerization.</p>
<p>Running the simulation in this containerized mode required 2.2 GB of memory, beyond that used before the simulation was started.  This was only slightly more than the memory required to run the simulation without Apptainer, 2.1 GB. This demonstrates clearly that running 16 copies of the 1.3 GB container image <code>dem21.sif</code> does not require 16 times as much memory, due I think to the read-only property of container images.</p>
</li>
</ul>
<h4 class="atx" id="a-container-that-can-use-a-gpulessa-iddouble-quotegpu-containerdouble-quotegreaterlessagreater">A container that can use a GPU<a id="gpu-container"></a></h4>
<ul>
<li><p>Make a definition file <strong><code>gpu.def</code></strong> with the following contents. As in the previous section we start with a Docker image that includes Python, Conda, and the Miniconda distribution and we install NumPy, Matplotlib, and SciPy. Now we also install CuPy, getting it from conda-forge to be sure it is up to date:</p>
<pre><code class="fenced-code-block">Bootstrap: docker
From: continuumio/miniconda3

%post
    conda install numpy matplotlib scipy
    conda install -c conda-forge cupy</code></pre>
</li>
<li><p>Use <code>gpu.def</code> to build the container <strong><code>gpu.sif</code></strong>:</p>
<pre><code class="fenced-code-block">$ sudo apptainer build "$SIFS"/gpu.sif gpu.def</code></pre>
<p>Due to the inclusion of CuPy, this container is considerably larger (3.5 GB vs 1.4 GB without CuPy).  Interestingly, I was able to build this container on  a PC that does not have a GPU (hoffice). Nevertheless when <code>gpu.sif</code> was copied to other computers that did have GPUs (my other PCs and Unity), it was able to use the GPU .</p>
</li>
<li><p>A GPU, the NVIDIA drivers, and CUDA must all be installed <strong>outside</strong> the container on the computer on which the container is to be run -- but it is not necessary for Python packages that will be using the GPU, in this case CuPy, to be installed outside the container.</p>
<ul>
<li>The section <a href="#nvidia-drivers">Installing NVIDIA drivers</a> above shows how to install these things on a PC.</li>
<li>When successfully installed it will be possible to run the shell command <strong><code>nvidia-smi</code></strong> outside the container, which will print information on the installed GPU and CUDA version.</li>
</ul>
</li>
<li><p>As documented in <a href="https://apptainer.org/docs/user/latest/gpu.html">this Apptainer page</a>, <code>apptainer</code> commands that run the container (<code>shell</code>, <code>exec</code>..) must include the <strong><code>--nv</code></strong> option to make CUDA installed outside the container available inside.  Here we are in a directory containing <code>gputest.py</code>, which will successfully import CuPy and use the GPU when run by <code>python</code> in the container <code>gpu.sif</code>:</p>
<pre><code class="fenced-code-block">(base)$ apptainer exec --nv "$SIFS"/gpu.sif python gputest.py
Running: gputest.py 11/22/23 D.C.
Local time: Wed Jan 15 17:54:50 2025
GPU 0 has compute capacity 6.1, 6 SMs, 4.23 GB RAM, guess model = GeForce GTX 1050
CPU timings use last 10 of 11 trials
GPU timings use last 25 of 28 trials

***************** Doing test dense_mult ******************
Multiply M*M=N element dense matrices
*********************************************************

************ Using float64 **************
         N     flop make mats  CPU test *CPU op/s*  GPU test *GPU op/s*  GPU xfer xfer rate
    99,856 6.30e+07 3.31e-03s 4.72e-04s 1.34e+11/s 1.25e-03s 5.04e+10/s 4.00e-03s  0.80GB/s
                                    ...</code></pre>
<p>Using the container, we can run the program <code>gputest.py</code> from the <code>base</code> environment, even though <code>base</code> does not have the packages <code>numpy</code>, <code>scipy</code>, <code>cupy</code> that <code>gputest.py</code> imports installed.</p>
</li>
</ul>
<h2 class="atx" id="part-2-moving-code-to-a-slurm-hpc-clusterlessa-iddouble-quotemove-to-hpcdouble-quotegreaterlessagreater">Part 2: Moving code to a Slurm HPC cluster<a id="move-to-hpc"></a></h2>
<h3 class="atx" id="why-do-itlessa-iddouble-quotewhy-hpcdouble-quotegreaterlessagreater">Why do it<a id="why-hpc"></a></h3>
<p>In general one uses an HPC cluster to get more computational power (e.g. if doing simulations carry out bigger and/or more simulations) than might be otherwise possible, due to one or more of the following factors:</p>
<ul>
<li>For code can only run on one computer but can use multiple cores, an HPC cluster typically will have computers with high core count (up to 128 cores per node on Unity).</li>
<li>For code that can use MPI to run on more than one networked computer, an HPC cluster can offer even larger core counts since a cluster consists of many computers networked together.</li>
<li>For code that can use a GPU to speed up computations, an HPC cluster may include higher-performance models of GPU than otherwise available.</li>
<li>For code that requires a lot of memory, HPC clusters are typically configured with considerable memory.</li>
<li>Even if none of the situations above is true, multiple jobs can be run simultaneously on an HPC cluster.</li>
</ul>
<p>However, the individual CPUs in an HPC cluster are typically no faster than those in a desktop PC (sometimes slower, as HPC computers are optimized for reliability) -- so there may be little advantage to running code that is not parallelized with either MPI or utilization of a GPU on an HPC cluster, apart from the higher core count of individual computers and the possibility of running multiple jobs simultaneously.</p>
<p>Finally, the computational resources of an HPC cluster are only useful if available within reasonably short times waiting in queue. Jobs requiring many computers or the fastest GPUs may sit a long time before starting.</p>
<h3 class="atx" id="unity-cluster-at-umass-amherstlessa-iddouble-quoteunity-clusterdouble-quotegreaterlessagreater">Unity cluster at UMass, Amherst<a id="unity-cluster"></a></h3>
<h4 class="atx" id="historylessa-iddouble-quoteunity-historydouble-quotegreaterlessagreater">History<a id="unity-history"></a></h4>
<ul>
<li>Before Unity was created the HPC cluster available to UMass Amherst researchers was the <strong>UMass Shared Cluster (UMSC)</strong>.  UMSC was administered by UMass Medical School, and ran Redhat Linux and the IBM LSF scheduling system.  UMSC was shut down in 3/23.</li>
<li>As of 1/25 the HPC cluster for general UMass use is <a href="https://unity.rc.umass.edu/"><strong>Unity</strong></a> (started in early 2022) located (as UMSC was) at the <a href="https://www.mghpcc.org/"><strong>MGHPCC</strong></a> in Holyoke. Unity runs <a href="https://ubuntu.com/"><strong>Ubuntu</strong></a> (24.04 as of 1/25) and the <a href="https://slurm.schedmd.com/documentation.html"><strong>Slurm</strong></a> scheduling system. </li>
</ul>
<h4 class="atx" id="logging-inlessa-iddouble-quoteunity-logindouble-quotegreaterlessagreater">Logging in<a id="unity-login"></a></h4>
<ul>
<li><p><strong>Logging with SSH.</strong> To login to Unity from a terminal program on a remote PC, <strong>SSH keys must be set up</strong> - here are the <a href="https://docs.unity.rc.umass.edu/documentation/connecting/ssh/">instructions in the Unity docs</a>.  While a bit of a pain to set up, SSH is convenient to use and is necessary to enable usage of the <code>scp</code> and <code>rsync</code> file transfer commands described below.</p>
<ul>
<li><p><strong>Setting up keys to allow login to unity from PC.</strong> Here <strong><code>&lt;user&gt;</code></strong> is a user name on a Linux PC, while <strong><code>&lt;userc&gt;</code></strong> is a user name on Unity (assigned by Unity admins, typically of form <code>netid_umass_edu</code>):</p>
<ul>
<li><p>In a browser go to <a href="https://docs.unity.rc.umass.edu/">https://docs.unity.rc.umass.edu/</a> and login with netid/pw.</p>
</li>
<li><p>In the  <strong>Account Setting</strong> page click <strong><code>[   +   ]</code></strong>. </p>
</li>
<li><p>In the <strong>Add New Key</strong> popup selected <strong>Generate key</strong>, <strong>OpenSSH</strong>.</p>
</li>
<li><p><strong>Save the key on your PC in <code>~/.ssh</code></strong> with desired name, e.g. <code>~/.ssh/unity.key</code>.</p>
</li>
<li><p>Set the permissions of the key file so only the owner can read/write, otherwise ssh will refuse to use it:</p>
<pre><code class="fenced-code-block">user:~/.ssh$ chmod 600 unity.key</code></pre>
</li>
<li><p>Add following lines to <code>~/.ssh/config</code>, creating this file if necessary :</p>
<pre><code class="fenced-code-block">Host unity
    HostName unity.rc.umass.edu
    User &lt;userc&gt;
    IdentityFile ~/.ssh/unity.key</code></pre>
</li>
<li><p>SSH will set up and maintain the file <code>~/.ssh/known_hosts</code></p>
</li>
<li><p>There is a way (not shown here) to store the private key in encrypted form, such that a password will be required to use it.</p>
</li>
</ul>
</li>
<li><p>Now we can <strong>login to Unity the PC</strong> (will not request a password, unless the private key is encrypted):</p>
<pre><code class="fenced-code-block">&lt;user&gt;:~$ ssh unity      # we start in a bash shell on the PC
&lt;userc&gt;@login2:~$        # now we are in bash shell on Unity, ctrl-d to logout</code></pre>
</li>
<li><p>Login to Unity from one of my PCs was set up as above and previously working -- but when I tried to login 12/24 I got warning and refusal to login:</p>
<pre><code class="fenced-code-block">(base) dc:~$ ssh unity
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
                     ...</code></pre>
<p>Later (2/25), from another PC, I got a different error message that sounded like there was a temporary problem that someone else would fix, but that was not the case:</p>
<pre><code class="fenced-code-block">(base) dc:~$ ssh unity
ssh: Could not resolve hostname unity: Temporary failure in name resolution</code></pre>
<p>In both cases this was fixed this by following the instructions above to generate a new key (including the <code>chmod 600 ... command</code>).</p>
</li>
</ul>
</li>
<li><p><strong>Logging in with Unity OnDemand.</strong>  The <strong>Shell, &gt;_Unity Shell Access</strong> menu item of <a href="https://ood.unity.rc.umass.edu/pun/sys/dashboard"><strong>Unity OnDemand</strong></a> opens a login shell (in a browser window, not a terminal) without using ssh (Unity OnDemand is accessed with <code>netid</code> and <code>pw</code>). This is reasonably convenient for all platforms and also allows logging into Unity from Windows without setting up ssh keys and without software beyond a browser.  But there seem to be some limitations on what can be done from this browser-window shell.</p>
</li>
</ul>
<h4 class="atx" id="storagelessa-iddouble-quoteunity-storagedouble-quotegreaterlessagreater">Storage<a id="unity-storage"></a></h4>
<ul>
<li>Here is the <a href="https://docs.unity.rc.umass.edu/documentation/cluster_specs/storage/">Unity doc page</a> on storage.</li>
<li>As of 1/25, the “Base quotas” (free initial tier) given to users are:<ul>
<li>50 GB of HDD in <strong><code>/home/&lt;userc&gt;</code></strong> with <code>&lt;userc&gt;</code> the Unity username, intended for user init files (like scripts for sbatch, I guess), not large-scale job I/O.</li>
<li>1 TB of SDD in <strong><code>/work/pi_&lt;userc&gt;</code></strong> intended for job I/O, shared between users in a PI’s group.</li>
<li>Upon request, 5 TB HDD in <strong><code>/project/pi_&lt;userc&gt;</code></strong> intended to store e.g. job output from /work but not for direct job I/O.</li>
<li>Without special permission users can allocate up to 50 TB of high-performance (job I/O) scratch space lasting up to 30 days in <strong><code>/scratch</code></strong>.</li>
<li>Previously (7/22) there were <strong><code>/work/&lt;userc&gt;</code></strong> directories  rather than <strong><code>work/pi_&lt;userc&gt;</code></strong> for job I/O, but these have been discontinued.</li>
</ul>
</li>
</ul>
<h4 class="atx" id="transferring-files-tofrom-unity-lessa-iddouble-quoteunity-file-transferdouble-quotegreaterlessagreater">Transferring files to/from Unity <a id="unity-file-transfer"></a></h4>
<ul>
<li><p><strong>Graphical:</strong> Files can be transferred using the graphical <a href="https://ood.unity.rc.umass.edu/pun/sys/dashboard"><strong>Unity OnDemand</strong></a>.  There may be some limitations on file size - using drag-and-drop I successfully transferred a 1.4 GB file from home (slower internet than work) but attempts to transfer a 3.5 GB file repeatedly failed.</p>
</li>
<li><p><strong>CLI:</strong> The following commands are part of OpenSSH and <strong>require ssh keys to be set up</strong> as shown above. Then the <strong><code>rsync</code></strong> and <strong><code>scp</code></strong> commands shown here can be run on the PC. Some info on using these commands with Unity is on <a href="https://docs.unity.rc.umass.edu/documentation/managing-files/cli/">this page</a>.</p>
<ul>
<li><p>Use <strong><code>scp</code></strong> to copy an individual file <code>localfile</code> on the PC to a the cluster:</p>
<pre><code class="fenced-code-block">$ scp &lt;localfile&gt; unity:~/&lt;subdirec&gt;                  # copy under directory /home/&lt;userc&gt;/
$ scp &lt;localfile&gt; unity:/work/&lt;direc&gt;/&lt;subdirec&gt;      # copy under group working directory</code></pre>
<p>Unlike Unity OnDemand drag-and-drop, scp successfully copied a 3.5 GB file to Unity from my home PC with its slow internet  uplink (took 23 min).</p>
</li>
<li><p>Similarly use <strong><code>scp</code></strong> to copy an individual file <code>remotefile</code> on the cluster to the current directory on the PC (note the period indicating the current directory):</p>
<pre><code class="fenced-code-block">$ scp unity:/work/&lt;direc&gt;/remotefile .</code></pre>
</li>
<li><p>To <strong>copy a directory and all its contents</strong>, use the <strong><code>-r</code></strong> flag on scp</p>
<pre><code class="fenced-code-block">$ scp -r &lt;source directory&gt; &lt;target directory&gt;</code></pre>
</li>
<li><p>Be careful when using <strong><code>scp</code></strong>, especially with the <strong><code>-r</code></strong> flag, as <strong>it will overwrite existing files on the destination computer</strong> -- it seems not to have a flag to inhibit this.</p>
</li>
<li><p>You can also use <strong><code>rysnc</code></strong> to transfer a whole directory including subdirectories between a Linux PC and Unity.  Unlike <code>scp</code>, with appropriate flags <code>rsync</code> can be run repeatedly and will only update files that have been changed.  I used <code>rsync</code> on the old UMSC HPC cluster, but I haven't tried it yet  on Unity.</p>
</li>
</ul>
</li>
<li><p><strong>Cloning repos from GitHub (GH).</strong>  As of 2/25 I don't see information about this in the <a href="https://docs.unity.rc.umass.edu/documentation/">Unity docs</a>, but this was figured out by consulting with someone at Unity help and looking at at <a href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh/using-ssh-agent-forwarding">this webpage</a> from GitHub. As in other places in this document <code>&lt;user&gt;..$</code> denotes input to a shell on the PC, while <code>&lt;userc&gt;..$</code> denotes input to a shell on Unity -- I have only tried these commands on a Unity login node, but they might also work on a compute node.</p>
<ul>
<li><p><strong>Cloning from public GH repo.</strong>  This can be done with no special setup by using the <code>git clone</code> command  on Unity with the  HTTPS address of the repo, available in the <strong><code>&lt;&gt; Code</code></strong> tab of the GH page for the repo.  For example, to clone the public repo <code>doncandela/dcfuncs</code> into a directory <code>foo</code> under <code>/work/pi_&lt;userc&gt;</code> do</p>
<pre><code class="fenced-code-block">&lt;userc&gt;..foo$ git clone https://github.com/doncandela/dcfuncs.git</code></pre>
<p>This command resulted in the creation on Unity of the subdirectory <code>foo/dcfuncs</code>, containing this GH repo including its <code>.git</code> file (which is managed by Git and holds the repo history). </p>
</li>
<li><p><strong>Cloning from private GH repo.</strong> It's assumed here this a private repo to which you have SS access -- for example a repo that belongs to you.  It seemed that the easiest way was to use <strong>SSH agent forwarding</strong>, which allows Unity (while you are logged in) to use the SSH keys from your PC to authenticate to GH.  First check that you have SSH access to GH from your PC:</p>
<pre><code class="fenced-code-block">&lt;user&gt;..$ ssh -T git@github.com
Hi doncandela! You've successfully authenticated, but GitHub does not provide shell access.</code></pre>
<p>Still on the PC, edit (or create) the file  <code>~/.ssh/config</code> to enable SSH agent forwarding. From previously setting up SSH access to GH I found that this file was present on my PCs with a block for Unity,  to which I added the last line shown here:</p>
<pre><code class="fenced-code-block">Host unity
     HostName unity.rc.umass.edu
     User candela_umass_edu                  # will be your Unity username &lt;userc&gt;
     IdentityFile ~/.ssh/2025-01-unity.key   # will be your SSH key file for Unity
     ForwardAgent yes                        # this is the new line added</code></pre>
<p>It will be necessary to do this on <strong>every PC</strong> that you will use to SSH into Unity and then tell Unity to clone from GH, and you will need to disconnect form Unity and SSH into it again for this to take effect.</p>
<p>After you do this you will be able do the same check on Unity as was done on the PC that you have SSH access to GH:</p>
<pre><code class="fenced-code-block">&lt;userc&gt;..$ ssh -T git@github.com
Hi doncandela! You've successfully authenticated, but GitHub does not provide shell access.</code></pre>
<p>However, the <em>first</em> time you try to access GH from your Unity account you will need to answer <code>yes</code> to a multiline message like this:</p>
<pre><code class="fenced-code-block">&lt;userc&gt;..$ ssh -T git@github.com
The authenticity of host 'github.com (140.82.114.3)' can't be established.
ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU.
This key is not known by any other names.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes</code></pre>
<p>Now, on Unity you can clone a private GH repo you have access to like <code>doncandela/dem21</code> by using the repo's SSH address (also available the <strong><code>&lt;&gt; Code</code></strong> tab of the GH page for the repo):</p>
<pre><code class="fenced-code-block">&lt;userc&gt;..foo$ git clone git@github.com:doncandela/dem21.git</code></pre>
<p>This creates the subdirectory <code>foo/dem21</code> on Unity with a clone of the repo.</p>
</li>
</ul>
</li>
<li><p><strong>Seeing how big the transferred files are.</strong> To see the size on Unity storage of a whole set of directories and subdirectories with their contents (for example as transferred using <code>scp -r ...</code> of by cloning a GitHub repo) use the <code>du</code> command:</p>
<pre><code class="fenced-code-block">&lt;userc&gt;...foo$ du -h
0    ./dem21/.git/branches
     ...
6.5K    ./dem21/tests/mpi
473K    ./dem21/tests
10M    ./dem21
10M    .</code></pre>
<p>Variants: <code>du -h</code> as shown above will show the sizes of directories only, while <code>du -ah</code> will also show the sizes of all files in the directories.</p>
</li>
</ul>
<h4 class="atx" id="slurm-on-unitylessa-iddouble-quoteunity-slurmdouble-quotegreaterlessagreater">Slurm on Unity<a id="unity-slurm"></a></h4>
<ul>
<li><p>Some Slurm resources:</p>
<ul>
<li><a href="https://slurm.schedmd.com/quickstart.html">Quick Start User Guide</a> in the <a href="https://slurm.schedmd.com/documentation.html">Slurm docs</a>.</li>
<li><a href="https://docs.unity.rc.umass.edu/documentation/get-started/hpc-theory/threads-cores-processes-sockets/">Overview of threads, cores, and sockets in Slurm</a> in the <a href="https://docs.unity.rc.umass.edu/documentation/">Unity docs</a>.</li>
<li>Stanford tutorial <a href="https://stanford-rc.github.io/docs-earth/docs/slurm-basics">SLURM Basics</a>.</li>
<li>A list of <a href="https://docs.rc.fas.harvard.edu/kb/convenient-slurm-commands/">Convenient Slurm Commands</a>  with detailed instructions from Harvard.</li>
<li><a href="http://acadix.biz/RCUG/HTML/index.html">Research Computing User's Guide</a> (esp Ch. 11 "Job Scheduling with SLURM").</li>
<li>A few more advanced resources are linked in <a href="#run-batch">Running batch jobs</a> below.</li>
</ul>
</li>
<li><p>The nodes in a Slurm cluster are assigned to <strong>partitions</strong>, and one or more partitions are specified when a job is submitted.  Slurm allows a node to be assigned to multiple partitions, but I don’t think this is done much on Unity except that some <code>gpu</code> nodes are also in <code>cpu</code>, etc.  Here are the <strong>x86_64 general-access and preempt <a href="https://docs.unity.rc.umass.edu/documentation/cluster_specs/partitions/">partitions on Unity</a></strong> (numbers and best GPUs as of 1/25):</p>
<table>
<thead>
<tr>
<th>Partition</th>
<th>Nodes</th>
<th>Total cores</th>
<th>Cores/node</th>
<th>Mem/node</th>
<th>GPUs/node</th>
<th>Best GPUs</th>
</tr>
</thead>
<tbody><tr>
<td><code>cpu</code></td>
<td>181</td>
<td>10,240</td>
<td>24-64</td>
<td>180-1,000 GB</td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>cpu-preempt</code></td>
<td>146</td>
<td>9,424</td>
<td>24-192</td>
<td>30-1,510 GB</td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>gpu</code></td>
<td>156</td>
<td></td>
<td>12-128</td>
<td>180-370 GB</td>
<td>2-4</td>
<td>NVIDIA V100</td>
</tr>
<tr>
<td><code>gpu-preempt</code></td>
<td>198</td>
<td></td>
<td>64-128</td>
<td>500-2010 GB</td>
<td>6-8</td>
<td>NVIDIA A100, H100</td>
</tr>
</tbody></table>
<ul>
<li><p>Job <a href="#wall-cpu-time">wall-time</a> limits:</p>
<ul>
<li><p>All partitions have a <strong>default time limit of one hour</strong>, in effect when <code>#SBATCH -t=..</code> is not used.</p>
</li>
<li><p>The nodes in <strong>preempt partitions</strong> belong to specific groups and jobs submitted outside the owning groups can be killed after two hours.  So, unless checkpointing is used to enable a job to pick up where it left off, general users should typically <strong>submit jobs with time limits less than 2 hours to the preempt partitions</strong>.</p>
</li>
<li><p>The <strong>maximum time limit is 2 days</strong> for all of these general-access partitions unless <strong><code>-q=long</code></strong> is set in the sbatch script which case the maximum time limit is <strong>14 days (336 hours)</strong>.</p>
</li>
<li><p>From the Unity docs I think the following are true but I’m not 100% sure:</p>
<ul>
<li><p>If a job does start on a preempt partition, it will not be killed before 2 hours of run time.</p>
</li>
<li><p>To get more chance of scheduling sbatch script can list more than one partition, e.g</p>
<pre><code class="fenced-code-block">#SBATCH -p=cpu,cpu-prempt</code></pre>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Jobs submitted to the <code>gpu</code> or <code>gpu-preempt</code> partitions will be rejected if they do not request GPUs using e.g. <code>#SBATCH -G=..</code>.</p>
</li>
</ul>
</li>
<li><p>Some useful Slurm commands:</p>
<pre><code class="fenced-code-block">$ squeue --me                    # show info on my jobs
$ sacct -j &lt;jobid&gt;               # show more detailed info on a specific job
$ scancel &lt;jobid&gt;                # kill one of my jobs.
$ seff &lt;jobid&gt;                   # show utilization efficiency of a completed job
$ sinfo -p cpu -r -l             # show status of nodes in partition cpu
$ scontrol show partition cpu    # detailed info on partition cpu
$ scontrol show node cpu029      # detailed info on node cpu029
$ scontrol show config           # show slurm configuration including default values</code></pre>
</li>
<li><p>Some useful scripts to see current usage/availablilty of resources on Unity, <a href="https://docs.unity.rc.umass.edu/documentation/jobs/helper_scripts/">more are here</a>.</p>
<pre><code class="fenced-code-block">$ unity-slurm-partition-usage  # show how many idle cores and gpus in each partition
$ unity-slurm-node-usage       # for each node show idle cores and gpus, partition is in
$ unity-slurm-account-usage    # show cores and gpus my group is currently using
$ unity-slurm-find-nodes a100  # show nodes with specified constraint (here A100 GPUs)
$ unity-slurm-find-nodes a100 | unity-slurm-node-usage    # show idleness of nodes with
                                                          # specified constraint</code></pre>
</li>
</ul>
<h4 class="atx" id="running-jobs-interactively-salloc-or-unity-computelessa-iddouble-quoterun-interactivedouble-quotegreaterlessagreater">Running jobs interactively: <code>salloc</code> or <code>unity-compute</code><a id="run-interactive"></a></h4>
<ul>
<li><p>You are not supposed to run interactive jobs on a login node.  Instead, from the login-node shell, issue a command like</p>
<pre><code class="fenced-code-block">$ salloc -c 6 -p cpu</code></pre>
<p>to allocate 6 cores on a node in the <code>cpu</code> partition and start an interactive shell on that node -- when the compute node is allocated (which seems to take at least a few seconds, sometimes longer) you will see the node name in the prompt. Similarly to allocate 6 cores and one GPU on a node in the <code>gpu</code> partition do</p>
<pre><code class="fenced-code-block">$ salloc -c 6 -G 1 -p gpu</code></pre>
<p>In either case use <code>ctrl-d</code> to exit back to the login-node shell.</p>
</li>
<li><p>There is another way to do this using <code>srun -pty bash</code>, but the way shown above with <code>salloc</code> seems to be recommended.  However Unity does provide a command <code>unity-compute</code> that gets a shell on a compute node in this way:</p>
<pre><code class="fenced-code-block">$ unity-compute         # get a compute-node shell with default 2 cores
$ unity-compute 6       # get a compute-node shell with 6 cores</code></pre>
</li>
</ul>
<h4 class="atx" id="using-bashrc-and-bash_aliaseslessa-iddouble-quoterc-filesdouble-quotegreaterlessagreater">Using <code>.bashrc</code> and <code>.bash_aliases</code><a id="rc-files"></a></h4>
<ul>
<li><p>The file <strong><code>~/.bashrc</code></strong> is executed whenever an interactive shell is started (when logging in, when using <code>salloc</code> to open an interactive shell on a compute node...).</p>
</li>
<li><p>If it exists <strong><code>~/.bash_aliases</code></strong> will be run by <code>~./bash_rc</code>, so this file is a good place to add alias commands without messing with the more complex <code>.bashrc</code>.</p>
<ul>
<li><p>This shows the contents of a typical .bash_aliases file:</p>
<pre><code class="fenced-code-block">$ cat .bash_aliases
# ~/.bash_aliases for unity 1/11/25 D.C.

# go to work directory
alias wcd='cd /work/pi_candela_umass_edu'

# get 6 cores on a non-gpu compute node and start an interactive shell
alias ish='salloc -c 6 -p cpu'

# get 6 cores and a GPU on a gpu compute node and start an interactive shell
alias ishg='salloc -c 6 -G 1 -p gpu'</code></pre>
</li>
<li><p>To see a list of defined aliases: <code>$ alias</code></p>
</li>
</ul>
</li>
</ul>
<h4 class="atx" id="using-modules-and-condalessa-iddouble-quoteunity-modules-condadouble-quotegreaterlessagreater">Using modules and Conda<a id="unity-modules-conda"></a></h4>
<ul>
<li><p><strong>Modules on an HPC system.</strong></p>
<ul>
<li><p>HPC systems like Unity have a <a href="https://docs.unity.rc.umass.edu/documentation/software/modules/"><strong><code>modules</code></strong></a> system installed  that sets the environment so desired versions of software are available.  Loading a module is much like activating a Conda environment: It typically sets <code>PATH</code> and other environment modules and can also take other actions.   </p>
<ul>
<li>The main difference is that modules are created by the HPC system admins to point to software packages installed by them in system space, and to run those packages correctly on the HPC system.</li>
<li>Conversely Conda environments are created by the user, install packages in user space, and must be configured by the user to work correctly.</li>
<li>It's not unusual to load some modules to make things like MPI, CUDA, and Conda itself available, and then to activate a Conda environment with specific code and packages needed.</li>
</ul>
</li>
<li><p>A few useful module commands (to be entered in a shell before running code; also <code>module purge</code> and <code>module load</code> commands are typically included in <a href="#run-batch">sbatch scripts</a>:</p>
<pre><code class="fenced-code-block">$ module av python               # show all python modules available
$ module spider python           # another way to show available python modules
$ module spider python/3.11.7    # shows which other modules must be loaded before this one (in this case none)
$ module load python/3.11.7      # load one of the python modules
$ module show python/3.11.7      # show what is in a particular module
$ module list                    # list which modules are loaded
$ module purge                   # unload all modules</code></pre>
</li>
</ul>
</li>
<li><p><strong>Using Conda on an HPC system.</strong><a id="conda-hpc"></a></p>
<ul>
<li><p>You must start by loading the <strong>Conda module</strong>.  Then <code>conda</code> commands can be used to create and activate Conda environments. Both <code>conda install</code> and <code>pip install</code> can be used in a Conda environment to install packages in that environment (see <a href="#pip-conda">Pip and Conda</a> above). </p>
</li>
<li><p>In this example an environment <strong><code>npsp</code></strong> is created with NumPy, SciPy, Matplotlib, and a version of Python earlier than the one installed outside of environments. These commands take some time and probably should be <strong><a href="#run-interactive">run on a compute node</a></strong>, not a login node. </p>
<pre><code class="fenced-code-block">$ python --version
Python 3.12.3
$ module load conda/latest
$ conda create -n npsp python=3.11
$ conda activate npsp
(npsp)$ conda install numpy scipy matplotlib
(npsp)$ python --version
Python 3.11.11
(npsp)$ pip list
Package         Version
--------------- --------y
matplotlib      3.10.0
numpy           2.2.1
scipy           1.15.1</code></pre>
</li>
<li><p>A created environment like <code>npsp</code> will persist across logins to Unity, but the <code>module load conda/latest</code>  command must be executed in every new shell before a <code>conda</code> command such as activating a previously created environment can be given.</p>
</li>
<li><p>It seems that on Unity Conda environments are always stored in <code>/work/&lt;userc&gt;/.conda</code> no matter which directory they were created from, and (conveniently) they are usable from both <code>/home</code> and <code>/work</code> directories.</p>
</li>
</ul>
</li>
<li><p><strong>Installing a local package on Unity.</strong></p>
<ul>
<li><p>This is done much the same way as installing a local package on a PC, as <a href="#local-package">shown above</a>.</p>
</li>
<li><p>Following the same example as in that section, the repository for the <strong><code>dcfuncs</code></strong> package is cloned to a directory <code>work/pi_&lt;userc&gt;...clones/dcfuncs</code> on Unity. Then a Conda environment <strong><code>dfs</code></strong> is created and NumPy and  <code>dcfuncs</code> are installed in that environment.</p>
<pre><code class="fenced-code-block">$ unity-compute                          # get shell on a compute node
(wait for the compute-node shell to come up)
$ module load conda/latest
$ conda create -n dfs python=3.12
$ conda activate dfs
(dfs)..$ conda install numpy              # needed by dcfuncs
(dfs)..$ cd ..clones                      # go to directory where will put clone
(dfs)..clones$ git clone https://github.com/doncandela/dcfuncs.git
(dfs)..clones$ cd dcfuncs; ls             # go into the cloned repo
LICENSE  README.md  pyproject.toml  setup.py  src  test
(dfs)...clones/dcfuncs$ pip install -e .  # install dcfuncs to current environment
(dfs)...clones/dcfuncs$ pip list
Package    Version Editable project location
---------- ------- ------_---------------------
dcfuncs    1.0     /work/pi_&lt;userc&gt;/.../dcfuncs
numpy      2.2.2
pip        24.3.1
setuptools 75.8.0
wheel      0.45.1</code></pre>
</li>
<li><p>Now that the environment <code>dfs</code> has been created, we can log completely out of Unity.  The environment it will persist and with it activated <code>dcfuncs</code> is available for importing in any directory. In a new login:</p>
<pre><code class="fenced-code-block">$ unity-compute                       # get shell on a compute node
(wait for the compute-node shell to come up)
$ module load conda/latest
$ conda activate dfs
(dfs)...$ cd ...clones/dcfuncs/test   # go to test-code directory in cloned repo
(dfs)...test$ ls
test-configs.py  test-util.ipynb  test-util.py  test0.yaml  test1.yaml
(dfs)...test$ python test-util.py     # we can run this program that imports dcfuncs
This is: dutil.py 8/19/24 D.C.
Using: util.py 8/18/24 D.C.

Testing zz:
- WARNING from util.py test code - This is just a warning.

Testing stoi:
stoi results = 93801881091158, 6318, 249613385242335
                       ...</code></pre>
</li>
</ul>
</li>
</ul>
<h4 class="atx" id="running-batch-jobs-sbatchlessa-iddouble-quoterun-batchdouble-quotegreaterlessagreater">Running batch jobs: <code>sbatch</code><a id="run-batch"></a></h4>
<ul>
<li><p>To run a background job on Unity an <strong>sbatch script</strong> e.g <code>myjob.sh</code> is created then the job is submitted to Slurm using</p>
<pre><code class="fenced-code-block">$ sbatch myjob.sh</code></pre>
</li>
<li><p>If desired the <code>sbatch</code> command can be run on a login node as it simply submits the job for scheduling -- the job itself is run on compute nodes chosen based on the parameters in the sbatch script.</p>
</li>
<li><p>If the script results in job output being written to the CWD then it will typically be run in a subdirectory of <code>/work/pi_&lt;userc&gt;</code>, which has room for large job output.</p>
</li>
<li><p>Here are the contents of a simple sbatch script:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# Example sbatch script - can put comments like this on any line.
#SBATCH -c 4                  # use 4 cores per task
#SBATCH -p cpu                # submit job to partition cpu
##SBATCH -p cpu-preempt        # submit job to partition cpu-preempt (this is commented out)
module purge                  # unload all modules
module load python/3.12       # load version of Python needed
python myscript.py &gt; output   # run myscript.py sending its output to a file</code></pre>
<p>  Notes on this script:</p>
<ul>
<li><p>The first line <code>#!/bin/bash</code> indicates Bash should be used to interpret the file (you could use a different shell).</p>
</li>
<li><p>The sbatch script is a regular shell file except that lines that <strong>start with <code>#SBATCH</code></strong> (exactly like this, in all caps) are interpreted specially by the <code>sbatch</code> command.  This means <code>#SBATCH</code> lines can be commented out by doubling the initial <code>#</code>, as shown above.</p>
</li>
<li><p>The <code>#SBATCH</code> lines, which give information to Slurm on how to schedule the job, must come before any regular shell commands.  Any <code>#SBATCH</code> lines after other shell commands other than comments are ignored.</p>
</li>
<li><p>The remainder of the sbatch script is ordinary shell commands.  Typically these could load modules as needed, then run the desired program.</p>
</li>
<li><p>The Conda module must be loaded before activating a Conda environment, so the sbatch script might have lines like:</p>
<pre><code class="fenced-code-block">module load conda/latest
conda activate myenv</code></pre>
</li>
<li><p>Programs can be run directly in the script as shown above, or as arguments to the Slurm command <code>srun</code> on a line in the script like this:</p>
<pre><code class="fenced-code-block">srun python myscript.py &gt; output</code></pre>
<p>Using <code>srun</code> establishes a <strong>job step</strong> and can also launch <strong>multiple copies of the program</strong> as separate tasks if <code>#SBATCH -n ..</code> was used to specify more than one task – see <a href="https://groups.oist.jp/scs/advanced-slurm">this page</a> for more info.</p>
</li>
<li><p>MPI programs can be run using <code>srun</code> or <code>mpirun</code>.  Note <code>srun</code> is a Slurm command that can start multiple copies of any program, whether or not MPI is available.  Conversely <code>mpirun</code> is only available in an environment in which MPI is available, see <a href="#unity-mpi">Using MPI on Unity</a> below.</p>
<p>This starts 10 copies of <code>myscript.py</code> as separate tasks:</p>
<pre><code class="fenced-code-block">mpirun -n 10 python myscript.py &gt; output</code></pre>
<p>while this sets the number of copies (MPI tasks) according to the <code>#SBATCH -n=...</code> setting:</p>
<pre><code class="fenced-code-block">mpirun python myscript.py &gt; output</code></pre>
<p>The second form is probably preferable unless there is some reason to have <code>mpirun</code> to create less tasks than were allocated by <code>#SBATCH -n ..</code>.</p>
</li>
</ul>
</li>
<li><p>Some resources for writing sbatch scripts, especially on choosing and setting #SBATCH parameters:</p>
<ul>
<li>In Unity docs: <a href="https://docs.unity.rc.umass.edu/documentation/jobs/sbatch/">Introduction to batch jobs</a>,  <a href="https://docs.unity.rc.umass.edu/documentation/get-started/hpc-theory/threads-cores-processes-sockets/">Overview of threads, cores and sockets</a>, and <a href="https://docs.unity.rc.umass.edu/documentation/jobs/slurm/">Slurm cheat sheet</a>.</li>
<li>In official Slurm docs: <a href="https://slurm.schedmd.com/sbatch.html">sbatch options</a> (there are many).</li>
<li>A <a href="https://hpc.llnl.gov/banks-jobs/running-jobs/slurm-quick-start-guide">quick-start guide</a> from Lawrence Livermore National Lab. Warning: some things here are particular to LLNL, won’t apply to Unity.</li>
<li><a href="https://docs-research-it.berkeley.edu/services/high-performance-computing/user-guide/running-your-jobs/scheduler-examples/">Examples of sbatch scripts for different kinds</a> of jobs from Berkeley (same warning).</li>
<li>Some <a href="https://groups.oist.jp/scs/advanced-slurm">more advanced Slurm topics</a> (array jobs, using srun in sbatch scripts to run multiple copies of one or more programs…) from Okinawa Institute of Science and Technology.</li>
</ul>
</li>
<li><p>In Slurm, a <strong>task</strong> can use one or more <strong>cores</strong> (which are called cpu’s in #SBATCH settings), but a task always lives on a single <strong>node</strong>, which typically means a single "computer" -- one or two CPU chips on a board with shared RAM and other resources like GPUs.  On the other hand, a single node can run multiple tasks if it has enough cores. </p>
<ul>
<li>For a <strong>non-MPI job</strong> there might be a <strong>single task</strong> (possibly multi-core), which therefore uses part or all of a <strong>single node</strong>.  These match the Slurm default <code>#SBATCH n=1</code> which will automatically live on one node.</li>
<li>For an <strong>MPI job</strong> (for which Slurm was originally conceived) there will ordinarily be <strong>more than one task</strong> and <strong>each task corresponds to an MPI rank, running an independent copy of the code.</strong>  I believe these tasks might run on one or more nodes unless <code>#SBATCH -N=...</code> is used to fix the number of nodes.</li>
<li><a href="https://groups.oist.jp/scs/advanced-slurm">This page</a> shows how <strong><code>srun</code></strong> can be used to run multiple copies of a program that don't communicate using MPI -- thus <strong>more than one task</strong> (I haven't tried this).</li>
</ul>
</li>
<li><p>Here are some #SBATCH settings useful for both single-task (non-MPI) and multi-task (MPI) jobs.  Note many command have two equivalent forms: a single-dash+single-letter form that does not need an equals sign, and a double-dash+multi-letter form that takes an equal sign before any supplied value.</p>
<pre><code class="fenced-code-block">#SBATCH -J &lt;name&gt;           # set a name for job, otherwise will be script filename
#SBATCH --job-name=&lt;name&gt;   # “ “

#SBATCH -o &lt;ofname&gt;         # set filename for output, otherwise will be slurm-&lt;jobid&gt;.out
#SBATCH --output=&lt;ofname&gt;   # “ “
#SBATCH -e &lt;efname&gt;         # set filename for error output, otherwise will go to output file
#SBATCH --error=&lt;name&gt;      # “ “

#SBATCH --mail-type=END     # send email to submitting user when job ends
#SBATCH --mail-type=ALL     # send email when job starts, ends, or fails

#SBATCH -p &lt;pname&gt;          # run the job on the nodes in partition &lt;pname&gt; 
#SBATCH --partition=&lt;pname&gt; # “ “
#SBATCH -p &lt;pname1&gt;,&lt;pname2&gt;  # use nodes in either of two partitions

#SBATCH -t 10               # set wall-time limit for job to complete to 10 minutes
#SBATCH --time=10           # “ “
#SBATCH -t 3:30:00          # set wall-time limit to 3.5 hours
#SBATCH -t 2-3              # set wall-time limit to 2 days + 3 hours

#SBATCH -c 6                # allocate 6 cores (not cpus!) per task
#SBATCH --cpus-per-task=6   # “ “

#SBATCH -G 1                # allocate one GPU for the whole job
#SBATCH --gpus=1            # “ “

#SBATCH --mem-per-cpu=4G   # allocate 4 GB of memory per core (not cpu!)

#SBATCH -q &lt;qos&gt;            # request quality of service &lt;qos&gt;
#SBATCH --qos=&lt;qos&gt;         # “ “
#SBATCH -q long             # on unity allow time limit up to 14 days
#SBATCH -q short            # on unity get higher priority for a single job per user
                            # on &lt;=2 nodes with time limit &lt;=4 hours

#SBATCH -C ”&lt;cons&gt;”         # only use nodes that have constraint &lt;cons&gt;, quotes may be unnec.
#SBATCH --constraint=”&lt;cons”&gt; # “ “
#SBATCH -C ”&lt;cons1&gt;&amp;&lt;cons2&gt;”  # only use nodes that match both constraints
#SBATCH -C ”v100|a100”      # on unity only use nodes that have V100 or A100 GPUs</code></pre>
<p>Notes on these: </p>
<ul>
<li>For all of the Unity general-access partitions: The <strong>default time limit is one hour</strong>, when <code>-t ..</code> is not used. <strong>Jobs submitted to preempt partitions can be killed after two hours</strong>.</li>
<li>The <strong>maximum time limit</strong> that can be set using <code>-t ..</code> is <strong>two days</strong> unless <code>-q long</code> is used in which case it is <strong>14 days (336 hours)</strong>.</li>
<li>By running <code>scontrol config</code> it is seen that on Unity the <strong>default memory per core is 1024 MB</strong>.</li>
<li><a href="https://docs.unity.rc.umass.edu/documentation/cluster_specs/features/">This page</a> shows the <strong>constraints</strong> available on Unity.</li>
<li>To set multiple constraints I think a <strong>single <code>#SBATCH C ..</code> line</strong> using the <code>&amp;</code> or <code>|</code> operators must be used as shown above.</li>
</ul>
</li>
<li><p>Here are some #SBATCH settings more useful for <strong>multi-task (e.g. MPI) jobs</strong>:</p>
<pre><code class="fenced-code-block">#SBATCH -n 100            # allocate resources for 100 tasks (100 MPI ranks)
#SBATCH --ntasks=100      # “ “
#SBATCH -C ib             # only use nodes with InfiniBand networking
#SBATCH --gpus-per-task=1 # allocate one GPU per task
#SBATCH --nodelist=cpu[049-068] # run on specific nodes

# When using the following probably should be using constraints or nodelist:
#SBATCH -N 10             # run the job on 10 nodes
#SBATCH --nodes=10        # “ “
#SBATCH --exclusive       # use entire nodes (don’t share nodes with other jobs)
# When using the following probably should be setting the number of nodes with -N
#SBATCH --mem=5G          # allocate 5 GB of memory per node
#SBATCH --mem=0           # allocate all available memory on nodes used</code></pre>
<p>The nodes on Unity are very heterogeneous, with between 12 and 192 cores per node, so I don’t think it makes sense to use <code>-N</code>,<code>--nodes</code> or<code> --exclusive</code> unless <code>--nodelist</code> or constraints are used to match the type of nodes used to the size of the job (tasks or cores used).  Similarly <code>--mem</code> sets the memory per node and I’m not sure what this means unless the number of nodes is specified.</p>
</li>
<li><p><strong>Example of a  simple batch job</strong><a id="simple-batch"></a> not using MPI, or a GPU, or Apptainer.</p>
<ul>
<li><p>As a container is not being used, a Conda environment must be set up on Unity with the needed packages. This example uses the environment <strong><code>npsp</code></strong> <a href="#conda-hpc">set up above</a> with Python, Numpy, and Scipy, but not CuPy.</p>
</li>
<li><p>The program <code>gputest.py</code> described above (which won't try to use a GPU if CuPy cannot be imported) was put in a directory <code>/work/.../try-gputest</code> along with an sbatch script <strong><code>simple.sh</code></strong> with these contents:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# simple.sh 2/27/25 D.C.
# One-task sbatch script runs gputest.py using none of MPI, a GPU, or Apptainer.
#SBATCH -c 6                         # use 6 CPU cores
#SBATCH -p cpu                       # submit to partition cpu
echo nodelist=$SLURM_JOB_NODELIST    # print list of nodes used
module purge                         # unload all modules
module load conda/latest             # need this to use conda commands
conda activate npsp                  # environment with NumPy and SciPy but not CuPy
python gputest.py                    # run gputest.py, output will be in slurm_&lt;jobid&gt;.out  </code></pre>
<p>As written above both the output of the commands like <code>echo nodelist...</code> and <code>module load...</code> will go to a file <code>slurm-&lt;jobid&gt;.out</code> in the directory from which <code>sbatch</code> is run, along with any output to sdout or stderr by <code>gputest.py</code>.  If desired the stdout+stderr output of <code>gputest.py</code> can be directed to a different file by replacing the last line above with <code>python gputest.py &amp;&gt; &lt;filename&gt;</code>. The <code>echo nodelist...</code>  command in this script is not necessary but they will put useful information in the output file -- in this case the specific nodes used. Here is a <a href="https://hpcc.umd.edu/hpcc/help/slurmenv.html">list of Slurm environment variables</a> that can be used in this way.</p>
</li>
<li><p>To submit the job we do</p>
<pre><code class="fenced-code-block">try-gputest$ sbatch simple.sh
Submitted batch job 29258794</code></pre>
<p>  Notes:</p>
<ul>
<li><p>With this way of running, <code>sbatch</code> is run from the directory <code>try-gputest</code> and the output will go there as well -- this is why we are using a directory under <code>/work</code>.</p>
</li>
<li><p>The <code>sbatch</code> command returns immediately with the jobid, no matter how long the actual job takes.</p>
</li>
<li><p><code>sbatch</code> can be run from a login node, since the job runs on nodes allocated according to the <code>#SBATCH</code> lines in <code>simple.sh</code>, not on the node where <code>sbatch</code> was run.</p>
</li>
<li><p>Since <code>simple.sh</code> sets the Conda environment, there is no need to set it before running <code>sbatch</code>.</p>
</li>
</ul>
</li>
<li><p>To see our pending and running jobs do</p>
<pre><code class="fenced-code-block">try-gputest$ sbatch squeue --me
            JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          29258794       cpu simple.s candela_  R       0:10      1 cpu001</code></pre>
<p>Jobs that haven't started running yet will have <code>PD</code> in the <code>ST</code> column.  Here <code>R</code> means the job is running (and has used 10 seconds so far).  To cancel the job (for example, if it runs much longer than expected) do</p>
<pre><code class="fenced-code-block">try-gputest$ scancel 29258794</code></pre>
<p>Unlike an interactive job, <strong>a job submitted using <code>sbatch</code> will not be cancelled when you log out</strong> -- it will continue running until your code ends, or the job time limit (<strong>default one hour</strong>) is exceeded, or you cancel it with <code>scancel</code>.</p>
</li>
<li><p>Once the job has completed, it will no longer be shown by <code>squeue</code>, but we can get info on the job's efficiency by doing</p>
<pre><code class="fenced-code-block">try-gputest$ seff 29258794
Job ID: 29258794
Cluster: unity
User/Group: candela_umass_edu/candela_umass_edu
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 6
CPU Utilized: 00:02:36
CPU Efficiency: 18.57% of 00:14:00 core-walltime
Job Wall-clock time: 00:02:20
Memory Utilized: 1.08 GB
Memory Efficiency: 18.02% of 6.00 GB</code></pre>
<p>  We can get more info on completed jobs by using <code>sacct</code> as detailed in <a href="https://docs.rc.fas.harvard.edu/kb/convenient-slurm-commands/">this page</a> from Harvard.</p>
</li>
<li><p>We can look at the output file when the job is completed (or while the job is still running, to see the output so far):</p>
<pre><code class="fenced-code-block">nodelist=cpu001
Loading conda
Running: gputest.py 11/22/23 D.C.
Local time: Thu Feb 27 23:57:35 2025
Import cupy failed, using CPU only
CPU timings use last 10 of 11 trials

***************** Doing test dense_mult ******************
Multiply M*M=N element dense matrices
                            ...</code></pre>
</li>
</ul>
</li>
</ul>
<h3 class="atx" id="using-mpi-on-unity-without-apptainerlessa-iddouble-quoteunity-mpidouble-quotegreaterlessagreater">Using MPI on Unity (without Apptainer)<a id="unity-mpi"></a></h3>
<h4 class="atx" id="ways-of-running-python-mpi-programs-on-unitylessa-iddouble-quoteways-mpi-unitydouble-quotegreaterlessagreater">Ways of running Python MPI programs on Unity<a id="ways-mpi-unity"></a></h4>
<p>Using Python MPI program requires (a) a working MPI installation - as in <a href="#on-linux-pc">Part 1</a> we only consider <a href="https://docs.open-mpi.org/en/v5.0.x/">OpenMPI</a> here, and (b) Python MPI functions - also as in Part 1 we only consider <a href="https://mpi4py.readthedocs.io/en/stable/"><code>mpi4py</code></a> here.  Even with these restrictions there are various choices involving modules and Conda environments that seem to work on Unity (and others that don't).  In this section we use the basic <a href="#mpi-testprogs">MPI test programs described above</a>: <strong><code>mpi_hw.py</code></strong> to check that there is a functional MPI + <code>mpi4py</code> setup, and <strong><code>osu_bw.py</code></strong> to measure the speed of communication between MPI ranks.</p>
<ul>
<li><p>First we see which OpenMPI modules are available on Unity (as of 3/25). In the examples shown below when an OpenMPI module is used the latest version without CUDA <code>openmpi/5.0.3</code> is selected.</p>
<pre><code class="fenced-code-block">$ module av openmpi

---------------------- /modules/modulefiles/spack/latest/linux-ubuntu24.04-x86_64/Core ------------------
   openmpi/4.1.6-cuda12.6    openmpi/4.1.6    openmpi/5.0.3-cuda12.6    openmpi/5.0.3</code></pre>
</li>
<li><p>Next we create two Conda environments <strong><code>m4p</code></strong> and <strong><code>m4pe</code></strong> with OpenMPI, <code>mpi4py</code>, Python, and other packages likely to be needed by programs running in this environment (here we show <code>numpy</code>, <code>scipy</code>, and <code>matplotlib</code>).  Things to note:</p>
<ul>
<li><p>It seems necessary to load a Unity OpenMPI module before creating these environments, as shown here, for everything shown later to work.</p>
</li>
<li><p>We use <code>conda-forge</code>, which seems to have relatively up-to-date packages, and for <strong><code>m4pe</code></strong> (but not <strong><code>m4p</code></strong>) we follow the prescription on <a href="https://conda-forge.org/docs/user/tipsandtricks/#using-external-message-passing-interface-mpi-libraries">this conda-forge page</a> to specify that an external MPI implementation will be used. </p>
</li>
</ul>
<pre><code class="fenced-code-block">$ unity-compute
(wait for the compute-node shell to come up)
$ module load conda/latest
$ module load openmpi/5.0.3

# Create environment m4p and check that OpenMPI is available in it.
$ conda create -n m4p -c conda-forge openmpi=5 mpi4py python=3.12
$ conda activate m4p
(m4p)$ conda install numpy scipy matplotlib
(m4p)$ mpirun --version
mpirun (Open MPI) 5.0.7
(m4p)$ ompi_info | head
                 Package: Open MPI conda@f424a898794e Distribution
                Open MPI: 5.0.7
  Open MPI repo revision: v5.0.7
   Open MPI release date: Feb 14, 2025
                 MPI API: 3.1.0
            Ident string: 5.0.7
                  Prefix: /work/candela_umass_edu/.conda/envs/m4p
 Configured architecture: x86_64-conda-linux-gnu
           Configured by: conda
           Configured on: Mon Feb 17 07:57:35 UTC 2025
(m4p)$ conda deactivate

# Create environment m4pe and check that OpenMPI is available in it.
$ conda create -n m4pe -c conda-forge "openmpi=5.0.3=external_*" mpi4py python=3.12
$ conda activate m4pe
(m4pe)$ conda install numpy scipy matplotlib
(m4pe)$ mpirun --version
mpirun (Open MPI) 5.0.3
(m4pe)$ ompi_info | head
                 Package: Open MPI package-maintainer@gpu005 Distribution
                Open MPI: 5.0.3
  Open MPI repo revision: v5.0.3
   Open MPI release date: Apr 08, 2024
                 MPI API: 3.1.0
            Ident string: 5.0.3
                  Prefix: /modules/spack/packages/linux-ubuntu24.04-x86_64/gcc-13.2.0/openmpi-5.0.3-bj572zbkduba5ueea4uwnhhgbi422h55
 Configured architecture: x86_64-pc-linux-gnu
           Configured by: package-maintainer
           Configured on: Sat Aug 24 21:50:27 UTC 2024</code></pre>
</li>
<li><p>Next we run <strong><code>mpi_hw.py</code></strong> interactively to check that MPI is functional.  Here and below we supply <strong><code>--display bindings</code></strong> to <code>mpirun</code> which should show which core(s) on which node each MPI rank is bound to, before running the supplied code (<code>python</code> here).</p>
<pre><code class="fenced-code-block"># Get an interactive compute node with four cores.
$ salloc -n 4 
(wait for the compute-node shell to come up)
$ cd python-scripts; ls    # cd to directory with mpi_hw.py
mpi_hw.py  ...
python-scripts$ module load conda/latest
python-scripts$ conda activate m4p
(m4p)..python-scripts$ mpirun --display bindings python mpi_hw.py
[gypsum-gpu001:4010527] Rank 0 bound to package[0][core:4]
[gypsum-gpu001:4010527] Rank 1 bound to package[0][core:5]
[gypsum-gpu001:4010527] Rank 2 bound to package[1][core:8]
[gypsum-gpu019:3278150] Rank 3 bound to package[0][core:3]
Hello world from rank 2 of 4 on gypsum-gpu001 running Open MPI v5.0.7
Hello world from rank 1 of 4 on gypsum-gpu001 running Open MPI v5.0.7
Hello world from rank 0 of 4 on gypsum-gpu001 running Open MPI v5.0.7
Hello world from rank 3 of 4 on gypsum-gpu019 running Open MPI v5.0.7

# To run in environmenet m4pe, need to load OpenMPI module.
(m4p)..python-scripts$ conda deactivate
..python-scripts$ conda activate m4pe
(m4pe)..python-scripts$ mpirun --display bindings python mpi_hw.py
bash: mpirun: command not found
(m4pe)..python-scripts$ module load openmpi/5.0.3
(m4pe)..python-scripts$ mpirun --display bindings python mpi_hw.py
[gypsum-gpu001:4014610] Rank 0 is not bound (or bound to all available processors)
[gypsum-gpu001:4014610] Rank 1 is not bound (or bound to all available processors)
[gypsum-gpu001:4014610] Rank 2 is not bound (or bound to all available processors)
[gypsum-gpu019:3281256] Rank 3 is not bound (or bound to all available processors)
Hello world from rank 1 of 4 on gypsum-gpu001 running Open MPI v5.0.3
Hello world from rank 2 of 4 on gypsum-gpu001 running Open MPI v5.0.3
Hello world from rank 0 of 4 on gypsum-gpu001 running Open MPI v5.0.3
Hello world from rank 3 of 4 on gypsum-gpu019 running Open MPI v5.0.3</code></pre>
<p>We see:</p>
<ul>
<li><p>We can run <code>mpirun</code> in environment <code>m4p</code> without first loading an OpenMPI module, but not in environment <code>m4pe</code> which requires the OpenMPI module to be loaded.</p>
</li>
<li><p><code>--display bindings</code> shows both node and core for each rank when an OpenMPI module is <em>not</em> loaded (top example above), but only shows node and <code>Rank n is not bound...</code> when an OpenMPI module <em>is</em> loaded (bottom example above).  Although not shown above, this holds true even if environment <code>m4p</code> is used.  Even when <code>Rank n is not bound...</code> is displayed, the program still functions -- so this may be a problem of communicating information rather than an actual problem.</p>
</li>
</ul>
</li>
<li><p>Finally we run <strong><code>osu_bw.py</code></strong> to check inter-rank communication speed.</p>
<ul>
<li><p>We get an interactive node with four cores (<code>-n 4</code>) on two nodes (<code>-N 2</code>) so intra- and inter-node communication could be compared, see below. For other purposes it may not be necessary to specify the number of nodes (<code>-N</code> can be omitted) or it may be wished to force all the ranks to be on one node (<code>-N 1</code>).  We also specify <strong><code>-C ib</code> to constrain the job to nodes with InfiniBand connectivity</strong>; if this was not done the reported communication speeds were sometimes about 100 times slower.</p>
<p>To start with we activate <code>m4p</code> and do not load the OpenMPI module, then use <code>mpirun -n 2...</code> to run <code>osu_bw.py</code> on two ranks -- it is necessary to supply <code>-n 2</code> to <code>mpirun</code> here as otherwise it would default to the four ranks allocated by the <code>salloc</code> command, and <code>osu_bw.py</code> insists on exactly two ranks.</p>
<pre><code class="fenced-code-block">$ salloc -n 4 -N 2 -C ib
(wait for the compute-node shell to come up)
$ cd python-scripts; ls    # cd to directory with osu_bw.py
osu_bw.py  ...
python-scripts$ module load conda/latest
python-scripts$ conda activate m4p
(m4p)..python-scripts$ mpirun -n 2 --display bindings python osu_bw.py
[cpu045:1260236] Rank 1 bound to package[1][core:47]
[cpu045:1260236] Rank 0 bound to package[1][core:42]
2
2
# MPI Bandwidth Test
# Size [B]    Bandwidth [MB/s]
         1                1.95
         2                3.81
         4                7.51
         8               15.48
        16               31.47
        32               61.05
        64              123.70
       128              220.22
       256              439.24
       512              815.56
     1,024            1,498.98
     2,048            2,401.25
     4,096            3,096.10
     8,192            4,489.08
    16,384            6,877.37
    32,768            8,597.59
    65,536           14,706.91
   131,072           17,796.39
   262,144           12,374.38
   524,288            7,485.89
 1,048,576            8,596.79
 2,097,152            8,909.45
 4,194,304            9,040.91
 8,388,608            9,107.42
16,777,216            6,882.39</code></pre>
<p>The maximum speed seen here, 18 GB/s, varied by about +/-2 GB/s on repeated runnings.</p>
</li>
<li><p>The example above used OpenMPI's <a href="https://docs.open-mpi.org/en/v5.0.x/launching-apps/scheduling.html">default binding strategy</a> "by slot", which placed both MPI ranks on the same node. To measure the communication speed between nodes, we can supply <code>--map-by node</code> to <code>mpirun</code>:</p>
<pre><code class="fenced-code-block">(m4p)..python-scripts$ mpirun -n 2 --map-by node --display bindings python osu_bw.py
[cpu045:1260382] Rank 0 bound to package[1][core:42]
[cpu047:2425563] Rank 1 bound to package[1][core:53]
2
# MPI Bandwidth Test
# Size [B]    Bandwidth [MB/s]
2
         1                1.15
         2                2.31
         4                4.58
         8                8.94
        16               18.27
        32               36.85
        64               73.54
       128              145.92
       256              280.03
       512              549.85
     1,024            1,058.59
     2,048            2,222.78
     4,096            4,392.00
     8,192            6,205.18
    16,384            9,066.75
    32,768           10,469.50
    65,536           11,322.56
   131,072           11,803.02
   262,144           12,076.67
   524,288           12,209.42
 1,048,576           12,275.90
 2,097,152           12,205.76
 4,194,304           12,288.37
 8,388,608           12,310.17
16,777,216           12,282.66</code></pre>
<p>Now the maximum speed is 12 GB/s, i.e.  35% slower than the speed between ranks on the same node - but for some reason the largest message sizes are actually faster between nodes than between ranks on the same node.</p>
<p>The OpenMPI version of <code>mpirun</code> has <a href="https://docs.open-mpi.org/en/main/man-openmpi/man1/mpirun.1.html">many other options</a>.  Note that in other MPI packages such as MPICH  <code>mpirun</code> has different, incompatible options.</p>
</li>
<li><p>The speed tests were repeated using the environment <strong><code>m4pe</code></strong> (external MPI installation) and gave identical speed results, both between ranks on the same node and on different nodes.  As noted above this required loading the OpenMPI module and then <code>--display bindings</code> no longer showed the core numbers used.</p>
</li>
</ul>
</li>
</ul>
<h4 class="atx" id="using-sbatch-to-run-a-simple-mpi-joblessa-iddouble-quotesbatch-mpidouble-quotegreaterlessagreater">Using <code>sbatch</code> to run a simple MPI job<a id="sbatch-mpi"></a></h4>
<p>Make an sbatch script <strong><code>osu_bw.sh</code></strong> with the following contents, and put it in a directory <code>try_mpi</code> along with the test program <code>osu_bw.py</code>:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# osu_bw.sh 4/3/25 D.C.
# sbatch script to run osu_bw.py, which times the speed of MPI messaging
# between two MPI ranks.
#SBATCH -n 2                         # run 2 MPI ranks
#SBATCH -p cpu                       # submit to partition cpu
#SBATCH -C ib                        # require inifiniband connectivity
echo nodelist=$SLURM_JOB_NODELIST    # get list of nodes used
module purge                         # unload all modules
module load conda/latest             # need this to use conda commands
conda activate m4p                   # environment with OpenMPI, mpi4py, NumPy and SciPy
mpirun --display bindings python osu_bw.py</code></pre>
<p>  We go to a directory <code>try-mpi</code> into which we have copied both <code>osu_bw.sh</code> and <code>osu_bw.py</code> and run the script (as usual when running sbatch scripts, this can be done from a login shell and there is no need to set a Conda environment as the script does this):</p>
<pre><code class="fenced-code-block">$ cd try-mpi; ls
osu_bw.sh  osu_bw.py  ...
try_mpi$ sbatch osu_bw.sh
Submitted batch job 31253216
(wait until 'squeue --me' shows that job has completed)
try-mpi$ cat slurm-31253216.out
nodelist=cpu046
Loading conda
[cpu046:2330110] Rank 0 bound to package[0][core:14]
[cpu046:2330110] Rank 1 bound to package[1][core:47]
2
2
# MPI Bandwidth Test
# Size [B]    Bandwidth [MB/s]
         1                0.93
         2                3.11
         4                6.24
         8               12.56
        16               25.16
        32               47.17
        64              101.24
       128              183.91
       256              365.55
       512              709.00
     1,024            1,232.34
     2,048            1,688.76
     4,096            2,238.17
     8,192            4,456.95
    16,384            6,828.24
    32,768            8,058.85
    65,536           14,153.93
   131,072           15,690.97
   262,144           11,528.39
   524,288            8,487.05
 1,048,576            8,582.14
 2,097,152            8,361.06
 4,194,304            8,990.32
 8,388,608            8,792.12
16,777,216            7,536.62</code></pre>
<h4 class="atx" id="enabling-numpy-multithreading-in-mpi-batch-jobslessa-iddouble-quotesbatch-multithreaddouble-quotegreaterlessagreater">Enabling NumPy multithreading in MPI batch jobs<a id="sbatch-multithread"></a></h4>
<p><strong>Note:</strong> As explained at the very end of this section, <strong>this has not been fully worked out</strong> and more work would be needed to get this working reliably.</p>
<p>For background see <a href="#multiple-cores">Parallel execution on multiple cores</a> and <a href="#multithread-mpi">Hyperthreading and NumPy multithreading with MPI</a> above.  Make an sbatch script <strong><code>threadcount_mpi.sh</code></strong>  with the following contents and put it in the directory <code>try-mpi</code> along with <code>threadcount_mpi.py</code>, which is an MPI-parallel version of <code>threadcount.py</code>  <a href="#multiple-cores">discussed above</a>. </p>
<pre><code class="fenced-code-block">#!/bin/bash
# threadcount_mpi.sh 4/4/25 D.C.
# sbatch script to run threadcount_mpi.py, which uses MPI to time matrix
# multiplications in parallel in several MPI tasks.
#SBATCH -n 4                         # run 4 MPI ranks
#SBATCH --mem-per-cpu=8G             # give each core 8 GB of memory
#SBATCH -p cpu                       # submit to partition cpu
#SBATCH -C ib                        # require inifiniband connectivity
echo nodelist=$SLURM_JOB_NODELIST    # get list of nodes used
module purge                         # unload all modules
module load conda/latest             # need this to use conda commands
conda activate m4p                   # environment with OpenMPI, mpi4py, NumPy and SciPy
mpirun --display bindings python threadcount_mpi.py</code></pre>
<p>Run this sbatch script, and examine its output file and efficiency as reported by <code>seff</code>. With the <code>sbatch</code> defaults, NumPy only uses one thread (one core) in each MPI rank:</p>
<pre><code class="fenced-code-block">try-mpi$ sbatch threadcount_mpi.sh
Submitted batch job 29270594
(wait until 'squeue --me' shows that job has completed)
try-mpi$ cat slurm-29270594.out
nodelist=cpu[046-048],uri-cpu006
Loading conda
[cpu046:3233583] Rank 0 bound to package[1][core:44]
[cpu048:812940] Rank 2 bound to package[0][core:12]
[uri-cpu006:1412965] Rank 3 bound to package[0][core:5]
[cpu047:1048628] Rank 1 bound to package[0][core:31]
This is rank 0 of 4 on cpu046 running Open MPI v5.0.7
This is rank 3 of 4 on uri-cpu006 running Open MPI v5.0.7
This is rank 1 of 4 on cpu047 running Open MPI v5.0.7
This is rank 2 of 4 on cpu048 running Open MPI v5.0.7
(rank 0) Making 10,000 x 10,000 random matrices...
(rank 3) Making 10,000 x 10,000 random matrices...
(rank 1) Making 10,000 x 10,000 random matrices...
(rank 2) Making 10,000 x 10,000 random matrices...
(rank 0) ...took 3.043e+00s, average threads = 1.000
(rank 0) Multiplying matrices 3 times...
(rank 1) ...took 3.078e+00s, average threads = 1.000
(rank 1) Multiplying matrices 3 times...
(rank 3) ...took 3.284e+00s, average threads = 1.000
(rank 3) Multiplying matrices 3 times...
(rank 2) ...took 3.292e+00s, average threads = 1.000
(rank 2) Multiplying matrices 3 times...
(rank 3) ...took 2.574e+01s per trial, average threads = 1.000
(rank 2) ...took 4.091e+01s per trial, average threads = 1.000
(rank 0) ...took 4.332e+01s per trial, average threads = 1.000
(rank 1) ...took 4.397e+01s per trial, average threads = 1.000
try-mpi$ seff 29270594
Job ID: 29270594
Cluster: unity
User/Group: candela_umass_edu/candela_umass_edu
State: COMPLETED (exit code 0)
Nodes: 4
Cores per node: 1
CPU Utilized: 00:08:01
CPU Efficiency: 85.28% of 00:09:24 core-walltime
Job Wall-clock time: 00:02:21
Memory Utilized: 7.31 GB (estimated maximum)
Memory Efficiency: 22.84% of 32.00 GB (8.00 GB/core)</code></pre>
<p>Here is a modified sbatch script <strong><code>threadcount_mpi2.sh</code></strong> that will enable NumPy to use two threads (two cores) in each MPI rank.  The modifications are (a) setting <code>#SBATCH -c 2</code> to allocate two cores per MPI rank, and (b) supplying the option <code>--cpus-per-rank 2</code> to <code>mpirun</code>.  Experimentally both of these modifications are needed to allow NumPy to multithread; conversely setting <code>OMP_NUM_THREADS</code> as  <a href="#multiple-cores">discussed above</a> for a non-MPI setting seems to have no effect here.</p>
<pre><code class="fenced-code-block">#!/bin/bash
# threadcount_mpi2.sh 4/4/25 D.C.
# sbatch script to run threadcount_mpi.py, which uses MPI to time matrix
# multiplications in parallel in several MPI tasks.
# threadcount_mpi2.sh has been modified from threadcount_mpi.sh so NumPy can
# use 2 threads.
#SBATCH -n 4                         # run 4 MPI ranks
#SBATCH -c 2                         # give each rank two cores
#SBATCH --mem-per-cpu=8G             # give each core 8 GB of memory
#SBATCH -p cpu                       # submit to partition cpu
#SBATCH -C ib                        # require inifiniband connectivity
echo nodelist=$SLURM_JOB_NODELIST    # get list of nodes used
module purge                         # unload all modules
module load conda/latest             # need this to use conda commands
conda activate m4p                   # environment with OpenMPI, mpi4py, NumPy and SciPy
mpirun --display bindings --cpus-per-rank 2 python threadcount_mpi.py</code></pre>
<p>Run the modified sbatch script, and examine its output file and efficiency:</p>
<pre><code class="fenced-code-block">try-mpi$ sbatch threadcount_mpi2.sh
Submitted batch job 29273079
(wait until 'squeue --me' shows that job has completed)
/try-mpi$ cat slurm-29273079.out
nodelist=cpu[045-046],uri-cpu[009,049]
Loading conda
[cpu045:1329365] Rank 0 bound to package[0][core:15-16]
[cpu046:3239344] Rank 1 bound to package[1][core:40-41]
[uri-cpu049:3879069] Rank 3 bound to package[0][core:11-12]
[uri-cpu009:313846] Rank 2 bound to package[0][core:3,7]
This is rank 0 of 4 on cpu045 running Open MPI v5.0.7
This is rank 1 of 4 on cpu046 running Open MPI v5.0.7
This is rank 2 of 4 on uri-cpu009 running Open MPI v5.0.7
This is rank 3 of 4 on uri-cpu049 running Open MPI v5.0.7
(rank 1) Making 10,000 x 10,000 random matrices...
(rank 0) Making 10,000 x 10,000 random matrices...
(rank 2) Making 10,000 x 10,000 random matrices...
(rank 3) Making 10,000 x 10,000 random matrices...
(rank 0) ...took 2.847e+00s, average threads = 1.000
(rank 0) Multiplying matrices 3 times...
(rank 1) ...took 3.030e+00s, average threads = 1.000
(rank 1) Multiplying matrices 3 times...
(rank 3) ...took 3.227e+00s, average threads = 1.000
(rank 3) Multiplying matrices 3 times...
(rank 2) ...took 3.364e+00s, average threads = 1.000
(rank 2) Multiplying matrices 3 times...
(rank 3) ...took 1.293e+01s per trial, average threads = 1.999
(rank 2) ...took 1.298e+01s per trial, average threads = 1.999
(rank 0) ...took 2.095e+01s per trial, average threads = 1.999
(rank 1) ...took 2.166e+01s per trial, average threads = 2.000
try-mpi$ seff 29273079
Job ID: 29273079
Cluster: unity
User/Group: candela_umass_edu/candela_umass_edu
State: COMPLETED (exit code 0)
Nodes: 4
Cores per node: 2
CPU Utilized: 00:07:10
CPU Efficiency: 72.64% of 00:09:52 core-walltime
Job Wall-clock time: 00:01:14
Memory Utilized: 7.41 GB (estimated maximum)
Memory Efficiency: 11.57% of 64.00 GB (8.00 GB/core)</code></pre>
<p>Notes:</p>
<ul>
<li><p>The modified job used twice as many cores (8 rather than 4), and it ran about twice as fast because the time-consuming part of <code>threadcount_mpi.py</code> (a call to <code>np.matmul</code> to do the matrix multiplications) was able to use two threads rather than one.</p>
</li>
<li><p>Only some NumPy functions can use multithreading to run faster -- for example the creation of the matrices using <code>rng.normal</code> only used one thread even though two cores were available.</p>
</li>
<li><p>The <a href="https://docs.open-mpi.org/en/main/man-openmpi/man1/mpirun.1.html">OpenMPI docs for <code>mpirun</code></a> say <code>--cpus-per-rank</code> is deprecated in favor of something like <code>--map-by &lt;obj&gt;:PE=n</code> but I haven't tried to figure this out.</p>
</li>
<li><p>If the settings for <code>#SBATCH -c ..</code> and <code>mpirun --cpus-per-rank ..</code> do not agree, strange things happen that I do not understand.</p>
</li>
<li><p><strong>This job did not work reliably and probably requires additional <code>#SBATCH</code> settings.</strong>  For example, sometimes one MPI rank took much longer to run, or used less threads than the other ranks.  It may be necessary to constrain the job to certain nodes, but this has not been tried.</p>
</li>
</ul>
<h4 class="atx" id="using-sbatch-to-run-boxpctpy--dem21-with-mpilessa-iddouble-quotesbatch-dem21double-quotegreaterlessagreater">Using <code>sbatch</code> to run <code>boxpct.py + dem21</code> with MPI<a id="sbatch-dem21"></a></h4>
<p>See <a href="#mpi-dem21">More elaborate MPI programs...</a> above for the corresponding steps on a PC.</p>
<ul>
<li><p>As in that section, the <strong><code>dem21</code></strong> package (not public) is cloned into a directory <code>try-dem21</code> on Unity. Also the <strong><code>msigs</code></strong> package (also not public), which is used by <code>mx2.py</code> to carry out larger simulations, has been copied into the same directory:</p>
<pre><code class="fenced-code-block">try-dem21$ git clone git@github.com:doncandela/dem21.git
try-dem21$ ls
dem  msigs ...</code></pre>
</li>
<li><p>As in <a href="#ways-mpi-unity">Ways of running Python MPI programs on Unity</a> above a Conda environment <strong><code>dem21</code></strong> is defined on Unity, similar to the <strong><code>m4p</code></strong>  environment defined in that section but now including additional packages required by <code>dem21</code> and with the <code>dem21</code> and <code>msigs</code> packages installed:</p>
<pre><code class="fenced-code-block">try-dem21$ unity-compute             # get an interactive shell on a compute node
(wait for the compute-node shell to come up)
try-dem21$ module load conda/latest
try-dem21$ module load openmpi/5.0.3
try-dem21$ conda create -n dem21 -c conda-forge openmpi=5 mpi4py python=3.12
try-dem21$ conda activate dem21 
(dem21)..try-dem21$ conda install numpy scipy matplotlib dill numba pyaml
(dem21)..try-dem21$ conda install -c conda-forge quaternion
(dem21)..try-dem21$ cd dem21
(dem21)..try-dem21/dem21$ pip install -e .
(dem21)..try-dem21/dem21$ cd ../msigs
(dem21)..try-dem21/msigs$ pip install -e .</code></pre>
</li>
<li><p>At this point we can log out and back into Unity, and there will be no need to activate the environment <code>dem21</code> interactively as it will be activated by sbatch scripts as needed.</p>
</li>
</ul>
<p>We go back to <code>try-dem21</code> and copy the test program <code>boxpct.py</code> and its configuration file <code>box.yaml</code> there from the <code>tests</code> subdirectory of the cloned repo:</p>
<pre><code class="fenced-code-block">try-dem21$ ls dem21/tests/box
box.yaml  boxmod.yaml  boxpct.py  boxpct.sh  heap3.yaml  output  plots
try-dem21$ cp dem21/tests/box/boxpct.py .
tri-dem21$ cp dem21/tests/box/box.yaml .</code></pre>
<ul>
<li><p>An sbatch script <strong><code>boxpct.sh</code></strong> is created in the directory <code>try-dem21</code> with these contents:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# boxpct.sh 4/4/25 D.C.
# sbatch script to run boxpct.py, using the dem21 package in MPI-parallel mode.
#SBATCH -n 4                         # run 4 MPI ranks
#SBATCH -N 1                         # all ranks on one node
#SBATCH --mem-per-cpu=8G             # give each core 8 GB of memory
#SBATCH -p cpu                       # submit to partition cpu
#SBATCH -C ib                        # require inifiniband connectivity
echo nodelist=$SLURM_JOB_NODELIST    # get list of nodes used
module purge                         # unload all modules
module load conda/latest             # need this to use conda commands
conda activate dem21                 # environment with OpenMPI, dem21, and dependencies
export pproc=mpi                     # tells dem21 to run in MPI-parallel mode
mpirun --display bindings python boxpct.py</code></pre>
</li>
<li><p>Now we can use this script to run <code>boxpct.py</code> in MPI-parallel mode:</p>
<pre><code class="fenced-code-block">try-dem21$ sbatch boxpct.sh
Submitted batch job 31294505
(wait until 'squeue --me' shows that job has completed)
try-dem21$ cat slurm-31294505.out
nodelist=uri-cpu007
Loading conda
[uri-cpu007:472048] Rank 0 bound to package[0][core:0]
[uri-cpu007:472048] Rank 1 bound to package[0][core:1]
[uri-cpu007:472048] Rank 2 bound to package[1][core:32]
[uri-cpu007:472048] Rank 3 bound to package[1][core:33]
- Started MPI on master + 3 worker ranks.
THIS IS: boxpct.py 12/3/22 D.C., using dem21 version: v1.2 2/11/25
Parallel processing: MPI, GHOST_ARRAY=True
- Read 1 config(s) from /work/pi_.../try-dem21/box.yaml

SIM 1/1:
Using inelastic 'silicone' grainlets with en=0.7 and R=0.500mm
                   ...</code></pre>
<p>As of 4/25, under some circumstances, each rank emitted an warning message like...</p>
<pre><code class="fenced-code-block">Warning: program compiled against libxml 213 using older 209</code></pre>
<p>...before running successfully.  This was seen when <code>-c conda-forge</code> was supplied to the <code>conda install numpy...</code> command used in creating the Conda environment <code>dem21</code>, unlike what is shown above. However, I don't know if this is really the reason for such warnings or if, for example, it depends on the library versions installed on the Unity node allocated to the job.</p>
</li>
<li><p><strong>A larger <code>dem21</code> sim using <code>mx2.py</code>.</strong>  To try out a more time-consuming simulation using an sbatch job on Unity, we follow the steps shown for a PC in <a href="#mx2py">A more intensive run with <code>mx2.py</code></a> above. </p>
<ul>
<li><p>in the directory <code>cc-expts-unity</code> containing the other needed files (not explained here) we make an sbatch script <strong><code>mx2-unity.sh</code></strong> as follows:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# cc-expts-unity/mx2-unity.sh 4/6/25 D.C.
# sbatch script to run granular-memory simulation program mx2.py non-containerized
# on the Unity cluster, as an example for "My cheat sheet for MPI, GPU, Apptainer,
# and HPC".
#
# Runs mx2.py in grandparent directory in 'mpi' parallel-processing mode.
# Reads default config file mx2.yaml in grandparent directory modified by
# mx2mod.yaml in current directory.

#SBATCH -n 16                        # run 16 MPI ranks (cores here)
#SBATCH -N 1                         # use one node
#SBATCH --mem=100G                   # allocate 100G of memory per node
##SBATCH --exclusive                  # don't share nodes with other jobs
##SBATCH --mem=0                      # allocate all available memory on nodes used
#SBATCH -t 120                       # time limit 2 hrs (default is 1 hr)
#SBATCH -p cpu                       # submit to partition cpu
#SBATCH -C ib                        # require inifiniband connectivity

echo nodelist=$SLURM_JOB_NODELIST    # get list of nodes used
module purge                         # unload all modules
module load conda/latest             # need this to use conda commands
conda activate dem21                 # environment with OpenMPI, dem21, and dependencies
export pproc=mpi                     # tells dem21 to run in MPI-parallel mode
mpirun --display bindings python ../../mx2.py mx2mod</code></pre>
</li>
<li><p>We submit the job from this directory  (<code>mx2.py</code> has been written to be run from the directory where its output should go -- this may not be true for other programs):</p>
<pre><code class="fenced-code-block">$ cd ..cc-expts-unity; ls
bw6-sigs.yaml  bw6.svg  mx2mod.yaml  mx2-unity.sh signals.sh
..cc-expts-unity$ sbatch mx2-unity.sh
Submitted batch job 31446485
(wait until 'squeue --me' shows that job has completed)
..cc-expts-unity$ cat slurm-31446485.out
x</code></pre>
</li>
</ul>
</li>
<li><p>WORKING HERE</p>
<p> <strong>WORKING HERE</strong></p>
<p>OLD BELOW Eamon Dwight has run much bigger simulations using the <code>dem21</code> package on Unity.  Here are some lines from a typical sbatch script he uses.  These were for simulations that ran well on 109 MPI ranks (due to the structure of <code>dem21</code>, which split the simulation domain into 216 boxes then allocated one MPI rank per two boxes plus one MPI rank for the control program).</p>
</li>
</ul>
<pre><code class="fenced-code-block">#SBATCH -q long                     # required for jobs running more than 2 days
#SBATCH -N 1                        # run on a single node
#SBATCH --nodelistcp=cpu[049-068]     # limit to nodes with 128 cores
#SBATCH -n 109                      # allocated for 109 MPI ranks
#SBATCH --mem=15000                 # allocate 15 GB memory (per node, one node here)
#SBATCH -t 300:00:00                # time limit 300 hrs (max allowed is 14 days = 336 hrs)
#SBATCH --constraint=ib</code></pre>
<p>  The <a href="https://slurm.schedmd.com/sbatch.html">docs for <code>sbatch</code></a> seem to imply that <em>all</em> of the nodes listed in <code>--nodelist=..</code> will be allocated to the job, but experimentally only the number of nodes specified by <code>-N...</code> will be allocated.  With the <code>#SBATCH</code> settings shown above all MPI ranks were on a single node, which proved to be more efficient than some other ways of running.</p>
<p>  TODO run bigger dem21 job.</p>
<h3 class="atx" id="using-a-gpu-on-unity-without-apptainerlessa-iddouble-quoteunity-gpudouble-quotegreaterlessagreater">Using a GPU on Unity (without Apptainer)<a id="unity-gpu"></a></h3>
<h4 class="atx" id="a-conda-environment-capable-of-using-a-gpulessa-iddouble-quoteconda-gpu-unitydouble-quotegreaterlessagreater">A Conda environment capable of using a GPU<a id="conda-gpu-unity"></a></h4>
<p>This was called <strong><code>gpu</code></strong> was created on Unity as follows (as of 1/25 it seemed the current version of Python, 3.13, was incompatible with CuPy - hence the specification here python=3.12):</p>
<pre><code class="fenced-code-block">$ module load conda/latest
$ conda create -n gpu python=3.12
$ conda activate gpu
(gpu)$ python --version
Python 3.12.8
(gpu)$ conda install numpy scipy matplotlib cupy
(gpu)$ pip list
Package         Version
--------------- -----------
cupy            13.3.0
matplotlib      3.10.0
numpy           2.2.1
scipy           1.15.1</code></pre>
<p>Unlike on my PCs, on Unity it was not necessary to explicitly specify <code>-c conda-forge</code> to get an up-to-date version of CuPy (see <a href="#pytorch-cupy">Installing CUDA-aware Python packages</a> above).  This may be because <a href="https://docs.unity.rc.umass.edu/documentation/software/conda/">on Unity, Conda uses Minforge</a> rather than Anaconda.</p>
<h4 class="atx" id="run-gputestpy-on-unity-interactivelylessa-iddouble-quotegputest-interactivedouble-quotegreaterlessagreater">Run <code>gputest.py</code> on Unity interactively<a id="gputest-interactive"></a></h4>
<ul>
<li><p>Here we get an interactive shell with 6 cores and one GPU on a compute node in the <code>gpu</code> partition, and load a CUDA module (although CUDA typically seems to be loaded already on GPU nodes). Then we run <code>nvidia-smi</code> to check that the GPU and CUDA are available and get info on them (not sure why CUDA version reported by <code>nvidia-smi</code> doesn’t match module loaded):</p>
<pre><code class="fenced-code-block">$ salloc -c 6 -G 1 -p gpu
(wait for the compute-node shell to come up)
$ module load cuda/12.6
$ nvidia-smi
Wed Jan 15 16:48:06 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
                                     ...</code></pre>
</li>
<li><p>Next we activate the environment <code>gpu</code> created as above.  Then the program <a href="#gputest-py"><code>gputest.py</code></a> can be run and it will use the GPU:</p>
<pre><code class="fenced-code-block">$ module load conda/latest
$ conda activate gpu
(gpu)$ cd ..                # cd to directory containing gputest.py
(gpu)$ python gputest.py
Running: gputest.py 11/22/23 D.C.
Local time: Sun Jan 12 23:25:36 2025
GPU 0 has compute capacity 6.1, 28 SMs, 11.71 GB RAM, guess model = None
CPU timings use last 10 of 11 trials
GPU timings use last 25 of 28 trials

***************** Doing test dense_mult ******************
Multiply M*M=N element dense matrices

*********************************************************

************ Using float64 **************
     N     flop make mats  CPU test *CPU op/s*  GPU test *GPU op/s*  GPU xfer xfer rate
99,856 6.30e+07 7.61e-03s 1.20e-02s 5.25e+09/s 2.79e-04s 2.26e+11/s 4.42e-03s  0.72GB/s
                                ...</code></pre>
</li>
</ul>
<h4 class="atx" id="a-batch-job-using-a-gpulessa-iddouble-quotegpu-sbatchdouble-quotegreaterlessagreater">A batch job using a GPU<a id="gpu-sbatch"></a></h4>
<ul>
<li><p>As in the non-GPU background job example above, here we again run <code>gputest.py</code> in the directory <code>/work/...test_gpu</code> but now we activate the Conda environment <code>gpu</code> which does include CuPy, so <code>gputest.py</code> will try to use a GPU.  We will also need to ensure the CUDA module is loaded, request a GPU, and run the job in a GPU partition.  So we will use an sbatch script <strong><code>gputest.sh</code></strong> with these contents:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# gputest.sh 2/28/25 D.C.
# One-task sbatch script using a GPU but not Apptainer, runs gputest.py
#SBATCH -c 6                  # use 6 CPU cores
#SBATCH -G 1                  # use one GPU
#SBATCH -p gpu                # submit to partition gpu
echo nodelist=$SLURM_JOB_NODELIST    # get list of nodes used
module purge                  # unload all modules
module load conda/latest
module load cuda/12.6         # need CUDA to use a GPU
conda activate gpu            # environment with NumPy, SciPy, and CuPy
python gputest.py</code></pre>
<p>  As written, this script puts no constraints on the type of GPU that will be allocated or how much memory it will have. Here is an <a href="https://docs.unity.rc.umass.edu/documentation/tools/gpus/">article in the Unity docs</a> with extensive information on the GPUs available on Unity and how to select them.</p>
</li>
<li><p>Here we submit the job, then examine its output. Note this can be run in any (or no) Conda environment, and if desired on a login node, as it is the node allocated by <code>sbatch</code> that will be used to run the job:</p>
<pre><code class="fenced-code-block">try-gputest$ sbatch gputest.sh
Submitted batch job 29282756
(wait until 'squeue --me' shows that job has completed)
$ cat slurm-29282756.out
nodelist=gypsum-gpu168
Loading conda
Loading cuda version 12.6
Running: gputest.py 11/22/23 D.C.
Local time: Fri Feb 28 22:30:40 2025
GPU 0 has compute capacity 7.5, 68 SMs, 11.54 GB RAM, guess model = None
CPU timings use last 10 of 11 trials
GPU timings use last 25 of 28 trials

***************** Doing test dense_mult ******************
Multiply M*M=N element dense matrices
*********************************************************
                           ...</code></pre>
<p>  Looking at the <a href="https://docs.unity.rc.umass.edu/documentation/cluster_specs/nodes/">Unity node list</a> we see that node <code>gypsum-gpu168</code> has NVIDIA RTX 2080ti GPUs, which according to the <a href="https://docs.unity.rc.umass.edu/documentation/tools/gpus/">Unity GPU info</a> has compute capability 7.5 in agreement with the output of <code>gputest.py</code>.</p>
</li>
</ul>
<h3 class="atx" id="using-apptainer-on-unitylessa-iddouble-quoteunity-apptainerdouble-quotegreaterlessagreater">Using Apptainer on Unity<a id="unity-apptainer"></a></h3>
<h4 class="atx" id="getting-container-images-on-the-clusterlessa-iddouble-quoteimages-to-unitydouble-quotegreaterlessagreater">Getting container images on the cluster<a id="images-to-unity"></a></h4>
<p>To run on Unity, a suitable container image (<code>.sif</code> file) must be present in a Unity job I/O location under <code>/work/pi_&lt;userc&gt;</code>.  Note <code>.sif</code> files are typically one to several GB in size.</p>
<ul>
<li><p>An image can be built on a Linux PC as described in <a href="#apptainer-pc">Using Apptainer on a Linux PC</a> above, then <a href="#unity-file-transfer">tranferred to Unity</a> using <code>scp</code> (the graphical <a href="https://ood.unity.rc.umass.edu/pun/sys/dashboard"><strong>Unity OnDemand</strong></a> does not seem able to transfer files this big).</p>
</li>
<li><p>It may be possible to build an image directly on Unity using the <strong><code>--fakeroot</code></strong> option to <code>apptainer build</code>, I haven’t tried this.</p>
</li>
<li><p>Due to their large sizes, I find it handy to put all my <code>.sif</code> files in one directory on Unity and define an alias that sets the environment variable <code>SIFS</code> to the path to this directory:</p>
<pre><code class="fenced-code-block"># Add this to ~/.bash_aliases:
alias sifs='export SIFS=/work/pi_..../sifs'</code></pre>
<p>If the <strong>path has any spaces</strong> <code>"$SIFS"</code> must be used rather than <code>$SIFS</code>  but this is not shown below. Then when a new shell is obtained <code>SIFS</code> can easily be set (and if desired, the list of container images and their sizes seen): </p>
<pre><code class="fenced-code-block">$ sifs             # sets SIFS
$ du -ah $SIFS
1.3G&nbsp;&nbsp;&nbsp;&nbsp;/work/pi_..../sifs/dfs.sif
1.3G    /work/pi_..../sifs/pack.sif
1.2G&nbsp;&nbsp;&nbsp;&nbsp;/work/pi_..../sifs/m4p.sif
1.3G&nbsp;&nbsp;&nbsp;&nbsp;/work/pi_..../sifs/dem21.sif
3.3G&nbsp;&nbsp;&nbsp;&nbsp;/work/pi_..../sifs/gpu.sif
             ...</code></pre>
<p>It is assumed below that <strong><code>SIFS</code> is set</strong> and the <strong>container images <code>dem21.sf</code>..<code>pack.sif</code> have been built</strong> as detailed in <a href="#apptainer-pc">Using Apptainer on a Linux PC</a>  and transferred to Unity, as shown just above.</p>
</li>
</ul>
<h4 class="atx" id="running-a-container-interactively-or-in-a-batch-joblessa-iddouble-quoteunity-run-containerdouble-quotegreaterlessagreater">Running a container interactively or in a batch job<a id="unity-run-container"></a></h4>
<p>This section describes how to run a container that <strong>does not use MPI or a GPU</strong> -- the additional steps needed for those things are in separate sections below.</p>
<ul>
<li><p><strong>Environment for running Apptainer containers.</strong>  Unless MPI or a GPU is used, for many purposes it should not be necessary to load modules other than the Apptainer module or to set a Conda environment:</p>
<ul>
<li><p>Python and packages typically loaded with Conda like NumPy and SciPy should be pre-loaded in the container, all in the desired versions.  </p>
</li>
<li><p>User packages installed locally should also be pre-loaded in the container.</p>
</li>
<li><p>It should not be necessary to set a Conda environment before running the container, unless this is required for code running outside the container.</p>
</li>
<li><p>Both MPI and use of a GPU require non-OS code outside the container  (to manage communication between copies of the container, or to run the GPU) so in these cases a suitable Conda environment and/or module must be loaded, as shown in sections below. </p>
</li>
</ul>
</li>
<li><p><strong>Running a container interactively.</strong> Obtain a shell on a compute node, and in this shell load the Apptainer module.  Also set <code>SIFS</code> to point to directory where <code>.sif</code> (container image) files are kept.</p>
<pre><code class="fenced-code-block">$ salloc -c 6 -p cpu    # Get 6 cores on a compute node in the cpu partition
(wait for the compute-node shell to come up)
$ module load apptainer/latest
$ sifs</code></pre>
<p>&nbsp;Here we have made a directory <code>try-tprogs</code> on Unity and copied into it:</p>
<ul>
<li>The short program <code>np-version.py</code> that imports Numpy and prints its version number.</li>
<li>The program <code>test-util.py</code> that imports the <code>dcfuncs</code> package and tests that it can be run.</li>
</ul>
<p>First we check the version of Python loaded on the Unity node we are using:</p>
<pre><code class="fenced-code-block">$ cd try-tprogs; ls
np-version.py  test-util.py
test-tprogs$ python --version
Python 3.12.3</code></pre>
<p>Next we run the container <strong><code>dfs.sif</code></strong> that was built in the section <a href="#local-package-container">A container with a local Python package installed</a>, which can run programs that import the <strong><code>dcfuncs</code></strong> package.  Running the container like this  executes the commands in the <code>%runscript</code> section of the container definition file:</p>
<pre><code class="fenced-code-block">try-tprogs$ $SIFS/dfs.sif
foo!</code></pre>
<p>Shelling into the container we see the version of Python installed inside when it was built:</p>
<pre><code class="fenced-code-block">try-tprogs$ apptainer shell $SIFS/dfs.sif
Apptainer&gt; python --version
Python 3.12.8
Apptainer&gt;             # hit ctrl-d to get out of container
exit</code></pre>
<p>Next we use <code>python</code> inside the container to run the scripts <code>np-version.py</code> and <code>test-util.py</code> that are outside the container.  The first script <code>np-version.py</code> uses NumPy installed in the container when it was built, independent of what Numpy if any exists outside the container.  The second script <code>test-util.py</code> imports and uses the package <code>dcfuncs</code>, which was installed locally inside the container when it was built:</p>
<pre><code class="fenced-code-block">try-tprogs$ apptainer exec $SIFS/dfs.sif python np-version.py
numpy version = 2.2.1
try-tprogs$ apptainer exec $SIFS/dfs.sif python test-util.py
This is: dutil.py 8/19/24 D.C.
Using: util.py 8/18/24 D.C.
  ...</code></pre>
<p>It is interesting to see what outside files can be accessed from inside a container  -- this depends on how the system admins have set things up.  Poking around a container on Unity after doing <code>apptainer shell..</code> from a directory under <code>/work</code> , it seemed that from inside the container I could access all files under <code>/work</code> , but under <code>/home</code> I could only see the files under my own subdirectory of <code>/home</code> (as of 3/25).</p>
</li>
<li><p><strong>Running a  (non-MPI, non-GPU) container with a batch job.</strong><a id="app-sbatch"></a> For this purpose we have copied the python script <code>gputest.py</code> to  a Unity directory <code>/work/.../try-gputest</code> (this was also done in earlier sections showing how to run batch jobs without Apptainer). For now we will run <code>gputest.py</code> from a container that that does not contain CuPy, which will cause it not to use a GPU.  The container <strong><code>dfs.sif</code></strong> used just above would work, but here we use the even simpler container <strong><code>pack.sif</code></strong> defined in <a href="#packages-container">A container including chosen Python packages</a> .  An sbatch script <strong><code>simple-app.sh</code></strong> with the following contents is put in the directory <code>try-gputest</code>:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# simple-app.sh 4/6/25 D.C.
# One-task sbatch script uses an Apptainer container pack.sif
# that doesn't have CuPy or OpenMPI to run gputest.py (which detects
# CuPy is not present and so doesn't use a GPU).
# Must set SIFS to directory containing pack.sif before running this
# script in a directory containing gputest.py.
#SBATCH -c 6                       # use 6 CPU cores
#SBATCH -p cpu                     # submit to partition cpu
echo nodelist=$SLURM_JOB_NODELIST  # print list of nodes used
module purge                       # unload all modules
module load apptainer/latest
# Use python in pack.sif to run gputeset.py in CWD.
apptainer exec $SIFS/pack.sif python gputest.py</code></pre>
<p>We can run the job from a login node, and there is no need to load any modules or set an environment as these are taken care of by the sbatch script above. Examining the output file,  it can be seen that <code>gputest.py</code> was unable to import <code>cupy</code> and so did not try to use a GPU:</p>
<pre><code class="fenced-code-block">try-tprogs$ sifs          # sets SIFS to directory containing pack.sif 
try-tprogs$ ls
simple-app.sh  gputest.py
try-tprogs$ sbatch simple-app.sh
Submitted batch job 29310376
(wait until 'squeue --me' shows that job has completed)
try-gputest$ cat slurm-29310376.out
nodelist=gypsum-gpu080
Loading apptainer version latest
Running: gputest.py 11/22/23 D.C.
Local time: Sun Mar  2 02:41:10 2025
Import cupy failed, using CPU only
CPU timings use last 10 of 11 trials

***************** Doing test dense_mult ******************
Multiply M*M=N element dense matrices
*********************************************************
                 ...</code></pre>
</li>
</ul>
<h4 class="atx" id="running-containers-that-use-mpilessa-iddouble-quoteunity-mpi-containerdouble-quotegreaterlessagreater">Running containers that use MPI<a id="unity-mpi-container"></a></h4>
<p>Here we combine things from the sections above on <a href="#unity-run-container">running a non-MPI container on Unity</a>, <a href="#mpi-container">running a container with MPI on a PC</a>, and <a href="#unity-mpi">running a non-containerized MPI job on Unity</a>.</p>
<p>For the examples here it assumed that the needed image file (<strong><code>m4p.sif</code></strong> or <strong><code>dem21.sif</code></strong>) has been built on a PC as shown in the sections referenced above and transferred to a directory under <code>/work/pi...</code> on Unity -- also that <strong><code>sifs</code></strong> has been aliased to a command that sets the environment variable <code>SIFS</code> to point to this directory, as <a href="#images-to-unity">discussed here</a>.</p>
<ul>
<li><p>First we make a Conda environment <strong><code>ompi</code></strong> in which to run the container, with OpenMPI but not including <code>mpi4py</code>, <code>numpy</code>... as these things are installed in the container. We do include Python so pip could be used to install things to this environment.  It works equally well to use the environment <strong><code>m4py</code></strong> defined above which does include <code>mpi4py</code>, etc.</p>
<pre><code class="fenced-code-block">$ unity-compute
(wait for the compute-node shell to come up)
$ module load conda/latest
$ module load openmpi/5.0.3
$ conda create -n ompi -c conda-forge openmpi=5 python=3.12
$ conda activate ompi
(ompi)$ mpirun --version
mpirun (Open MPI) 5.0.7
(m4p)$ ompi_info | head
                 Package: Open MPI conda@f424a898794e Distribution
                Open MPI: 5.0.7
  Open MPI repo revision: v5.0.7
   Open MPI release date: Feb 14, 2025
                 MPI API: 3.1.0
            Ident string: 5.0.7
                  Prefix: /work/candela_umass_edu/.conda/envs/ompi
 Configured architecture: x86_64-conda-linux-gnu
           Configured by: conda
           Configured on: Mon Feb 17 07:57:35 UTC 2025</code></pre>
</li>
<li><p>Here we use the container <strong><code>m4p.sif</code></strong> to run <strong><code>mpi_hw.py</code></strong> in a manner similar to the <a href="#ways-mpi-unity">non-Apptainer section on MPI</a> above.  The difference is that here we are using <code>mpirun</code> to start multiple copies of <code>apptainer exec</code>, each of which then runs <code>python mpi_hw.py</code>.</p>
<pre><code class="fenced-code-block">$ salloc -n 4              # get interactive shell on compute node with 4 cores
(wait for the compute-node shell to come up)
$ module load conda/latest
$ conda activate ompi
(ompi)..$ sifs             # sets SIFS to directory with m4p.sif
$ cd python-scripts; ls    # cd to directory with mpi_hw.py
mpi_hw.py  ...
(ompi)..python-scripts$ mpirun --display bindings apptainer exec $SIFS/m4p.sif python mpi_hw.py
[cpu005:01143] Rank 0 bound to package[1][core:18]
[cpu005:01143] Rank 1 bound to package[1][core:19]
[cpu007:2945042] Rank 2 bound to package[1][core:21]
[cpu008:4032683] Rank 3 bound to package[0][core:3]
Hello world from rank 1 of 4 on cpu005 running Open MPI v5.0.7
Hello world from rank 3 of 4 on cpu008 running Open MPI v5.0.7
Hello world from rank 2 of 4 on cpu007 running Open MPI v5.0.7
Hello world from rank 0 of 4 on cpu005 running Open MPI v5.0.7</code></pre>
</li>
<li><p>Here we use the container <strong><code>m4p.sif</code></strong> to run <strong><code>osu_bw.py</code></strong>  in two ranks on the same node, then on two ranks on different nodes.  Again we copy the <a href="#ways-mpi-unity">non-Apptainer section on MPI</a> above, but again we are using <code>mpirun</code> to run multiple copies of <code>apptainer exec</code> rather than directly running <code>python</code>.</p>
<pre><code class="fenced-code-block">$ salloc -n 4 -N 2 -C ib    # get interactive shell with 4 cores on 2 nodes, infiniband
(wait for the compute-node shell to come up)
$ module load conda/latest
$ conda activate ompi
(ompi)..$ sifs             # sets SIFS to directory with m4p.sif
$ cd python-scripts; ls    # cd to directory with osu_bw.py
osu_bw.py  ...

# Run with default binding, puts both ranks on same node.
(ompi)..python-scripts$ mpirun -n 2 --display bindings apptainer exec $SIFS/m4p.sif python osu_bw.py
[cpu049:742033] Rank 0 bound to package[1][core:83]
[cpu049:742033] Rank 1 bound to package[1][core:84]
2
2
# MPI Bandwidth Test
# Size [B]    Bandwidth [MB/s]
         1                2.59
         2                5.47
         4               11.13
         8               22.20
        16               44.19
        32               86.90
        64              174.54
       128              308.25
       256              603.50
       512            1,202.67
     1,024            2,355.65
     2,048            4,450.55
     4,096            7,887.71
     8,192            5,930.39
    16,384           13,396.33
    32,768            9,352.70
    65,536           13,328.49
   131,072           16,870.32
   262,144           18,602.76
   524,288           20,919.15
 1,048,576           21,668.60
 2,097,152           21,891.10
 4,194,304           22,074.93
 8,388,608           22,823.64
16,777,216           21,265.93

# Run with --map-by node, puts ranks on diffent nodes.
(ompi)..python-scripts$ mpirun -n 2 --map-by node --display bindings apptainer exec $SIFS/m4p.sif python osu_bw.py
[cpu049:742176] Rank 0 bound to package[1][core:83]
[cpu050:4179815] Rank 1 bound to package[0][core:2]
2
# MPI Bandwidth Test
# Size [B]    Bandwidth [MB/s]
2
         1                1.76
         2                3.48
         4                7.06
         8               14.21
        16               28.43
        32               56.85
        64              114.17
       128              224.43
       256              387.01
       512              781.21
     1,024            1,478.60
     2,048            3,056.77
     4,096            4,353.85
     8,192            4,458.93
    16,384            5,331.77
    32,768            7,504.09
    65,536           11,265.97
   131,072           11,891.43
   262,144           12,117.05
   524,288           12,148.33
 1,048,576           12,211.63
 2,097,152           12,285.85
 4,194,304           12,315.35
 8,388,608           12,317.98
16,777,216           12,310.61</code></pre>
<p>The peak speeds seem about the same as observed in the the <a href="#ways-mpi-unity">non-Apptainer tests</a> above.</p>
</li>
<li><p><strong>Running a containerized MPI batch job.</strong> Here is an sbatch script <strong><code>osubw-app.sh</code></strong> for running <code>osu_bw.py</code>  with the container <code>myp.sif</code> in a batch job. The <code>#SBATCH</code> settings are the same as used for <code>salloc</code> when <code>osu_bw.py</code> was run interactively in the previous section:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# osubw-app.sh 4/6/25 D.C.
# Two-task sbatch script uses an Apptainer container m4p.sif that
# has OpenMPI to run osu_bw.py, which measures the commnunication
# speed between two MPI ranks. Activates the Conda environment ompi to
# make OpenMPI available outside the container. Must set SIFS to directory
# containing m4p.sif before running script in a directory containing osu_bw.py
#SBATCH -N 2                       # allocate two nodes
#SBATCH -n 4                       # allocate for up to 4 MPI ranks
#SBATCH -p cpu                     # submit to partition cpu
#SBATCH -C ib                      # require inifiniband connectivity
echo nodelist=$SLURM_JOB_NODELIST  # print list of nodes used
module purge                       # unload all modules
module load apptainer/latest
module load conda/latest
conda activate ompi
mpirun -n 2 --display bindings apptainer exec $SIFS/m4p.sif python osu_bw.py

# Alternative mpirun command has '--map-by node' to make run on two nodes.
#mpirun -n 2 --display bindings --map-by node \
#    apptainer exec $SIFS/ompi5.sif python osu_bw.py</code></pre>
<p>The job is submitted from a directory containing this sbatch script and <code>osu_bw.py</code>.  As usual it can be submitted from a login shell, without activating a Conda environment:</p>
<pre><code class="fenced-code-block">$ sifs                # sets SIFS to directory containing m4p.sif 
$ cd try-mpi; ls      # cd to directory where osubw-app.sh and osu_bw.py are located
osubw-app.sh osu_bw.py...
try-mpi$ sbatch osubw-app.sh
Submitted batch job 31303947
(wait until 'squeue --me' shows that job has completed)
try-mpi$ cat slurm-31303947.out
nodelist=cpu[046-047]
Loading apptainer version latest
Loading conda
[cpu046:691666] Rank 0 bound to package[0][core:1]
[cpu046:691666] Rank 1 bound to package[0][core:2]
2
2
# MPI Bandwidth Test
# Size [B]    Bandwidth [MB/s]
         1                2.43
         2                4.81
         4                9.80
         8               19.52
        16               39.17
        32               77.89
        64              155.72
       128              288.67
       256              578.99
       512            1,155.67
     1,024            2,242.96
     2,048            4,224.08
     4,096            7,576.89
     8,192            5,053.99
    16,384            7,661.24
    32,768            9,452.70
    65,536           16,074.42
   131,072           20,191.90
   262,144           14,337.65
   524,288            9,070.66
 1,048,576            8,696.12
 2,097,152            9,255.01
 4,194,304            9,152.04
 8,388,608            9,188.64
16,777,216            8,734.19</code></pre>
</li>
<li><p><strong>Using a container to run the <code>dem21</code> test program <code>boxpct.py</code>.</strong>  Here we follow the steps shown for a PC in <a href="#dem21-container">A container to run the more elaborate MPI package <code>dem21</code></a> above, but now running sbatch jobs on Unity.</p>
<ul>
<li><p>As <a href="#images-to-unity">described earlier</a> the container <strong><code>dem21.sif</code></strong> built on a PC as in <a href="#dem21-container">A container to run the more elaborate...</a>  was copied to a Unity directory under <code>/work/pi..</code> and the alias <code>sifs</code> was set up to set the environment variable <code>SIFS</code> to point to this directory.</p>
</li>
<li><p>As was done earlier for a <a href="#sbatch-dem21">non-containerized run on Unity</a>,  <code>boxpct.py</code>  and its configuration file <code>box.yaml</code> are copied to a directory <code>try-dem21</code>. Now we also put in this directory an sbatch script <strong><code>boxpct-app.sh</code></strong> with these contents:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# boxpct-app.sh 4/6/25 D.C.
# n-task sbatch script uses an Apptainer container dem21.sif that
# has OpenMPI and the dem21 package to run boxpct.py, which is a
# test program for the dem21 simulation package.
# Must set SIFS to directory containing dem21.sif before running this
# script in a directory containing boxpct.py
#SBATCH -n 4                       # allocate for n MPI ranks
#SBATCH -p cpu                     # submit to partition cpu
#SBATCH -C ib                      # require inifiniband connectivity
echo nodelist=$SLURM_JOB_NODELIST  # print list of nodes used
module purge                       # unload all modules
module load apptainer/latest
module load conda/latest
conda activate ompi
export pproc=mpi                   # tells dem21 to run in MPI-parallel mode
mpirun --display bindings apptainer exec $SIFS/dem21.sif python boxpct.py</code></pre>
</li>
<li><p>The job is run in the same manner as <code>osu_bw.py</code> was run just above:</p>
<pre><code class="fenced-code-block">$ sifs                # sets SIFS to directory containing m4p.sif 
$ cd try-dem21; ls      # cd to directory where boxpct-app.sh, boxpct.py, and box. are located
boxpct-app.sh boxpct.py  box.yaml  ...
try-dem21$ sbatch boxpct-app.sh
Submitted batch job 31304489
(wait until 'squeue --me' shows that job has completed)
try-mpi$ cat slurm-31304489.out
nodelist=cpu046
Loading apptainer version latest
Loading conda
[cpu046:717593] Rank 0 bound to package[0][core:1]
[cpu046:717593] Rank 1 bound to package[0][core:2]
[cpu046:717593] Rank 2 bound to package[1][core:32]
[cpu046:717593] Rank 3 bound to package[1][core:33]
- Started MPI on master + 3 worker ranks.
THIS IS: boxpct.py 12/3/22 D.C., using dem21 version: v1.2 2/11/25
Parallel processing: MPI, GHOST_ARRAY=True
- Read 1 config(s) from /work/pi_candela_umass_edu/dcstuff/2025-03ff-mgah/try-dem21/box.yaml

SIM 1/1:
Using inelastic 'silicone' grainlets with en=0.7 and R=0.500mm

                          ...</code></pre>
</li>
</ul>
</li>
<li><p><strong>Using a container to run a larger DEM simulation with <code>dem21</code>.</strong>   Here we continue to follow the corresponding steps shown for a PC in <a href="#dem21-container">A container to run the more elaborate MPI package <code>dem21</code></a> above. <strong>WORKING HERE</strong></p>
<ul>
<li>x</li>
</ul>
</li>
</ul>
<h4 class="atx" id="running-a-container-the-uses-a-gpulessa-iddouble-quoteunity-gpu-containerdouble-quotegreaterlessagreater">Running a container the uses a GPU<a id="unity-gpu-container"></a></h4>
<ul>
<li><p>This is very similar to running a non-GPU container as described above, with these differences:</p>
<ul>
<li>Obviously this must be done on a node with GPU(s), with a GPU allocated to the job by SLURM.</li>
<li>Both CUDA and Apptainer modules should be loaded (although both packages seem to be pre-loaded on GPU nodes).</li>
<li>The container (<code>.sif file</code>) must have been built with CUDA libraries. Installing CuPy in the container build definition seems to accomplish this.</li>
<li>Apptainer commands running the container must have the --nv flag to make the external CUDA libraries available.</li>
</ul>
</li>
<li><p>Here is an example of these things in action for <strong>interactive use of a GPU with a container</strong>:  </p>
<ul>
<li><p>As <a href="#images-to-unity">described earlier</a> the container <strong><code>gpu.sif</code></strong> (built on a PC as in <a href="#gpu-container">A container that can use a GPU</a>) was copied to a Unity directory under <code>/work/pi..</code> and the alias <code>sifs</code> was set up to set the environment variable <code>SIFS</code> to point to this directory.</p>
</li>
<li><p><code>gputest.py</code> was copied to the directory <code>try-gputest</code> (this was already done for other sections above).</p>
</li>
<li><p>An interactive shell is allocated on a compute node with 6 cores and one GPU, then CUDA and Apptainer modules are loaded (<code>nvidia-smi</code> checks that the GPU is available but is not necessary here):</p>
<pre><code class="fenced-code-block">$ salloc -c 6 -G 1 -p gpu
(wait for the compute-node shell to come up)
$ module load apptainer/latest
$ module load cuda/12.6
$ nvidia-smi
Tue Jan 14 16:57:25 2025
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4
                           ...</code></pre>
</li>
<li><p>Now <code>apptainer exec</code> with the flag <code>--nv</code> is able to use the GPU.  Note that it is not necessary to set a Conda environment -- running in the container replaces this:</p>
<pre><code class="fenced-code-block">$ cd try-gputest; ls
gputest.py ...
try-gputest$ sifs                  # set SIFS
try-gputest$ apptainer exec --nv $SIFS/gpu.sif python gputest.py
Running: gputest.py 11/22/23 D.C.
Local time: Tue Jan 14 17:00:08 2025
GPU 0 has compute capacity 6.1, 28 SMs, 11.71 GB RAM, guess model = None
CPU timings use last 10 of 11 trials
GPU timings use last 25 of 28 trials

***************** Doing test dense_mult ******************
Multiply M*M=N element dense matrices

*********************************************************

************ Using float64 **************
       N     flop make mats  CPU test *CPU op/s*  GPU test *GPU op/s*  GPU xfer xfer rate
  99,856 6.30e+07 5.57e-03s 1.04e-03s 6.04e+10/s 2.76e-04s 2.28e+11/s 9.48e-03s  0.34GB/s
                                    ...</code></pre>
</li>
</ul>
</li>
<li><p><strong>A batch job using a container, with a GPU.</strong></p>
<ul>
<li><p>This is similar to the <a href="#app-sbatch">non-GPU batch container job shown earlier</a>, with these differences: </p>
<ul>
<li>We request a GPU, and submit to a GPU partition.</li>
<li>In addition to Apptainer, we need to load the module for CUDA.</li>
<li>We use the container <code>gpu.sif</code> that was built including Cupy.</li>
<li>We need the <code>–-nv</code> flag on apptainer exec.</li>
</ul>
</li>
<li><p>Here is an sbatch script <strong><code>gputest-app.sh</code></strong> that incorporates these changes, which we put in the same directory <code>try-gputest</code> as <code>gputest.py</code>:</p>
<pre><code class="fenced-code-block">#!/bin/bash
# gputest-app.sh 4/6/25 D.C.
# One-task sbatch script uses an Apptainer container gpu.sif
# that has CuPy to run gputest.py, which will use a GPU.
# Must set SIFS to directory containing gpu.sif before running this
# script in a directory containing gputest.py
#SBATCH -c 6                       # use 6 CPU cores
#SBATCH -G 1                       # use one GPU
#SBATCH -p gpu                     # submit to partition gpu
echo nodelist=$SLURM_JOB_NODELIST  # print list of nodes used
module purge                       # unload all modules
module load apptainer/latest
module load cuda/12.6              # need CUDA to use a GPU
# Use python in gpu.sif to run gputest.py in CWD; need --nv flag
# on apptainer exec to use a GPU.
apptainer exec --nv $SIFS/gpu.sif python gputest.py</code></pre>
<p>As usual for <code>sbatch</code> jobs, we can run the job from a login node if desired:</p>
<pre><code class="fenced-code-block">$ cd try-gputest; ls
gputest-app.sh gputest.py ...
try-gputest$ sifs                    # set SIFS
try-gputest$ sbatch gputest-app.sh
Submitted batch job 29323951
(wait until 'squeue --me' shows that job has completed)
try-gputest$ cat slurm-29323951.out
nodelist=gypsum-gpu096
Loading apptainer version latest
Loading cuda version 12.6
Running: gputest.py 11/22/23 D.C.
Local time: Sun Mar  2 14:40:17 2025
GPU 0 has compute capacity 5.2, 24 SMs, 12.79 GB RAM, guess model = None
CPU timings use last 10 of 11 trials
GPU timings use last 25 of 28 trials

***************** Doing test dense_mult ******************
Multiply M*M=N element dense matrices
*********************************************************

************ Using float64 **************
         N     flop make mats  CPU test *CPU op/s*  GPU test *GPU op/s*  GPU xfer xfer rate
    99,856 6.30e+07 5.75e-03s 4.16e-04s 1.52e+11/s 5.77e-04s 1.09e+11/s 4.67e-03s  0.68GB/s
                       ...
try-gputest$ seff 29323951
Job ID: 29323951
Cluster: unity
User/Group: candela_umass_edu/candela_umass_edu
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 6
CPU Utilized: 00:03:15
CPU Efficiency: 19.12% of 00:17:00 core-walltime
Job Wall-clock time: 00:02:50
Memory Utilized: 2.76 GB
Memory Efficiency: 46.07% of 6.00 GB</code></pre>
</li>
</ul>
</li>
</ul>
<h2 class="atx" id="random-notes-on-parallel-computing-with-pythonlessa-iddouble-quoterandom-notesdouble-quotegreaterlessagreater">Random notes on parallel computing with Python<a id="random-notes"></a></h2>
<h3 class="atx" id="a-long-journeylessa-iddouble-quotejourneydouble-quotegreaterlessagreater">A long journey<a id="journey"></a></h3>
<p>This "cheat sheet" on MPI, GPUs, Apptainer, and HPC (<strong>MGAH</strong>) has ended up longer than anticipated.  But finally this shows with examples how the elements of  MGAH can be used together in various useful combinations, including:</p>
<ul>
<li><p>Using a Slurm cluster, both <a href="#unity-cluster">without (<strong>H</strong>)</a> and <a href="#unity-apptainer">with (<strong>AH</strong>)</a> Apptainer.</p>
</li>
<li><p>Running an MPI program on a PC, both <a href="#mpi-pc">without (<strong>M</strong>)</a> and <a href="#mpi-container">with (<strong>MA</strong>)</a> Apptainer.</p>
</li>
<li><p>Running an MPI program on a Slurm cluster, both <a href="#unity-mpi">without (<strong>MH</strong>)</a> and <a href="#unity-mpi-container">with (<strong>MAH</strong>)</a> Apptainer.</p>
</li>
<li><p>Running a GPU program on a PC, both <a href="#gpu-pc">without (<strong>G</strong>)</a> and with <a href="#gpu-container">(<strong>GA</strong>) Apptainer</a>.</p>
</li>
<li><p>Running a GPU program on a Slurm cluster, both <a href="#unity-gpu">without (<strong>GH</strong>)</a> and <a href="#unity-gpu-container">with (<strong>GAH</strong>)</a> Apptainer.</p>
</li>
</ul>
<p>What haven't been shown explicitly here are examples of using MPI and GPUs together with or without Apptainer (<strong>MGH</strong>, <strong>MGAH</strong>)-- but I think the necessary ingredients to do this are in the sections above.</p>
<p>The main advantages that emerged for each of the elements of MGAH were:</p>
<ul>
<li><strong>MPI (M)</strong> enables parallel computation that can use all cores of a PC, and then if needed scale to using all cores on multiple nodes in a cluster -- at the expense of figuring out in detail how to divide your code into multiple tasks that coordinate send messages to coordinate.</li>
<li>A <strong>GPU (G)</strong> parallelizes code more easily than MPI, but only if the code can make use of existing GPU-aware packages like CuPy.  While the degree of parallelism is limited by the GPU available, in practice this seems no worse than what can be done using MPI (unless HPC resources beyond those discussed in this document were obtained).</li>
<li>Containerization of code with <strong>Apptainer (A)</strong> does seem effective.  For example, all of the containers built and tested on PCs (using MPI, a GPU, or neither) worked without difficulty when simply copied to the Unity cluster.</li>
<li>Moving code to an <strong>HPC cluster (H)</strong> like Unity has proved useful to me mainly when the <em>volume</em> of work (e.g. number of simulations) increased, to enable completion of a study.  Individual jobs could be made to complete about 10 times faster than on a PC (if many cores were used for MPI, or a high-quality GPU could be used) -- but the big advantage over the PC was the ability to queue up many such jobs all at once.</li>
</ul>
<h3 class="atx" id="wall-time-and-cpu-timelessa-iddouble-quotewall-cpu-timedouble-quotegreaterlessagreater">Wall time and CPU time<a id="wall-cpu-time"></a></h3>
<p><strong>TODO</strong></p>
<h3 class="atx" id="factors-other-than-parallelism-affecting-execution-speedlessa-iddouble-quoteother-speed-factorsdouble-quotegreaterlessagreater">Factors other than parallelism affecting execution speed<a id="other-speed-factors"></a></h3>
<p><strong>TODO</strong> already have this info near intro?</p>
<h3 class="atx" id="strong-and-weak-scalinglessa-iddouble-quotestrong-weak-scalingdouble-quotegreaterlessagreater">Strong and weak scaling<a id="strong-weak-scaling"></a></h3>
<p>Estimating MPI communication overhead<a id="estimate-mpi-overhead"></a></p>
</article>
</body>
</html>